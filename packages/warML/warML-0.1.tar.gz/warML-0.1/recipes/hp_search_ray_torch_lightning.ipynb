{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import sigmoid\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "output_cols = ['date_cible','perimetre_prod','type_prod','prev_FC']\n",
    "USELESS_COLS_BY_TYPE = dict(pv=['u100','ff100','v100'],\n",
    "                            eolien=['t2m','ssrd'])\n",
    "\n",
    "# Mod√®les nationaux\n",
    "\n",
    "class WindDataModule(LightningDataModule):\n",
    "\n",
    "    def __init__(self,df:pd.DataFrame, type_prod:str,batch_size:int):\n",
    "\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.type_prod=type_prod\n",
    "        self.batch_size=batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download, split, etc...\n",
    "        # only called on 1 GPU/TPU in distributed\n",
    "\n",
    "        df = self.df[self.df.type_prod==self.type_prod].drop(columns=['perimetre_prod','type_prod','date_lancement','puissance_installee','comptage'],errors='ignore')\n",
    "        # DROP USELESS COLS\n",
    "        for useless_c in USELESS_COLS_BY_TYPE[self.type_prod]:\n",
    "            df = df[df.columns.drop(list(df.filter(regex=useless_c)))]\n",
    "\n",
    "        df_train = df[df.date_cible.dt.year < 2019]\n",
    "        df_test = df[df.date_cible.dt.year == 2019]\n",
    "\n",
    "        df_train, df_val = train_test_split(df_train, test_size=0.33)\n",
    "\n",
    "        std_scaler = StandardScaler()\n",
    "\n",
    "        self.x_train = torch.from_numpy(std_scaler.fit_transform(df_train.drop(columns=['FC','date_cible']))).float()\n",
    "        self.x_test = torch.from_numpy(std_scaler.transform(df_test.drop(columns=['FC','date_cible']))).float()\n",
    "        self.x_val = torch.from_numpy(std_scaler.transform(df_val.drop(columns=['FC','date_cible']))).float()\n",
    "        self.y_train = torch.from_numpy(df_train['FC'].values).float()\n",
    "        self.y_test = torch.from_numpy(df_test['FC'].values).float()\n",
    "        self.y_val = torch.from_numpy(df_val['FC'].values).float()\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_split = TensorDataset(self.x_train, self.y_train)\n",
    "        return DataLoader(train_split, shuffle=True, batch_size=self.batch_size,num_workers=1)\n",
    "    def val_dataloader(self):\n",
    "        val_split = TensorDataset(self.x_val, self.y_val)\n",
    "        return DataLoader(val_split,num_workers=1)\n",
    "    def test_dataloader(self):\n",
    "        test_split = TensorDataset(self.x_test, self.y_test)\n",
    "        return DataLoader(test_split,num_workers=1)\n",
    "    def predict_dataloader(self):\n",
    "        test_split = TensorDataset(self.x_test, self.y_test)\n",
    "        return DataLoader(test_split,num_workers=1)\n",
    "\n",
    "\n",
    "def predict(model, x):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "        return sigmoid(out).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## National Eolien\n",
    "\n",
    "\n",
    "type_prod = 'eolien'\n",
    "n_samples=30\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "\n",
    "from ray import tune\n",
    "\n",
    "class LightningMNISTRegressor(pl.LightningModule):\n",
    "    def __init__(self, config,input_dim):\n",
    "        super(LightningMNISTRegressor, self).__init__()\n",
    "\n",
    "        self.lr = config[\"lr\"]\n",
    "        self.dropout_rate = config[\"dropout_rate\"]\n",
    "        layer_1_dim, layer_2_dim = config[\"layer_1\"], config[\"layer_2\"]\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "        # Input shape is (batch_size,  n_dim)\n",
    "        self.layer_1 = torch.nn.Linear(input_dim, layer_1_dim)\n",
    "        self.drop_1 = torch.nn.Dropout(p=self.dropout_rate)\n",
    "        self.layer_2 = torch.nn.Linear(layer_1_dim, layer_2_dim)\n",
    "        self.drop_2 = torch.nn.Dropout(p=self.dropout_rate)\n",
    "        self.layer_3 = torch.nn.Linear(layer_2_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, d = x.size()\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.drop_1(torch.relu(self.layer_1(x)))\n",
    "        x = self.drop_2(torch.relu(self.layer_2(x)))\n",
    "        x = self.layer_3(x)\n",
    "        x = x.view(-1)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"ptl/val_loss\", avg_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_with_config(config, input_dim=29, base_df=None, num_gpus=1, disable_logging=False):\n",
    "    model = LightningMNISTRegressor(config, input_dim)\n",
    "    metrics = {\"loss\": \"ptl/val_loss\"}\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config['epochs'],\n",
    "        gpus=num_gpus,\n",
    "        progress_bar_refresh_rate=0,\n",
    "        callbacks=[TuneReportCallback(metrics, on=\"validation_end\")] if not disable_logging else None)\n",
    "\n",
    "\n",
    "    trainer.fit(model, datamodule=WindDataModule(df=base_df, type_prod=type_prod, batch_size=config['batch_size']))\n",
    "    return trainer\n",
    "\n",
    "def hp_search(base_df, input_dim, num_samples=10, cpus_per_trial=1, gpus_per_trial=1,name='foo'):\n",
    "    config = {\n",
    "        \"layer_1\": tune.choice([2, 4, 8,16]),\n",
    "        \"layer_2\": tune.choice([2, 4, 8,16]),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"dropout_rate\": tune.uniform(0.0,0.4),\n",
    "        \"batch_size\": tune.choice([32, 64, 128]),\n",
    "        \"epochs\": tune.choice(range(10)),\n",
    "    }\n",
    "\n",
    "    trainable = tune.with_parameters(\n",
    "        train_with_config,  input_dim=input_dim, base_df=base_df, num_gpus=gpus_per_trial)\n",
    "    return tune.run(\n",
    "        trainable,\n",
    "        resources_per_trial={\n",
    "            \"cpu\": cpus_per_trial,\n",
    "            \"gpu\": gpus_per_trial\n",
    "        },\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "\n",
    "        name=name)\n",
    "\n",
    "analysis = hp_search(national_df, input_dim=29, num_samples=n_samples, cpus_per_trial=1,gpus_per_trial=0,name=\"national_eolien\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_trial_config = analysis.get_best_trial(\"loss\", \"min\", \"last\").config\n",
    "best_trainer = train_with_config( best_trial_config, 29, national_df, disable_logging=True, num_gpus=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#best_trainer.predict() # not working wtf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dm = WindDataModule(national_df, type_prod=type_prod, batch_size=32)\n",
    "dm.prepare_data()\n",
    "test_df['prev_FC'] = predict(best_trainer.model, dm.x_test)\n",
    "test_df['type_prod'] =type_prod\n",
    "test_df['perimetre_prod'] ='national'\n",
    "overall_preds = pd.concat([overall_preds,test_df[output_cols]], axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}