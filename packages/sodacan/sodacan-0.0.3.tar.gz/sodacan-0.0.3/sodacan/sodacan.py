"""COPYRIGHT 2021 """
RQ="""
altgraph==0.17
argcomplete==1.10.0
backcall==0.2.0
beautifulsoup4==4.8.0
bitly-api==0.3
bs4==0.0.1
cachetools==4.2.1
certifi==2020.12.5
cffi==1.14.5
chardet==3.0.4
clarifai==2.6.2
click==7.1.2
colorama==0.3.9
colored==1.3.93
colormath==3.0.0
configparser==3.5.0
cryptography==3.4.6
curlify==2.2.1
cycler==0.10.0
decorator==4.4.2
dicttoxml==1.7.4
dill==0.3.3
docx2txt==0.8
EasyProcess==0.3
EbookLib==0.17.1
emoji==0.5.1
et-xmlfile==1.0.1
extract-msg==0.23.1
facebook-business==3.3.0
facebookads==2.11.4
feedparser==5.2.1
fonttools==3.29.0
future==0.18.2
gast==0.2.0
google-api-core==1.3.0
google-api-python-client==1.6.4
google-auth==1.5.1
google-auth-httplib2==0.0.4
google-auth-oauthlib==0.2.0
google-images-download==2.3.0
googleapis-common-protos==1.5.3
grpcio==1.35.0
gspread==0.6.2
gTTS==2.0.1
gTTS-token==1.1.4
html5lib==1.0.1
httplib2==0.10.3
idna==2.10
imageio==2.9.0
imageio-ffmpeg==0.4.3
IMAPClient==2.1.0
imgkit==1.0.1
imgurpython==1.1.7
instapy==0.6.2
ipython==7.20.0
ipython-genutils==0.2.0
jdcal==1.4.1
jedi==0.18.0
jsonschema==2.6.0
keyring==22.0.1
kiwisolver==1.3.1
lxml==4.6.2
matplotlib==3.3.4
MeaningCloud-python==2.0.0
moviepy==1.0.0
mtranslate==1.8
multiprocess==0.70.11.1
mutagen==1.40.0
networkx==2.5
numpy==1.20.1
oauth2==1.9.0.post1
oauth2client==4.1.2
oauthlib==3.1.0
olefile==0.46
opencv-python==4.5.1.48
openpyxl==2.5.4
pandas==1.2.2
parso==0.8.1
pathlib2==2.3.2
pathos==0.2.2.1
pdf2image==1.1.0
pdfminer.six==20181108
pefile==2019.4.18
pickleshare==0.7.5
Pillow==8.1.0
pip==21.0.1
pkginfo==1.7.0
playsound==1.2.2
plyer==2.0.0
pox==0.2.9
ppft==1.6.6.3
proglog==0.1.9
prompt-toolkit==3.0.16
protobuf==3.15.0
psutil==5.8.0
ptyprocess==0.6.0
pyactiveresource==2.2.2
pyasn1==0.4.8
pyasn1-modules==0.2.8
pycparser==2.20
pycryptodome==3.10.1
pydub==0.22.0
Pygments==2.8.0
pyinstaller==4.2
pyinstaller-hooks-contrib==2020.11
pyocr==0.5.2
pyOpenSSL==20.0.1
pyparsing==2.4.7
PyPDF2==1.26.0
pyperclip==1.6.0
pypng==0.0.18
pyreadline==2.1
PySocks==1.6.8
pytesseract==0.2.4
python-dateutil==2.7.3
python-docx==0.8.6
python-pptx==0.6.18
python-resize-image==1.1.11
pytz==2017.3
PyVirtualDisplay==0.2.1
PyWavelets==1.1.1
pywin32-ctypes==0.2.0
PyYAML==5.4.1
regex==2020.11.13
requests==2.25.1
requests-oauthlib==1.3.0
requests-toolbelt==0.9.1
rsa==4.7.1
scikit-image==0.18.1
scipy==1.6.1
selenium==3.141.0
setuptools==53.0.0
ShopifyAPI==8.2.0
six==1.12.0
sortedcontainers==2.3.0
soupsieve==2.2
SpeechRecognition==3.8.1
speedtest-cli==2.0.2
termcolor==1.1.0
text-to-image==0.0.5
textract==1.6.3
tifffile==2021.2.1
tqdm==4.57.0
traitlets==5.0.5
twine==1.11.0
tzlocal==1.5.1
uritemplate==3.0.1
urllib3==1.26.3
virtualenv==16.0.0
Wand==0.4.5
wcwidth==0.1.7
webcolors==1.7
webdriverdownloader==1.1.0.3
webencodings==0.5.1
xlrd==2.0.1
XlsxWriter==1.0.5
xmltodict==0.11.0
youtube-dl==2021.2.10
"""
for i in RQ.split("\n"):
  #os.system("pip install ")
  1
def p0():
  "pip install pyobjc ==5.0"

def p1():
  """
  #i am pretty sure this is for 3.9.0 `virtual1`
  # Hey! She  did do the --upgrade .  
  #pip install pip --upgrade
  #pip install setuptools --upgrade
  #pip install ipython
  #pip install ShopifyAPI #820
  #pip install pandas
  #pip install pyinstaller
  #pip install termcolor #1.1.0
  #"youtube-dl"
  #"requests"
  #pip install twine==1.11.0
  #pip install facebook-business==3.3.0
  #pip install facebookads==2.11.4
  """

def p2():
  """
  pip install bs4==0.0.1
  pip install multiprocess
  pip install Pillow

  pip install keyring

  pip install selenium==3.14.1
  pip install pyperclip==1.6.0
  pip install colorama==0.3.9
  pip install colored==1.3.93
  pip install colormath==3.0.0
  pip install numpy #1.20.1

  pip install imgkit==1.0.1
  pip install imgurpython==1.1.7
  pip install instapy==0.6.2
  pip install moviepy==1.0.0 # not fully required
  pip install playsound==1.2.2
  pip install mtranslate
  pip install gTTS==2.0.1 # not fully required
  pip install sounddevice==0.3.10
  pip install speedtest-cli==2.0.2

  pip install configparser==3.5.0
  pip install dicttoxml==1.7.4
  pip install dill --upgrade
  pip install emoji==0.5.1
  pip install fonttools==3.29.0
  pip install gspread==0.6.2
  pip install pydub==0.22.0
  pip install PyPDF2==1.26.0
  pip install python-dateutil==2.7.3
  pip install python-docx==0.8.6
  pip install python-pptx==0.6.5
  pip install python-resize-image==1.1.11


  pip install google-api-core==1.3.0
  pip install google-api-python-client==1.6.4
  pip install google-auth==1.5.1
  pip install google-auth-httplib2
  pip install google-auth-oauthlib==0.2.0
  pip install google-images-download==2.3.0
  pip install googleapis-common-protos==1.5.3
  """

def part1():
  """
  pip install oauth2==1.9.0.post1
  pip install oauth2client==4.1.2
  pip install oauthlib --upgrade # 3.1.0
  pip install pyocr==0.5.2
  pip install pytesseract==0.2.4
  pip install text-to-image==0.0.5
  pip install textract

  pip install mutagen==1.40.0
  pip install pathos==0.2.2.1
  pip install imageio --upgrade #2.9.0
  pip install virtualenv==16.0.0
  pip install matplotlib --upgrade #3.3.4
  pip install bitly-api==0.3


  pip install pdf2image==1.1.0
  pip install psutil --upgrade #5.8.0
  pip install ptyprocess==0.6.0
  pip install pyparsing --upgrade #2.4.7
  pip install pypng==0.0.18
  pip install PySocks==1.6.8
  pip install pytz==2017.3
  pip install PyVirtualDisplay==0.2.1

  pip install html5lib==1.0.1
  pip install httplib2==0.10.3
  pip install lxml --upgrade #4.6.2
  pip install opencv-python --upgrade #4.5.1.48
  pip install openpyxl==2.5.4
  pip install scikit-image --upgrade #0.18.1
  pip install urllib3 --upgrade #1.26.3
  pip install wcwidth==0.1.7
  pip install webcolors==1.7
  pip install xlrd --upgrade # 2.0.1
  pip install XlsxWriter==1.0.5
  pip install xmltodict==0.11.0

  pip install feedparser==5.2.1
  pip install gast==0.2.0
  pip install pathlib2==2.3.2
  pip install Wand==0.4.5
  """
p0()
p1()
p2()
part1()

import os
from time import sleep as sleep, sleep as zz, sleep as sp
from os import system, makedirs
from subprocess import Popen, getoutput, check_output
from facebook_business.adobjects.targetingsearch import TargetingSearch
from facebook_business.adobjects.targeting import Targeting
# from facebook_business.adobjects.reachestimate import ReachEstimate
from facebook_business.adobjects.customaudiencedatasource import CustomAudienceDataSource
from facebook_business.adobjects.customaudience import CustomAudience
from facebook_business.adobjects.campaign import Campaign
from facebook_business.adobjects.adset import AdSet
from facebook_business.adobjects.adpreview import AdPreview
from facebook_business.adobjects.adimage import AdImage
from facebook_business.adobjects.adcreativephotodata import AdCreativePhotoData
from facebook_business.adobjects.adcreativeobjectstoryspec import AdCreativeObjectStorySpec
from facebook_business.adobjects.adcreativelinkdata import AdCreativeLinkData
from facebook_business.adobjects.adcreative import AdCreative
from facebook_business.adobjects.adaccount import AdAccount
from facebook_business.adobjects.ad import Ad
from facebook_business import FacebookAdsApi
from datetime import timedelta, date, datetime
from collections import OrderedDict, Counter, defaultdict
import time
import sys
import subprocess
import shopify
import pyperclip
import pickle
try:import rumps
except:pass
import requests as requests, requests as r, requests as hickey
import re
import random
import os
import json
import csv
import copy
import string
g = lambda: globals()
rnd = round
ADSET_TESTING = False
Count = lambda l, x: l.count(x)
Database = "soda"
GLOBAL_ADD_PRODUCT_NOTIFICATION = False
GLOBAL_IMAGE_COMPARISON_TEST_SCORE = 0.9
GLOBAL_BROWSER_PAGEGOT_ZOOM_LEVEL = 2
GLOBAL_BROWSER_ELEMENT_WAIT_TIME = 3 # 7
GLOBAL_BROWSER_GET_PAGE_WAIT_TIME = 12 # 12 # requires 12
GLOBAL_BROWSER_URLWAIT_WAIT_TIME = 10 # 60
GLOBAL_BROWSER_PAGEGOT_WAIT_TIME = 3 # 5
GLOBAL_BROWSER_REQUIRE_SPEEDTEST = False
GLOBAL_BROWSER_STEP_SLEEPTIME = 0
GLOBAL_BROWSER_WINDOW_POSITION = [0, 0]
GLOBAL_BROWSER_WINDOW_SIZE = [1920, 600] # [1920, 1200]
GLOBAL_EMAILER_INITIALIZE_ERROR_MESSAGE = False
GLOBAL_FIREFOX_PROFILE_PATH = os.path.expanduser("~/Library/Application Support/Firefox/Profiles")
DOWNLOAD_VIDEO = False
WHILE_TRUE = 100000000
EMPTYSTRING = ""
Null = None
Exists = lambda address: os.path.exists(String(address))
Join = lambda *args: args[0].join(args[1])if(2==len(args))else(args[0].join(args[1:]))
Replacements = lambda s, *args, LOL={}: [setitem(LOL,"z",s),[setitem(LOL,"z",LOL["z"].replace(x,j)) for x,j in zip(args[0::2],args[1::2])] ,LOL["z"]][-1]
Split = lambda *args: (args[1].split(args[0]))if(len(args)==2)else(args[1].split(args[0],args[2]))
Strip = lambda s: s.strip()
Title = lambda s: s.title().replace("'S ","'s")
add = "globals().update(g.__dict__)"
midcmd = """process(lambda:[[OSA.log(str(tryreturn(lambda:eval(OSA.log("Func?"))(),ep=1)))]for i in(range(WHILE_TRUE)]))"""
subtract = "g.__dict__.update(globals())"
sys.setrecursionlimit(100000)


"""
if not os.path.exists(homepath("~/.matplotlib")):
  import imageio
  os.system("mkdir ~/.matplotlib && touch ~/.matplotlib/matplotlibrc && echo 'backend: agg' >> ~/.matplotlib/matplotlibrc")
  os.system("brew install ffmpeg &>/dev/null")
  os.system("brew install mysql &>/dev/null")
  imageio.plugins.ffmpeg.download()
  os.system("brew install mpv --with-libcaca &>/dev/null")
  os.system("asciiview")
  os.system("open ueiraweur.png")
  os.system("mpv fasdfs.jpg -vo caca")
"""

""" General-Utils """
def Copy(id,**kwargs):
  """
  This is used to copy an adset in Facebook Marketing. It is used to copy an adset when Facebook's ad set does not copy over.
  """
  # v3.3
  return [setitem(kwargs,"x",list(map(Integer,key("copied_id", [Shop()(All(Shop)[0].shop_abbreviation),json.loads(requests.post("https://graph.facebook.com/v3.3/%s/copies"%id, data={ "deep_copy":"true",
               "start_time":"%s 6:00:00 EST"%(Date().dt(0) if datetime.now().hour in [0,1,2] else Date().dt(1)),
               "status_option": "ACTIVE",
               "access_token": Shop.objects.all()[0].Facebook_Business_App_Token, }).content.decode())][1]["ad_object_ids"]))) ),
        [[AdSet(kwargs["x"][0]).remote_update(params={"status":"ACTIVE"}),Ad(kwargs["x"][1]).remote_update(params={"status":"ACTIVE"}),] if(2==len(kwargs["x"])) else [Campaign(kwargs["x"][0]).remote_update(params={"status":"ACTIVE"}),AdSet(kwargs["x"][1]).remote_update(params={"status":"ACTIVE"}),Ad(kwargs["x"][2]).remote_update(params={"status":"ACTIVE"}),] ],
        kwargs["x"],
  ][2]
def Exec(x,globals_,locals_):
  """
  This is a function used to execute a string.
  """
  globals().update(locals_)
  exec(x,globals())
def Float(x):
  """
  This is used to turn a string into a float.
  """
  return float(x)
def Integer(x):
  """
  This is used to turn a string into an integer.
  """
  return int(x)
def String(x):
  """
  This is used to turn 

  """
  return str(x)
def Ziff(*args):
  s, sep = args[0], args[1]
  maxsplit = -1 if len([i for i in args if type(i) == int])==0 else [i for i in args if type(i) == int][0]
  fncs = None if len([i for i in args if type(i) == list])==0 else [i for i in args if type(i) == list][0]
  y = s.split(sep,maxsplit)
  if fncs == None:
    return y
  else:
    y = [fncs[idx](i) for idx, i in enum(y)]
    return y
  """
  Ziff("x|y|z","|",[lambda i: i*2,lambda i: i*2,lambda i: i*2])
  Ziff("x|y|z","|")
  Ziff("x|y|z","|",1,[lambda i:i*2, lambda i: i*2])
  """
def add(x,y):
  globals()[x] += y
  return globals()[x]
def add_tag(x,y):
  if x == "" or x == None:
    x = y
  else:
    x += ", "
    x += y
  x = sorted(set(x.split(", ")))
  x = Join(", ", x)
  return x
  """
  add_tag("","Test")
  add_tag("Home","Test")
  add_tag("Home, Place","Test")
  """
def add_text_to_file(file, text, line_number):
  new_line_text = generate_one_random_number(5000)
  os.system("""sed -i "" -e '%ss/$/%s/' '%s'"""%(line_number,new_line_text,file))
  with open(file,"r") as f:
    new = f.read().replace(str(new_line_text),"\n"+text)
    open(file,"w").write(new)
def add_text_to_image(address,text,font=16,position=None):
  from PIL import Image, ImageDraw, ImageFont
  img = Image.open(address)
  d = ImageDraw.Draw(img)
  fnt = ImageFont.truetype("/Library/Fonts/Times New Roman.ttf", font)
  if not position:
    position = (5,5)
  d.text(position, text, font=fnt, fill=(0, 0, 0))
  img.save(address)
  return address
def added_list(*args):
  return flatten(args,1)
def address_backslash(address):
  return address.replace(" ", "\\ ")
def address_normalize(address):
  return(address)if(0==address.endswith("/"))else(address[:-1])
def and_list(*args):
  from types import MethodType,ModuleType,FunctionType
  latest = None
  for idx, arg in enum(args):
    if type(arg) == FunctionType or type(arg) == MethodType: arg = tryreturn(lambda:arg())
    else: arg = args[idx]
    latest = arg
    if arg == False or arg == 0 or arg == None or arg == [] or arg == () or arg == "" or arg == b"": return latest
  return latest
  """ ty moral_core on myfreecams """
def array_even(data, count):
  data2 = data
  for data in data2:
    while len(data)%count!=0:
      data.append("")
  return data2
def array_inner_even(data, delimiter="|"):
  for idx, i in enumerate(data):
    max_len = max(list(map(len, list(map(str, i)))))
    for idx2, j in enumerate(i):
      j = str(j)
      if(max_len!=len(j)):
        j = j + (delimiter*(max_len-len(j)))
        i[idx2]=j
  return data
def array_split(data, count, even=False):
  """
  array_split(lrange(45),10)
  [[0, 1, 2, 3, 4, 5, 6, 7, 8],
   [9, 10, 11, 12, 13, 14, 15, 16, 17],
   [18, 19, 20, 21, 22, 23, 24, 25, 26],
   [27, 28, 29, 30, 31, 32, 33, 34, 35],
   [36, 37, 38, 39, 40, 41, 42, 43, 44]]
  """
  import numpy as np
  data = list(data)
  if len(data) % count == 0:
    a = int(len(data)/count)
    b = list(range(0,len(data),a))+[len(data)]
    a_c = [data[i:i+a] for i in (b[:-1])]
    data = a_c
  else:
    return array_split1(data, count)
  data = list(map(list, data))
  return array_even(data) if(True==even) else(data)
def array_split1(data, count, even=False):
  """
  array_split1(lrange(45),10)
  [[0, 1, 2, 3, 4, 5, 6, 7, 8],
   [9, 10, 11, 12, 13, 14, 15, 16, 17],
   [18, 19, 20, 21, 22, 23, 24, 25, 26],
   [27, 28, 29, 30, 31, 32, 33, 34, 35],
   [36, 37, 38, 39, 40, 41, 42, 43, 44]]
  """
  import numpy as np
  data = np.array(data)
  data = np.array_split(data, (int(len(data)/count)+1))
  data = list(map(list, data))
  return array_even(data) if(True==even) else(data)
def array_split2(data, count):
  """
  array_split2(lrange(45),10)
  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
   [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],
   [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],
   [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
   [40, 41, 42, 43, 44]]
  """
  x = []
  y = len(data) % count
  z = []
  i = 0
  z.append(data[0:count]) if int(len(data)/count) == 0 else "`"
  for i in range(int(len(data)/count)):
    z.append(data[i*count:(i+1)*count])
  z.append(data[(i+1)*count:]) if ""!=data[(i+1)*count:] else "`"
  return z
def apilimitcall(x, sleeptime = 5):
  try:
    # [(x.__call__()())if(x.__name__=="<lambda>")else(x.__call__()),blueprint("success")][0]
    return [(x.__call__())if(x.__name__=="<lambda>")else(x.__call__()),blueprint("success")][0]
  except Exception as e:
    blueprint("error: %s; sleeping %s" % (e, sleeptime))
    [[blueprint("waiting: %s\r"%(i+1),end=""),time.sleep(1)] for i in range(sleeptime)]
    sleeptime = sleeptime + 5
    return apilimitcall(x, sleeptime = sleeptime)
  """
  x = lambda: (0/0) if random.random() > 0.5 else ()
  apilimitcall(x)
  """
def assert_dialog(lambda_function, notification):
  try:
    assert lambda_function()
  except:
    OSA.display_dialog(notification, text_prompt = False, buttons = ["OK"])
def bind(obj,name,method):
  from types import MethodType,ModuleType,FunctionType
  setattr(obj, name, MethodType(method,obj))
def bind2(obj, name):
  from types import MethodType,ModuleType,FunctionType
  setattr(obj, name, MethodType(globals()[name],obj))
def bind3(obj,func):
  from types import MethodType,ModuleType,FunctionType
  setattr(obj, func.__name__, MethodType(func,obj))if("<lambda>"!=func.__name__)else(setattr(obj, get_lambda_name(func), MethodType(func,obj)))
def bindm(x,**kwargs):
  [bind(x,a,b) for a,b in kwargs.items()]
  return x
  """
  bindm(AD(),test = lambda self: print(1)).test()
  """
def binded_update(x,y):
  lmap(lambda i: bind(x,*i), y.items())
  """
  x= AttrDict()
  y={"croak": lambda self:print("croaks"),"moof":lambda self:print("moofs")}
  binded_update(x,y)
  x.croak()
  x.moof()
  """
def brewlist(versions=False):
  """
  --versions, you get 1.20.1_4, not necessarily what's in brew search. seems that you tended to use latest version.
  """
  return getoutput("brew list").split("\n")if(versions==False)else(lmap(lambda x: x.replace(" ", "@"), getoutput("brew list --versions").split("\n")))
  """
  brewlist(versions = False)
  brewlist(versions = True)
  """
def brightness(lvl):
  OSA("System Events", ['brightness %s'%lvl])
def button_up(x=None,y=None,z=None,cork=None,headors=None):
  if cork: return [dict(zip(lmap(re_spaces,key('text',headors(x))),lmap(re_spaces,key('text',i)))) for i in array_split(cork(x),int(len(cork(x))/len(headors(x))) )]
  return dict(zip(lmap(lambda i: re_spaces(i), key("text",y(x))),lmap(lambda i: re_spaces(i), key("text",z(x)))))
def ceil(x):
  import math
  return math.ceil(x)
def check_option(option):
  option = option.title()
  if "Size" not in option and "Material" not in option and "Capacity" not in option and "Height" not in option and "Model" not in option:
    return True
  else:
    return False
def check_output(x):
  return or_list(lambda:subprocess.check_output(x,shell=True).decode()[:-1],lambda:subprocess.getoutput(x))
def cm_to_inch(s):
  if "cm" not  in s: return s
  try:
    cm_findings = re.findall(r" [0-9]*?cm", s)
    for cm_finding in cm_findings:
      x = cm_finding.replace("cm","")
      x = int(x)
      inch_measurement = x / 2.54
      inch_measurement = round(inch_measurement, 1)
      print("cm_to_inch finding: %scm to %sin" % (x, inch_measurement))
      s = s.replace(cm_finding, "%sin"%inch_measurement)
    print("[NOTE] function cm_to_inch --questionable use-- ")
  except Exception as e:
    print("cm to inches error: %s" % e)
    print(s)
  return s
def cm_to_inch2(s):
  if "cm" not in s: return s
  __original__ = s
  try:
    s = " " + s
    cm_findings = re.findall(r"( .*?cm)", s)
    for cm_finding in cm_findings:
      original = cm_finding
      cm_finding = cm_finding.replace("cm", "")
      cm_finding = cm_finding.split(" ")[-1]
      numbers = re.findall(r"[^0-9]*([0-9]*)",cm_finding)
      tmp = []
      print("tmp numbers: %s" % numbers)
      for i in numbers:
        try: tmp.append(int(i))
        except Exception as e: print("error: %s, %s" % (i,e))
      numbers = tmp
      print("numbers after tmp: %s" % numbers)
      numbers = [str(i) for i in numbers]
      the_inch_copy = str(original)
      for i in numbers:
        rounded = round((int(i)/2.54), 1)
        rounded = str(rounded)
        the_inch_copy = the_inch_copy.replace(i, rounded)
        print("cm: %s; rounded: %s" % (i, rounded))
      print("new 'original' : %s" % the_inch_copy)
      the_inch_copy = the_inch_copy.replace("cm", "in")
      s = s.replace(original, the_inch_copy)
      s = s.strip()
    print("===\n\n===== now showing comparison..")
    print("original: %s" % __original__)
    print("\n\n")
    print("s: %s" % s)
    print("\n\n")
    input("is this okay?: ")
    return s
  except Exception as e:
    print("erorrror : %s" % e)
def cm_to_inch3(s):
  s = Replacements(s, "2XL", "XXL", "3XL", "XXXL", "4XL", "XXXXL", "5XL", "XXXXXL", "6XL", "XXXXXXL")
  swizes = re.findall(r"[0-9]+",s)
  swizes = pool(Integer, swizes).result()
  swizes_ = pool(lambda i: wall((i/2.54)), swizes).result()
  s = Replacements(s, *list(map(str,sum(list(map(list,zip(swizes,swizes_))),[]))))
  return s
def cm_to_inch4(a):
  return a
  w = findall(a,"[\d\.]+cm")
  if w:
    x = findall(a,"[\d\.]+cm")
    assert len(x) == 1
    y = findall(a,1,"[\d\.]+cm")
    z = int(findall(y,1,"([\d\.]+)cm"))
    z = round(float(z)/2.54,2)
    z = str(z)
    if z.endswith(".0"):
      z = str(z).split(".")[0]
    replacement_string = "{}in".format(z)
    return re.sub("([\d\.]+cm)",replacement_string,a)
  else:
    return a
def compare_dict(a,b):
  x=""
  x+="{"
  x+="\n"
  for c,d in a.items():
    x+="    "
    x+="'%s': "%(c)
    if d != b[c]:
      x+="'%s' -> '%s',"%(d,b[c])
    else:
      x+="'%s'"%(d)
    x+="\n"
  x+="}"
  print(x)
  return x
  """
  compare_dict(
  {'ali_url': 'url',
  'fulfilled quantity': 0,
  'idx': 0,
  'shipping_address': 'Shipping Address, City, State, Zip Code',
  'sku': 'sku',
  'title': 'title',
  'total quantity': 0,
  'variant_title': ''},
  {'ali_url': 'url',
  'fulfilled quantity': 1,
  'idx': 0,
  'shipping_address': 'Shipping Address, City, State, Zip Code',
  'sku': 'sku',
  'title': 'title',
  'total quantity': 1,
  'variant_title': ''}
  )
  """
def copy_details():
  pyperclip.copy("dsthingasdf@protonmail.com asdfghjkASDFGHJK in the drafts folder")
def copypickles(x,y):
  import shutil
  shutil.copy(x,y)
def create_directories(*args):
  for idx,i in enum(args):
    os.makedirs("/".join(args[:idx+1]),exist_ok=True)
  """
  create_directories("a","b")
  rm("a")
  """
def create_pypi_package(file_in,readme_text,desc):
  basic_license = "Python. Free to use no attribution required."
  name = file_in.replace(".py","")
  version = "0.1.0"
  description = desc
  author = "pleasefeedme"
  author_email = "myfakeemail@gmail.com"
  license = basic_license
  packages = [file_in.replace(".py","")]
  install_requires = []
  import os
  os.makedirs(name)
  os.chdir(name)
  open("LICENSE.txt","w").write(basic_license)
  open("README.md","w").write(readme_text)
  open("setup.py","w").write(
  """from setuptools import setup
setup(
name='%s',
version='%s',
description='%s',
author='%s',
author_email='%s',
license='%s',
packages=['%s'],
install_requires=%s)
"""%(name,version,description,author,author_email,basic_license,name,install_requires))
  os.makedirs(name)
  os.chdir(name)
  import shutil
  shutil.copy("../../%s"%(file_in),"./")
  os.chdir("../")
  # didn't work
def csed(r="class",s="class"):
  greenprint("the use of ' is not supported")
  s = s.replace('"','\\"').replace("'","\\'")
  blueprint(re.findall(r, open(__file__).read(), flags=re.MULTILINE))
  os.system("""sed -i '' -e 's/%s/%s/g' %s"""%(r,s,__file__))
def csv_table_to_html(table):
  data = '<table border="1">'
  data +=  '<tbody>'
  numerical_row = 0
  for row in table:
    data += "<tr>"
    numerical_col = 0
    for cell in row:
      data+= ("""<th style="text-align: center; color: #000000;">%s</th>"""%cell) if (numerical_row == 0\
        or numerical_col == 0) else ("""<td style="text-align: center;">%s</td>"""%cell)
      numerical_col += 1
    numerical_row += 1



    data += "</tr>"
  data += "</tbody>"
  data += "</table>"
  return data
def csv_table_to_png(bux):
  address = str(homepath("~/tavern/tavern/soda/dls/%s.csv"%random.randrange(99999999))).zfill(len("99999999"))
  csv.writer(open(address,"w")).writerows(bux)
  import pandas as pd
  df = pd.read_csv(address)
  os.remove(address)
  htmTable = df.to_html()
  load = re.sub(r"[\n\t]","",htmTable)

  import cv2
  reds = html_to_png(load)
  q = cv2.imread(reds)
  quinces = []
  for x in range(q.shape[1]):
    y = q[0:,x]
    print(x, y.shape, set(y.flatten()))
    if set(y.flatten()) == {255}:
      quinces.append(x)


  quinces = list(reversed(quinces))
  zealous = None
  for greater, lesser in zip(quinces[0:], quinces[1:]):
    if (greater-lesser) != 1:
      zealous = greater+10
      break
  redprint(zealous)
  v = q[0:,0:zealous]

  address = str(homepath("~/tavern/tavern/soda/dls/%s.png"%random.randrange(9999999999))).zfill(len("9999999999"))
  cv2.imwrite(address, v)
  impreview(address)
  return address
def date_of_birth_drawer(date_of_birth, m_num = False):
  date_of_birth = String(date_of_birth)
  date_of_birth = date_of_birth.zfill(8)
  m, d, y = ["January","February","March","April","May","June","July","August","September","October","November","December"].__getitem__(Integer(date_of_birth[:2])-1)if(m_num==False)else(date_of_birth[0:2]), date_of_birth[2:4], date_of_birth[4:]
  return m, d, y
def dataframe_to_dictlist(dataframe):
  dictlist = []
  headers = list(dataframe)
  data = dataframe.to_dict()
  data_len = len(data[headers[0]])
  for idx in range(data_len):
    e = {}
    for header in headers:
      e[header] = data[header][idx]
    dictlist.append(e)
  return dictlist
def datetime_math(x, **kwargs):
  return x + timedelta(**kwargs)
def dbsed(s="",r=""):
  csed(r, s)
def deepcopy(x):
  return copy.deepcopy(x)
def delete_adset(adset_id):
  Del(Get(Adset,adset_id=adset_id))
def delete_adsets():
  a_shop()
  for i in All(Adset):
    if AdSet(i.adset_id).remote_read(fields=["status"])["status"] == "ARCHIVED":
      print("Deleting one adset")
      Del(i)
      lmap(Del,Filter(Adsetinsight,adset_id=i.adset_id))
def delete_data():
  lmap(Del,All(AceInTheHole))
  lmap(Del,All(AceInTheHoleType))
  lmap(Del,All(AceInTheHoleTypeTag))
  lmap(Del,All(Adset))
  lmap(Del,All(Aliexpress_Dispute))
  lmap(Del,All(Aliexpressorder))
  lmap(Del,All(Aliexpressorder_event))
  lmap(Del,All(ApprovedTransaction))
  lmap(Del,All(Facebookadaccountspend))
  lmap(Del,All(GhostProduct))
  lmap(Del,All(GhostProductUpdate))
  lmap(Del,All(Keep_Exchange))
  lmap(Del,All(Lineitem))
  lmap(Del,All(New_Email))
  lmap(Del,All(Order))
  lmap(Del,All(Payment))
  lmap(Del,All(Payout))
  lmap(Del,All(Product))
  lmap(Del,All(ProductTalk))
  lmap(Del,All(ReOrder))
  lmap(Del,All(Settlement))
  lmap(Del,All(Soup))
  lmap(Del,All(Video))
  lmap(Del,All(TertiaryAction))
  lmap(Del,All(ProductsFeed))
  lmap(Del,All(LineitemsFeed))
def delete_last():
  Del(All(RandomGeneratedWords).n(-1))
def dictfromkeys(headers, default_value, ordered=False):
  x = dict(zip(headers, [default_value for header in headers]))if(ordered==False)else(OrderedDict(zip(headers, [default_value for header in headers])))
  return x
def dictrecurse(attrdict):
  for k,v in attrdict.items():
    if type(v) == AttrDict:
      attrdict[k] = dictrecurse(attrdict[k])
  return dict(attrdict)
def dictupdate(x,**kwargs):
  x.update(**kwargs)
  return x
def decimal_re(x):
  return Integer("".join(re.findall(r"\d+", x)))
def delete_keys(x,*args):
  for i in args:
    tryprocess(lambda: x.__delitem__(i))
  return x
  """
  a = {"a":"b","c":"d",}
  delete_keys(a,"a","c")
  """
def dictionarymeaning(x):
  from nltk.corpus import wordnet
  y = sudby(lambda i:i.name().split(".")[0]==x,wordnet.synsets(x))
  z = ifelseget(lambda:len(y) == 0,lambda:or_list(lambda:"Definition using Mirriam Webster. %s"%(re_substitute(random.choice(SOUPY(requests.get("https://www.merriam-webster.com/dictionary/%s"%(x)).text,"span","class","dtText")).text.split(": ")[1],["\s+"," "])),lambda:"No definition found for %s"%(x)),lambda:random.choice(y).definition())
  return z
def dictjoin(*args,**kwargs):
  x = {}
  for i in args:
    x.update(i)
  return x
def dicttoxml(x):
  import dicttoxml
def diff(x,y):
  x_, y_ = x, y
  x, y = lmap(lambda i:open(i).read().split("\n"),[x,y])
  diffs = []
  for i in x:
    if i in y:
      y.pop(y.index(i))
    else:
      diffs.append(i)
  x, y = lmap(lambda i:open(i).read().split("\n"),[x_,y_])
  for i in y:
    if i in x:
      x.pop(x.index(i))
    else:
      diffs.append(i)if(i not in diffs) else ()
  print(len(diffs))
  return diffs
def dip(x, y=1):
  for i in range(y):
    try:
      x = sum(x,[])
    except Exception as e:
      x = x
  return x
def dictxml(x,tcer=False):
  if tcer == False:
    import dicttoxml
    y = dicttoxml.dicttoxml(x)
    #y = y[0:39] + y[45:len(y)-7]
    return y
  else:
    import xmltodict
    y = xmltodict.parse(x)
    return y
def dkey(x):
  return list(x.items())[0][0]
  """
  dkey({"a":"b"})
  """
def dl(x):
  return Images().download(x)
def draw_circular_pay_chart():
  length = 45
  x = np.full(tuple(([length]*2)+[3]),[255,255,255])
  coordinates = []
  y = 0
  for i in range(length):
    coordinates.append((y,length-y-1))
    y += 1
  y = 0
  for i in range(length):
    coordinates.append((y,-(length-y)+1))
    y += 1
  y = 0
  for i in range(length):
    coordinates.append((-y,length-y-1))
    y += 1
  y = 0
  for i in range(length):
    coordinates.append((-y,-(length-y)+1))
    y += 1
  for i in coordinates:
    x[i[0]][i[1]] = np.array([0,0,0])
def droll(x):
  assert x() == True
def dt(x=0, strf='%Y-%m-%d'):
  return (datetime.now() + timedelta(x)).strftime(strf)
def dune(*args):
  x, y = args[0], args[1]
  x = [y[idx](i) for idx,i in enum(x)]
  return x
  """
  dune("a, 2, 3".split(", "), [lambda i: i*2, lambda i:int(i)+2, lambda i:int(i)+5])

  """
def dvalue(x):
  return list(x.items())[0][1]
  """
  dvalue({"a":"b"})
  """
def emoji_viewer():
  os.system("""osascript -e 'tell application "System Events" to key code 49 using {control down, command down}' """)
def enum(x):
  return enumerate(x)
def eye_exam():
  print("visit:  https://www.personaleyes.com.au/online-eye-test/index.php")
  print(" 1m away, 6 questions are asked  ")
def extract_emojis(str):
  import emoji
  return ''.join(c for c in str if c in emoji.UNICODE_EMOJI)
def filter(objects, *args, **kwargs):
  from django.db.models.query_utils import Q
  objects = [AttrDict(i) if type(i)==dict else i for i in objects]
  data = []
  for i in objects:
    to_append = 1
    for attr, value in kwargs.items():
      attr_arg = None
      if "__" not in attr:
        attr_arg = "equals"
      elif "__" in attr and attr.split("__")[1] == "contains":
        attr_arg = "contains"
      elif "__" in attr and attr.split("__")[1] == "icontains":
        attr_arg = "icontains"
      elif "__" in attr and attr.split("__")[1] == "range":
        attr_arg = "range"

      attr=((attr)if("__" not in attr)else(attr.split("__")[0]))

      if attr_arg == "equals" and not (getattr(i,attr) == value):
        to_append = 0
      if attr_arg == "contains" and not (value in getattr(i,attr)):
        to_append = 0
      if attr_arg == "icontains" and not (value.lower() in getattr(i,attr).lower()):
        to_append = 0
      if attr_arg == "range" and not (getattr(i,attr) >= value[0] and getattr(i,attr) <= value[1]):
        to_append = 0

      
    if(1==to_append):
      data.append(i)

  #data = []
  #args = [~Q(x=5),~Q(y=5)]
  #args = [~Q(x=5,y=5),]
  #data = lmap(AD,[{"x":5,"y":5},{"x":5,"y":4},{"x":4,"y":5},{"x":4,"y":4}])
  #new = []
  #for i in data:
  #  to_append = True
  #  for j in args:
  #    for k, l  in j.children:
  #      print(i, j, k, l)
  #      if getattr(i, k) == l:
  #        to_append = False
  #        print(getattr(i,k), l)
  #  if to_append == True:
  #    print(i)
  #    new.append(i)
  
  #new = []
  #for i in data:
  #  to_append = [True for i in range(len(args))]
  #  idx = 0
  #  for j in args:
  #    for k, l  in j.children:
  #      print(i, j, k, l)
  #      if getattr(i, k) == l:
  #        to_append[idx] = False
  #        print(getattr(i,k), l)
  #    idx += 1
  #  if set(to_append) == {True}:
  #    print(i)
  #    new.append(i)
  if args:
    new = []
    for i in data:
      to_append = [True for i in range(len(args))]
      idx = 0
      for j in args:
        all_signifiers = [True for i in range(len(j.children))]
        idx_2 = 0
        for k, l  in j.children:

          attr_arg = None
          if "__" not in k:
            attr_arg = "equals"
          elif "__" in k and k.split("__")[1] == "contains":
            attr_arg = "contains"
          elif "__" in k and k.split("__")[1] == "icontains":
            attr_arg = "icontains"
          elif "__" in k and k.split("__")[1] == "range":
            attr_arg = "range"

          attr=((k)if("__" not in k)else(k.split("__")[0]))
          value = l

          if attr_arg == "equals" and (getattr(i,attr) == value):
            all_signifiers[idx_2] = False
          if attr_arg == "contains" and (value in getattr(i,attr)):
            all_signifiers[idx_2] = False
          if attr_arg == "icontains" and (value.lower() in getattr(i,attr).lower()):
            all_signifiers[idx_2] = False
          if attr_arg == "range" and (getattr(i,attr) >= value[0] and getattr(i,attr) <= value[1]):
            all_signifiers[idx_2] = False

          #if getattr(i, k) == l:
          #  #to_append[idx] = False
          #  all_signifiers[idx_2] = False
          #  print(getattr(i,k), l)
          idx_2 += 1
        if set(all_signifiers) == {False}:
          to_append[idx] = False
        idx += 1
      if set(to_append) == {True}:
        new.append(i)

    data = new
  return data
  """
  assert filter([{"a":5,"b":2},{"a":4,"b":3}],~Q(a=5)) == [{'a': 4, 'b': 3}]
  assert filter([{"a":5,"b":2},{"a":4,"b":3}],~Q(a=5),~Q(b=3)) == []
  assert filter([{"a":5,"b":2},{"a":4,"b":3}],~Q(a=5),~Q(b=2)) == [{'a': 4, 'b': 3}]
  assert filter([{"a":5,"b":2},{"a":4,"b":3},{"a":5,"b":5}],~Q(a=5)) == [{'a': 4, 'b': 3}]
  assert filter([{"a":5,"b":2},{"a":4,"b":3},{"a":5,"b":5}],~Q(a=5,b=5)) == [{'a': 5, 'b': 2}, {'a': 4, 'b': 3}]
  """
def filter_in(a, b, mode="show_not_there"):
  assert len(oset(a)) == len(a)
  assert len(oset(b)) == len(b)
  if mode == "show_not_there":
    x = []
    for i in a:
      if i in b:
        x.append(i)
    y = []
    for i in b:
      if i not in x:
        y.append(i)
    return y
  elif mode == "show_there":
    x = []
    for i in a:
      if i in b:
        x.append(i)
    return x
  """
  filter_in([1,2,3],[1,2,3,4],"show_not_there")
  filter_in([1,2,3],[1,2,3,4],"show_there")
  filter_in([1,2,3,5],[1,2,3,4,5,6],"show_not_there")
  """
def findall(s, r, x=None):
  return (re.findall(r, s))if(len(listminus(locals().values(),None))==2)else(re.findall(x, s)[0])if(len(listminus(locals().values(),[[]]))==3)else()
def flatten(x, y=1):
  for i in range(y):
    try:
      x = sum(x,[])
    except Exception as e:
      x = x
  return x
def floor(x):
  import math; return math.floor(x)
def flt(x):
  return float(x)
def font_preview(address):
  from PIL import Image, ImageDraw, ImageFont
   
  img = Image.new('RGB', (1800, 540), color = (255, 255, 255))
   
  fnt = ImageFont.truetype(address, 45)
  d = ImageDraw.Draw(img)
  d.text((10,10), "[{}] Hello world. Untitled `404`.liquid ~`!@#$%^&*()_+-=[]\\|;':<>,.?/Seven Six Five Four".format(address.split("/")[-1]), font=fnt, fill=(0, 0, 0))
   
  img.save('pil_text_font.png')
  impreview('pil_text_font.png')
  os.system('rm pil_text_font.png')
def free_plus_ship(x):
  CH().free_plus_ship(x)
def fuckmachine(key):
  return globe("key")
def generate_keylogger():
  times, keys = [], []
  file = open(homepath("~/hole/hole/keylogger/logfile.log")).read().split("\n")[:-1]
  file = sudby(lambda i: i.split(" ",1)[1][0] != "[", file)
  for i in file:
    time, key = i.split(" ",1)
    times.append(time)
    keys.append(key)
  time, letters, current_load, on = None, "", "", False
  current_loads = []
  for i, j in zip(times,keys):
    letters = letters + j
    time = i
    if letters.endswith("ss-"):
      on = True
    if on == True:
      current_load = current_load + j
    if letters.endswith("-ee"):
      on = False
      time = i
      current_load = current_load[2:-3]
      print(current_load)
      current_loads.append([time, current_load])
      time = datetime.fromtimestamp(int(time))
      tp(lambda:Save(Note,note=current_load,time=time))
      letters = ""
      current_load = ""
  # if os.path.getsize(homepath("~/hole/hole/keylogger/logfile.log")) > 7432790:
  #   x = open(homepath("~/hole/hole/keylogger/logfile.log"),"r").readlines()
  #   num_lines = int(len(x)/2)
  #   y = x[:num_lines]
  #   open(homepath("~/hole/hole/keylogger/logfile.log"),"w").write("".join(y))
  time.sleep(60)
  ifdo(lambda:random.randrange(1,61) == 60,lambda:os.system("killall keylogger"))
  generate_keylogger()
  # return current_loads
def generate_one_alphabetical_string(size=10):
  import string
  w = (" ".join(string.ascii_letters)).split(" ")
  x = ""
  for i in range(size):
    x += random.sample(w,1)[0]
  return x
def generate_one_alphanumeric_string(size=10):
  import string
  w = (" ".join(string.ascii_letters)).split(" ") + list(map(str,list(range(10))))
  x = ""
  for i in range(size):
    x += random.sample(w,1)[0]
  return x
def generate_one_random_number(digits):
  x = ""
  while True:
    x = x + str(random.choice(list(range(10))))
    if len(x) == digits:
      return x
def generator(x):
  return (i for i in x)
def getattrs(attrs,x):
  return [getattr(x,i) for i in attrs]
def getitems(items,x):
  return [getitem(x,i) for i in items]
def getpass(x = None):
  from getpass import getpass
  return getpass()if(x==None)else(getpass(x))
def getsafarisource():
  blueprint("Safari -> Advanced -> Show develop menu ; Develop -> Allow JavaScript from Apple Events")
  x = subprocess.check_output("""osascript -e 'tell application "Safari" to set my_html to source of document 1'""",shell=True).decode("utf-8",errors="backslashreplace")
  return x
def getsafariurl():
  x = subprocess.getoutput("""osascript -e 'tell application "Safari" to set the_url to URL of current tab of window 1'""")
  return x
def getuser():
  import getpass
  return getpass.getuser()
def getwindowcount(x):
  return int(subprocess.getoutput("""osascript -e 'tell application "%s" to get (count of windows)'"""%x))
def get_active_shops():
  return Filter(Shop,Active=True)
def get_chmod_statuses():
  for i in os.listdir("/Applications"):
    status = subprocess.getoutput("stat -f '%OLp' '/Applications/{}'".format(i))
    print("%s: %s" % (i,status))
  for i in os.listdir("/Applications/Utilities"):
    status = subprocess.getoutput("stat -f '%OLp' '/Applications/Utilities/{}'".format(i))
    print("%s: %s" % (i,status))
def get_dircount(path=None):
  if path is None: path = os.path.expanduser('~/')+'Downloads'
  return len(os.listdir(path))
def get_feed():
  return get_user().remote_read(fields=["feed"]).export_all_data()["feed"]["data"]
def get_in_between_idx(new,x):
  chosen_idx = None
  for idx,i in enum(x[:-1]):
    if new > i and new < x[idx+1]:
      print(i,new,x[idx+1])
      chosen_idx = idx
  return chosen_idx
def get_one_address(directory,ext):
  return os.path.join(directory,"x")+(".%s"%(ext))
def get_random_address(directory):
  print("getting random address")
  class x(str):
    __init__ = lambda self, s: super().__init__()
    png = lambda self: self.__add__(".png")
    jpg = lambda self: self.__add__(".jpg")
    jpeg = lambda self: self.__add__(".jpeg")
    csv = lambda self: self.__add__(".csv")
    mp4 = lambda self: self.__add__(".mp4")
    txt = lambda self: self.__add__(".txt")
    txt = lambda self: self.__add__(".txt")
    txt = lambda self: self.__add__(".txt")
    txt = lambda self: self.__add__(".txt")
  c = x(generate_one_random_number(10))
  if c in lmap(lambda i: ".".join(i.split(".")[:-1]), os.listdir(directory)):
    return get_random_address(directory)
  c = x(os.path.join(directory,c))
  return c
def get_random_address2(directory,ext):
  x = random.randrange(10000000)
  return os.path.join(directory,str(x))+".%s"%(ext)
def get_random_from_lists(*args):
  firsts = args[:int(len(args)/2)]
  x = []
  x.append(firsts[0])
  for idx,i in enum(firsts[1:]):
    x.append(round(i+x[-1],2))
  new = random.random()
  x.insert(0,0)
  """
  while True:
    new = random.random()
    for idx,i in enum(x[:-1]):
      if new > i and new < x[idx+1]:
        print(i,new,x[idx+1])
        time.sleep(1)
  """
  choices = args[int(len(args)/2):]
  chosen_idx = get_in_between_idx(new,x)
  chosen_choices = choices[chosen_idx]
  return random.choice(chosen_choices)
def get_random_word():
  from nltk.corpus import words
  x = words.words()
  word = random.choice(x)
  return word
def get_lambda_name(l):
  return get_source(l).split("=")[0].strip()
def get_latest_download(path=None,x=0):
  import glob
  if path is None: path = os.path.expanduser('~/')+'Downloads'
  return sorted(glob.glob('%s/*' % path), key=os.path.getmtime, reverse=True)[x]
def get_product_url(x):
  url = "https://%s/admin/products/%s"%(Get(Shop,shop_abbreviation="rom").Domain_Name,x.id)
  return url
def get_size_of(x):
  return sys.getsizeof(x)
def get_source(x):
  from inspect import getsource
  return getsource(x)
def gethickey():
  session = requests.session()
  session.original_get = session.get
  def get(self,*args,**params):
    tp(lambda:MelaniaTrump().semlo().deflux().flux().jagged().didnt_you_deeptimeslotAffiliateMarketing().hiTo().thawk().symphony().isEnglishYet().IsLoL().Buy().Sell().Cuy().affiliation().greenpowderbomb().marketing().slice().fullarrest().cardiaclobotomy().pipesolarplexus().accumulateADDITIONALdiscontinuancies().slowlyoffsetroots___().wherewasit__().takefullpercentage().drivebyAndGiveTinnitusForAdditionalPercentage().InsertMurderererererererCCComPleXXX().affyliatemarketing())
    url = list(args).pop()
    url = re_substitute(url,["(?m)^https://",""])
    self.original_get(url)
  bind3(session,get)
  tp(lambda:MelaniaTrump().IsNowMelaniaTrump().RemoveTrump().Melania().ReplaceTrump().Trumpet().Crimp().Purchase().Toss().Rename().Ban().Diet())
  tp(lambda:MelaniaTrump().killherself().nobodyExists())
  tp(lambda:MelaniaTrump().Trash().IssueReinventionOfGameAndGirlsPerspectiveasswell())
  return session
def getitem(*args):
  return or_list(lambda:args[0].get(args[1],or_list(lambda:args[2],None)),lambda:or_list(lambda:args[0][args[1]],lambda:args[2]),lambda:(0/0))
def gl(x,a):
  globals()[a] = x
  """
  gl("5","test")
  print(gx("test"))
  """
def gleb(x,y=1):
  return (random.sample(x,1)[0])if(y==1)else(random.sample(x,y))
def globalise(x,a,**like_a_is_the_key):
  globals()[a] = x
def globalosis(x):
  globals().update(x)
def globalpacker(func,variable):
  if variable not in globals():
    globalise(func(),variable)
  return globals()[variable]
  """
  notentry(lambda:1,"b")
  assert globe("b") == 1
  """
def globe(x,*args):
  return (globals().get(x,*args))if(args)else(globals().get(x))
def go_over(x,y):
  x(y)
  return y
  """
  go_over(lambda i: print(i.a), AD(a=5))
  """
def got_ali_url():
  existing = lmap(lambda i: re.findall("\d+\.html",i.ali_url)[0],Filter(Product,ali_url__icontains="aliexpress.com"))
  urls_2 = lmap(lambda i: re.findall("\d+.html",i.url)[0],All(AddProduct))
  now = re.findall("\d+\.html",get_first_chrome_url())[0]
  if now in existing or now in urls_2:
    print("index: %s"%(shuffled(existing+urls_2).index(now)))
    print("now: %s" % now)
    return True
def gx(x,*args):
  return (globals().get(x,*args))if(args)else(globals().get(x))
def homepath(x):
  import os
  return os.path.expanduser("~%s"%(x.split("~")[1]))
def html_test(x):
  open("test.html","w").write(str(x))
  system("/Applications/Firefox\ 46.app/Contents/MacOS/firefox-bin -p sele test.html &>/dev/null&")
def html_to_png(io):
  address_1 = homepath("~/tavern/tavern/soda/dls/._%s_tmp.html"%(random.randrange(10000000,99999999)))
  address_2 = homepath("~/tavern/tavern/soda/dls/._%s_out.png"%(random.randrange(10000000,99999999)))
  try:
    if os.path.exists(io):
      io = io
    else:
      try:
        try:open(address_1,"w",encoding="utf-8").write(io)
        except:open(address_1,"wb",encoding="utf-8").write(io)
      except Exception as v:
        v
      io = address_1
    try:
      os.system("""/usr/local/bin/wkhtmltoimage --disable-smart-width --javascript-delay 1000 --encoding utf-8 --load-error-handling ignore --load-media-error-handling ignore "%s" "%s" """%(address_1,address_2))
    except Exception as w:
      w
    tryprocess(os.remove,address_1)
    return address_2
  except Exception as e:
    e = str(e)
    OSA.log("MIGHTY_ERROR: %s"%e)
    return "MIGHTY ERROR"
def ifdo(x,y):
  if x():
    y()
  """
  ifdo(lambda: 1==1, lambda: print(5))
  ifdo(lambda: 1==2, lambda: print(5))
  ifdo(lambda: [], lambda: print(5))
  ifdo(lambda: True, lambda: print(5))
  """
def ifelsedo(x,y,z):
  if tryreturn(lambda:x()):
    return y()
  else:
    return z()
  """
  ifelsedo(lambda: 1==1, lambda: print(5), lambda: print(4))
  ifelsedo(lambda: 1==2, lambda: print(5), lambda: print(4))
  ifelsedo(lambda: [], lambda: print(5), lambda: print(4))
  ifelsedo(lambda: True, lambda: print(5), lambda: print(4))
  """
def ifelseget(x,y,z):
  if tryreturn(lambda:x()):
    return y()
  else:
    return z()
  """
  ifelseget(lambda: 1==1, lambda: print(5), lambda: print(4))
  ifelseget(lambda: 1==2, lambda: print(5), lambda: print(4))
  ifelseget(lambda: [], lambda: print(5), lambda: print(4))
  ifelseget(lambda: True, lambda: print(5), lambda: print(4))
  """
def ifelselist(*args):
  for i,j in zip(args[0::2],args[1::2]):
    if i():
      return j()
def ifget(x,y):
  if tryreturn(lambda:x()):
    return y()
def im2arr(fn):
  import numpy as np
  from PIL import Image
  return np.array(Image.open(fn))
def images_to_column_xlsx(images,column="A",image_size=100,**stars):
  import openpyxl
  wb = ifelseget(lambda:stars["wb"],lambda:stars["wb"],lambda:openpyxl.Workbook())
  ws = wb.worksheets[0]
  ws.column_dimensions['A'].width = (image_size/8)
  s = 1
  for i in images:
    img = openpyxl.drawing.image.Image(i)
    img.anchor = '%s%s'%(column,s)
    print('%s%s'%(column,s))
    ws.add_image(img)
    ws.row_dimensions[s].height = (image_size*0.75)
    s += 1
  wb.save('out.xlsx')
  return wb
def impreview(address, speed=0.3):
  if not os.path.exists(str(address)):
    import cv2
    os.makedirs(homepath("~/tavern/tavern/soda/dls"),exist_ok=True)
    a = (homepath("~/tavern/tavern/soda/dls/%s.png"%(generate_one_alphanumeric_string(18))))
    cv2.imwrite(a, address)
    address = a

  from PIL import Image
  if os.path.isdir(address):
    [[Image.open(os.path.join(address,fn)).show(), time.sleep(speed)] for fn in sorted(os.listdir(address))]
  else:
    Image.open(address).show()
def index(x, y):
  try:return list(x).index(y)
  except:return -1
def indicepick(x,y):
  return [y[i] for i in x]
  """
  indicepick([1,2,3], [1,2,3,4,5,6])
  """
def intcls(x,**kwargs):
  return type("a",(int,),kwargs)(x)
  """
  r = intcls(123,print = lambda self:print(self))
  r.print()
  """
def intify(x):
  return [int(i) if tp(lambda:int(i))==1 else i for i in x]
def itemcopy(a,b,f):
  redprint("Temporary Guide For Cloning: Keyse, GeheadN+(A),(B),(F);A^!TAKES FROM B, ITER<F>.")
  for zelish in f:
    rhondousel = getattr(b, zelish, None)
    setattr(a, zelish, rhondousel)
  a.save()
  return a
  """ ::: Tests ::: """
  """
  a = AttrDict()
  b = All(Product)[0]
  fields = ['size_chart', 'vendor', 'id', 'item_type']
  itemcopy(a,f,fields)
  """
def iterindex(xy, lox):
  x = []
  for i in xy:
    if i in lox:
      x.append(lox.index(i))
  return x
  """
  xy = [0,1,2,3,4,5,6]
  lox = [0,1,2,3,4,5,6,7,8,0,1,2,3]
  print(iterindex(xy, lox))
  xy = [0,1,2,3,4,5,6]
  lox = [7]
  print(iterindex(xy, lox))
  """
def key(dictlist, key):
  if type(dictlist) is str or type(dictlist) is int:
    dictlist, key = key, dictlist
  try: return [getattr(i, key) for i in list(dictlist)]
  except: return [i[key] for i in list(dictlist)]
def keyby(x,y):
  return or_list(lambda:[i for i in y if x(i)],lambda:[i for i in y if x(*i)],[])
def keycall(key, dictlist, *args, **kwargs):
  try: return [getattr(i, key)(*args, **kwargs) for i in list(dictlist)]
  except: return [i[key](*args, **kwargs) for i in list(dictlist)]
def keycontains(key, contains, dictlist):
  try: return [i for i in list(data) if contains in i[key]]
  except: return [i for i in list(data) if contains in getattr(i, key)]
def keyequals(key, equals, data):
  try: return [i for i in list(data) if i[key] == equals]
  except: return [i for i in list(data) if getattr(i, key) == equals]
def keyicontains(key, icontains, dictlist):
  try: return [i for i in list(data) if icontains.lower() in i[key].lower()]
  except: return [i for i in list(data) if icontains.lower() in getattr(i, key).lower()]
def keymulti(keys, dictlist):
  try: return [[getattr(a,b) for b in keys] for a in list(dictlist)]
  except: return [[getitem(a,b) for b in keys] for a in list(dictlist)]
def keynicontains(key, nicontains, data, ):
  try: return [i for i in list(data) if nicontains.lower() not in i[key].lower()]
  except: return [i for i in list(data) if nicontains.lower() not in getattr(i, key).lower()]
def keyncontains(key, ncontains, data, ):
  try: return [i for i in list(data) if ncontains not in i[key]]
  except: return [i for i in list(data) if ncontains not in getattr(i, key)]
def keynequals(key, nequals, data, ):
  try: return [i for i in list(data) if i[key] != nequals]
  except: return [i for i in list(data) if getattr(i, key) != nequals]
def keynotequals(key, notequals, data, ):
  try: return [i for i in list(data) if i[key] != notequals]
  except: return [i for i in list(data) if getattr(i, key) != notequals]
def keysort(key, dictlist, tcer=True):
  import operator
  if type(key) is not list:
    key = [key]
  try: return sorted(list(dictlist), key=operator.itemgetter(*key), reverse=tcer)
  except: return sorted(list(dictlist), key=operator.attrgetter(*key), reverse=tcer)
def keysort_multi(columns, items, tcer=False):
  from operator import itemgetter, attrgetter
  from functools import cmp_to_key
  comparers = None
  if tryprocess(lambda:items[0].get(columns[0])): comparers = [((itemgetter(col[1:].strip()), -1) if col.startswith('-') else (itemgetter(col.strip()), 1)) for col in columns]
  else: comparers = [((attrgetter(col[1:].strip()), -1) if col.startswith('-') else (attrgetter(col.strip()), 1)) for col in columns]
  def comparer(left, right):
    def cmp(a, b):
      if a == None and b == None: return 0
      if a == None and b != None: return 1        
      if a != None and b == None: return -1
      elif a != None and b != None: return (a > b) - (a < b)
    comparer_iter = ( cmp(fn(left), fn(right)) * mult for fn, mult in comparers)
    return next((result for result in comparer_iter if result), 0)
  return sorted(list(items), key=cmp_to_key(comparer), reverse=tcer)
def kodo(func, *args, ep=0, error = None, **kwargs):
  try:
    return func(*args, **kwargs)
  except Exception as e:
    OSA.log(str(or_list(error,e)))if(1==ep or error)else(1)
    return 0
  (0/0)
def ldict(x=None):
  return OrderedDict(x)if(x)else(OrderedDict())
def linspace(start, stop, precision, endpoint=False):
  start, stop = round(float(start),2), round(float(stop),2)
  roundpoint = len(str(precision).split(".")[-1])if(".") in str(precision) else 0
  d = []
  x = start
  while True:
    d.append(x)
    x = x + precision
    x = round(x, roundpoint)
    if x == stop:
      break
  if endpoint == True:
    d.append(x)
  return d
  """
  linspace(0.76, 1.01, 0.01)
  """
def list_and(*args):
  from types import MethodType,ModuleType,FunctionType
  latest = None
  for idx, arg in enum(args):
    if type(arg) == FunctionType or type(arg) == MethodType: arg = tryreturn(lambda:arg())
    else: arg = args[idx]
    latest = arg
    if arg == False or arg == 0 or arg == None or arg == [] or arg == () or arg == "" or arg == b"": return latest
  return latest
def listadd(*args):
  x = []
  for i in args:
    if "append" not in dir(i):
      i = [i]
    x.extend(i)
  return x
  """
  listadd([1,2,3],[1,2,3],["a","b","c"],[[1,2,3]])
  """
def listinsert(x,l1,l2):
  return l2[:x] + l1 + l2[x:]
  """
  assert listinsert(1,[4,5,6],[1,2,3]) == [1,4,5,6,2,3,]

  """
def listmap(func, *args, **kwargs):
  from functools import partial
  return list(map( partial(func, **kwargs), *args ))
def listminus(x,y=[],minus_once = False, **kwargs):
  # puts [] into a list.
  if "append" not in dir(y):
    y = [y]
  if minus_once == False:
    return [i for i in x if i not in y and kwargs.get("method",lambda i:True)(i)]
  else:
    for i in y:
      if i not in x:
        continue
      else:
        R = x.index(i)
        x.pop(R)
    return x
  """
  x = [2,1,2,1]
  y = [1]
  assert [2, 2] == listminus(x, y, minus_once = False)
  assert [2, 2, 1] == listminus(x, y, minus_once = True)
  """
def listplus(x,y,z):
  l = len(x)
  for i in range(y-l):
    x.append(z)
  return x
  '''
  listplus([1,2,3],5,None)
  '''
def listreplace(io, *args, **kwargs):
  return [setitem(kwargs,"z",io),[setitem(kwargs,"z",[i if i != x else j for i in kwargs["z"]]) for x,j in zip(args[0::2],args[1::2])] ,kwargs["z"]][-1]
def listshift(start=None,x=None):
  a = x[start]
  x.__delitem__(start)
  x = [a] + x
  return x
  """
  listshift(2,[1,2,3,4,5])
  """
def lmap(func, *args, **kwargs):
  from functools import partial
  arg_lens = oset([len(i) for i in args])
  assert len(arg_lens) == 1
  if arg_lens[0] == 0:
    return []
  # x = or_list(lambda:list(map( partial(func, **kwargs), *args )),
  #                 lambda:list(map( partial(func, **kwargs), *[[i[idx] for i in args[0]] for idx in list(range(oset(list(map(len,args[0])))[0]))]) ),
  #                 lambda: 0/0)
  x = or_list(lambda:list(map( partial(func, **kwargs), *args )),
                  lambda:list(map( partial(func, **kwargs), *transpose(args[0]) )),
                  lambda:0/0)
  ifdo(lambda:x==0,lambda:exec("assert False"))
  return x
  """
  assert lmap(lambda i,j: i+j, [(1,1),(2,2),(3,3)]) == [2, 4, 6]
  assert lmap(lambda i: i+1, [1,2]) == [2, 3]
  """
def lrange(*args):
  return list(range(args[0]))if(len(args)==1)else(list(range(args[0],args[1])))
def lset(x):
  return list(set(x))
def loadpickles(*args,**kws):
  ifdo(lambda:os.path.exists(args[0])==False,lambda:savepickles(kws['default'],args[0]) )
  return pickle.load(open(args[0],'rb'))
def login_prompt():
  OSA().log("Please log in. Then press OK. ʕ•́ᴥ•̀ʔ",tp=False)
def lsorted(x,**kwargs):
  return sorted(x,key=kwargs.get("key",None),reverse=kwargs.get("tcer",False))
  """
  lsorted([5,2,3],tcer=True)
  lsorted([5,2,3],y=lambda i: i)
  lsorted([5,2,3],y=lambda i: i,tcer=True)
  """
def make_archive(address):
  import shutil
  import zipfile
  rm("%s.zip"%address)if(1==os.path.exists("%s.zip"%address))else(0)
  shutil.make_archive(address, 'zip', address) if os.path.isdir(address) else zipfile.ZipFile("%s.zip"%address, mode="w").write(address)
  return "%s.zip"%address
def methodsort(x, method, tcer=False):
  return sorted(x, key=method, reverse=tcer)
def microsecondize(a,b):
  c = (b-a)
  d = c.seconds
  v = c.microseconds / 1000000
  f = (d)+(v)
  return f
def mig(*args,**kwargs):
  SQL().migrate(*args,**kwargs)
def mkchdir(address):
  os.makedirs(address, exist_ok=True)
  os.chdir(address)
def msort(x, method, tcer=False):
  return sorted(x, key=method, reverse=tcer)
def multi_input(printout):
  distinct_print("====multi_input====:\n%s"%printout)
  x = ""
  while True:
    y = input("")
    if y[-2:] == "\Q":
      y = y[:-2]
    if y=="q":
      return x
    x += y
    x += "\n"
def multiprocessing_process(target):
  import multiprocessing
  R = multiprocessing.Process(target = target)
  R.start()
  return R
def mysql_args_and_kwargs_to_string(*args, **kwargs):
  import django
  stuff = []
  for i in args:
    if type(i) == django.db.models.query_utils.Q:
      x = i.children
      for idx_0, a in enum(x):
        x[idx_0] = list(a)

        for idx,b in enum(x[idx_0]):
          if b == True:
            x[idx_0][idx] = "true"
          elif b == False:
            x[idx_0][idx] = "false"

      for j in x:
        if "__" in j[0]:
          if "__icontains" in j[0]:
            stuff.append("%s not like '%%%s%%'"%(j[0].split("__")[0],j[0].split("__")[1]))
        else:
          stuff.append("%s!='%s'"%(j[0],j[1]))


  for a,b in kwargs.items():
    if a == True: a = "true"
    if a == False: a = "false"
    if "__" in a:
      if "__icontains" in a:
        stuff.append("%s like '%%%s%%'"%(a.split("__")[0],b))
    else:
      stuff.append("%s='%s'"%(a,b))


  stuff = "where" + " " + " and ".join(stuff)
  return stuff
def mysql_delete(x):
  """ This will work only if the id is an AutoField on any model with multiple unique fields. """
  #t = ('/usr/local/bin/mysql -u root --password=w24uyLMGU2TWdkBdUKMWySQiAcfdjB1A soda -e """delete from %s_%s where id="%s";"""&>/dev/null ' % (Database, x._meta.verbose_name.replace(" ",""), x.id))
  t = ("""/usr/local/bin/mysql -u root --password=w24uyLMGU2TWdkBdUKMWySQiAcfdjB1A soda -e "delete from %s_%s where id='%s';"&>/dev/null """ % (Database, x._meta.verbose_name.replace(" ",""), x.id))
  #redprint(t)
  os.system(t)
def mysql_exec(w="select count(*) from soda_timedtask;"):
  x = subprocess.getoutput("""mysql -u root --password=w24uyLMGU2TWdkBdUKMWySQiAcfdjB1A soda -e "%s" """ % ((w+";")if(not w.endswith(";"))else(w))).split("\n")[1:]
  x = [i.split("\t") for i in x]
  headers = x.pop(0)
  y = [dict(zip(headers, i)) for i in x]
  return y
def ner_tagger(text):
  from nltk.tag import StanfordNERTagger
  from nltk.tokenize import word_tokenize

  Binarydata().export("NER")
  
  st = StanfordNERTagger('NER/english.all.3class.distsim.crf.ser.gz',
               'NER/stanford-ner.jar',
               encoding='utf-8')

  tokenized_text = word_tokenize(text)
  classified_text = st.tag(tokenized_text)

  print(classified_text)

  x = []
  for i in classified_text:
    if i[1]=='PERSON':
      print(i)
      x.append(i[0])

  import shutil
  shutil.rmtree("NER")

  return x
def new_dict(x,fields=[]):
  return AD({a:b for a,b in x.items() if a in fields})
def notentry(a,b):
  if b not in globals():
    globalise(a(),b)
  return globals()[b]
  """
  notentry(lambda:1,"b")
  assert globe("b") == 1
  """
def notexists(x):
  if x != False and x != 0 and x != None and x != [] and x != () and x != "" and x != b"":
    return False
  else:
    return True
  """
  notexists("")
  """
def nps_chat_reader():
  from nltk.corpus import nps_chat
  for i in nps_chat.xml_posts():
    print(i.text)
    x = input("")
    if x == "quit":
      break
  return
def openr(address):
  return open(address)
def openw(address):
  return open(address, "w")
def openrb(address):
  return open(address, "rb")
def openwb(address):
  return open(address, "wb")
def ordered_json_dumps(x):
  return json.dumps(OrderedDict([[a,str(x[a])] for a in list(sorted(x.keys())) if not a.startswith("_")]), indent=4)
def or_list(*args):
  from types import MethodType,ModuleType,FunctionType
  for idx, arg in enum(args):
    if type(arg) == FunctionType or type(arg) == MethodType:
      arg = tryreturn(lambda:arg())
      if arg != False and arg != 0 and arg != None and arg != [] and arg != () and arg != "" and arg != b"":
        return arg
    if arg != False and arg != 0 and arg != None and arg != [] and arg != () and arg != "" and arg != b"":
      return args[idx]
  return (tryreturn(lambda:args[-1]()))if(type(args[-1])==FunctionType or type(args[-1])==MethodType)else(args[-1])
  """
  or_list(tryreturn(lambda: 3/1), "a", None, 0,)
  or_list(1,lambda:print(1),lambda:print(1))
  or_list(lambda:print(1),1,lambda:print(1))
  or_list(lambda:print(1),1)
  or_list(0,ExecutableText().export("hello"),1)
  or_list(0,lambda x=1: x)
  """
def oset(x, **kwargs):
  y = []
  for i in x:
    if i not in y:
      if i not in kwargs.get("minus",[]):
        if kwargs.get("method",lambda i: True)(i) == True:
          y.append(i)
  return y
  """
  assert oset([3,2,3,3,2]) == [3, 2]
  assert oset([1,2,1,]) == [1,2]
  assert oset([1,2,1,],method=lambda i: i!=1) == [2]
  assert oset([1,2,1,],method=lambda i: i!=1,minus=[2]) == []
  assert oset([1,2,1,],method=lambda i: i!=1,minus=[3]) == [2]
  """
def osremove(*args,**kwargs):
  os.remove(*args,**kwargs)
def overlay_sound_files(sound_files):
  from pydub import AudioSegment
  sound_file = AudioSegment.from_file(sound_files[0])
  for i in sound_files[1:]:
    new_sound_file = AudioSegment.from_file(i)
    sound_file = sound_file.overlay(new_sound_file)
  sound_file.export(os.path.expanduser("~/Downloads/export.wav"), format='wav')
  return os.path.expanduser("~/Downloads/export.wav")
def pathjoin(*args):
  return os.path.join(*args)
def plusUpdate(x, **kwargs):
  return [[setattr(x,a,getattr(x,a)+b) for a,b in kwargs.items()],x.save(),x][2]
def poll(o, x, step=8, poll_forever=True):
  import polling
  polling.poll(o, step=step, poll_forever=poll_forever)
  x()
  poll(o, x, step=step, poll_forever=poll_forever)
def pool(f, *args, nodes=12, **kwargs):
  # [ERRORFUL] if you do pool(ss.assert_connection_speed, "20MB"), it should have minimum_speed = , otherwise you're saying that "20MB" is the list which you should be pooling.
  results = type("list", (list,), dict(result=lambda self: [keycall("join",self),keycall("result",self)][1]))
  results = results()
  if args and len(args[0]) == 0: return results

  #@results() returns "processing" list. does not fine.
  #@unless i make results keycall join.
  #results = []
  from inspect import getfullargspec
  fullargspec = getfullargspec(f)
  """
  defaults_len = tryreturn(len, fullargspec.defaults)
  accountable_args = listminus(fullargspec.args, (["self"] + list(kwargs)), minus_once = True)
  accountable_args_len = len(accountable_args) - defaults_len
  if accountable_args_len == 0:
    accountable_args_len = accountable_args_len - len(args)
  """
  argcount = f.__code__.co_argcount
  if "self" in fullargspec.args:
    argcount = argcount - 1
  accountable_args_len = argcount -  (len(kwargs))
  # [TESTING] magentaprint(accountable_args_len)

  zilleum = 0
  while True:
    print(keycall("result",results))
    print(accountable_args_len)
    if keycall("result",results).count("processing") < nodes:
      if accountable_args_len != 0:
        #@ruined the args from before calling pool. results.append(process(f,*[a.pop(0) for a in args], **kwargs))
        results.append(process(f,*[a[zilleum] for a in args], **kwargs))
        zilleum+=1
      elif accountable_args_len == 0:
        results.append(process(f, **kwargs))
        zilleum+=1 # umm... this is the counter for the num times def r()'s r runs, which must equal args[0]'s len which is ie, lrange(2), so thats how many times you want function r with 0 arguments to run which is a list of a range of 2 which is twice
        #def hi():
        #@works. hi(**{})
    else:
      time.sleep(0.0001)
    #if len(args[0]) == 0:
    print('args', args)
    print('zilleum', zilleum)
    if not args:
      r = results[0]
      r.join_saved = r.join
      r.result_saved = r.result
      def result(self):
        self.join()
        return self.result_saved()
      is_running = lambda self: self.isAlive()
      bind3(r, result)
      bind3(r, is_running)
      return r
    elif zilleum == len(args[0]):
      # halts for say, args[0] is 11, nodes is 2.
      return results
    assert 1 == len(set(list(map(len, args))))
    # copyright 2021 Adam
def popen(cmd):
  return Popen(cmd.split(' '),shell=False,stdin=None, stdout=None, stderr=None, close_fds=True)
def popwhere(key, keyequals, dictlist):
  [  setitem(g(),"indexes",[])  ,  [g()["indexes"].append(idx)if(keyequals==  (getattr(i,key) if("~~~"!=getattr(i,key,"~~~")) else(i.get(key))  )) else(None)    for idx, i in enum(dictlist)]  ]
  assert len(g()["indexes"]) == 1
  dictlist.pop(g()["indexes"].pop())
  return dictlist
  """
  class Test():
    def __init__(self):
      self.a = "b"
      self.c = "d"
  class Test2():
    def __init__(self):
      self.a = "c"
      self.c = "b"
  dictlist = [Test(),Test2()]
  popwhere("a","b",dictlist)

  class Test():
    def __init__(self):
      self.a = "b"
      self.c = "d"
  class Test2():
    def __init__(self):
      self.a = "b"
      self.c = "b"
  dictlist = [Test(),Test2()]
  try:popwhere("a","b",dictlist)
  except:print("expected error")
  """
def process(func, *args, start_process=1, **kwargs):
  import multiprocessing
  process_id = str(generate_one_random_number(20))
  while process_id in globals():
    process_id = str(generate_one_random_number(20))
  globals()[process_id] = "processing"
  def new_func(func, *args, **kwargs):
    globals()[process_id] = func(*args,**kwargs)
  def strand(func, *args, start_process=1, **kwargs):
    from threading import Thread
    t = Thread(target=func, args=args, kwargs=kwargs)
    t.start()if(start_process==1)else(1)
    return t
  x = strand(new_func, *tuple([func] + list(args)), start_process=start_process, **kwargs)
  x.globals = globals
  x.process_id = process_id
  def result(self):
    return self.globals()[self.process_id]
  bind3(x, result)
  def tmp(self):
    while self.is_alive() == True:
      time.sleep(1)
    return self.globals()[self.process_id]
  bind3(x, tmp)
  return x
def process_(func, *args, start_process=1, **kwargs):
  import multiprocessing
  p = multiprocessing.Process(target=func,*args,**kwargs)
  if(1==start_process):p.start()
  return p
def productcsv(sku_image_dict=None,shop=None,images=None,options=None,variants=None,title=None,product_type=None,tags=None,description=None,):
  {'Body (HTML)': 'Cute but funny',
   'Handle': 'feel-the-force-decor',
   'Image Alt Text': '',
   'Image Position': '1',
   'Image Src': '',
   'Option1 Name': 'Color',
   'Option1 Value': 'Black',
   'Option2 Name': '',
   'Option2 Value': '',
   'Option3 Name': '',
   'Option3 Value': '',
   'Tags': '1, test',
   'Title': 'Feel The Force Decor',
   'Type': 'test',
   'Variant Compare At Price': '14.95',
   'Variant Grams': '0',
   'Variant Image': '',
   'Variant Inventory Qty': '1494',
   'Variant Price': '9.95',
   'Variant SKU': "['sku-1-193']",
   'Vendor': 'Epic Life Shop'}


  {
   'Gift Card': 'false', #
   'Google Shopping / AdWords Grouping': '', #
   'Google Shopping / AdWords Labels': '', #
   'Google Shopping / Age Group': '', #
   'Google Shopping / Condition': '', #
   'Google Shopping / Custom Label 0': '', #
   'Google Shopping / Custom Label 1': '', #
   'Google Shopping / Custom Label 2': '', #
   'Google Shopping / Custom Label 3': '', #
   'Google Shopping / Custom Label 4': '', #
   'Google Shopping / Custom Product': '', #
   'Google Shopping / Gender': '', #
   'Google Shopping / Google Product Category': '', #
   'Google Shopping / MPN': '', #
   'Published': 'true', #
   'SEO Description': '', #
   'SEO Title': '', #
   'Variant Barcode': '', #
   'Variant Fulfillment Service': 'manual', #
   'Variant Inventory Policy': 'deny', #
   'Variant Inventory Tracker': 'shopify', #
   'Variant Requires Shipping': 'true', #
   'Variant Tax Code': '', #
   'Variant Taxable': 'true', #
   'Variant Weight Unit': 'kg', # 
   }


  """Handle               Option1 Value   Option2 Value   Option3 Value Variant SKU Variant Grams Variant Inventory Tracker Variant Inventory Qty Variant Inventory Policy  Variant Fulfillment Service Variant Price Variant Compare At Price  Variant Requires Shipping Variant Taxable   Image Src Image Position 

  Handle  Title Body (HTML) Vendor  Type  Tags  Published Option1 Name    Option2 Name    Option3 Name                          Image Src                                     Variant Image"""

  headers = \
  ['Handle',
   'Title',
   'Body (HTML)',
   'Vendor',
   'Type',
   'Tags',
   'Published',
   'Option1 Name',
   'Option1 Value',
   'Option2 Name',
   'Option2 Value',
   'Option3 Name',
   'Option3 Value',
   'Variant SKU',
   'Variant Grams',
   'Variant Inventory Tracker',
   'Variant Inventory Qty',
   'Variant Inventory Policy',
   'Variant Fulfillment Service',
   'Variant Price',
   'Variant Compare At Price',
   'Variant Requires Shipping',
   'Variant Taxable',
   'Variant Barcode',
   'Image Src',
   'Image Position',
   'Image Alt Text',
   'Gift Card',
   'SEO Title',
   'SEO Description',
   'Google Shopping / Google Product Category',
   'Google Shopping / Gender',
   'Google Shopping / Age Group',
   'Google Shopping / MPN',
   'Google Shopping / AdWords Grouping',
   'Google Shopping / AdWords Labels',
   'Google Shopping / Condition',
   'Google Shopping / Custom Product',
   'Google Shopping / Custom Label 0',
   'Google Shopping / Custom Label 1',
   'Google Shopping / Custom Label 2',
   'Google Shopping / Custom Label 3',
   'Google Shopping / Custom Label 4',
   'Variant Image',
   'Variant Weight Unit',
   'Variant Tax Code']

  x = dictfromkeys(headers, default_value = "")

  x.update({"Option1 Name": getitem(key("name",options), 0, ""), "Option2 Name": getitem(key("name",options), 1, ""), "Option3 Name": getitem(key("name",options), 2, ""), "Title": title, "Body (HTML)": description, "Vendor": "", "Type": product_type, "Tags":"", "Published":"true", "Image Src":images[0]["src"], "Gift Card": "false", "Variant Image": images[0]["src"]})
  image_position = 0
  variants_ = []
  for idx, variant in enumerate(variants):
    variant_ = dictfromkeys(headers, default_value="")
    if idx==0: variant_.update(x)
    variant_["Handle"] = "".join(re.findall(r"[0-9a-zA-Z ]",title)).lower().replace(" ","-").replace("--","-").replace("--","-")
    variant_["Option1 Value"] = variant.get("option1", "")
    variant_["Option2 Value"] = variant.get("option2", "")
    variant_["Option3 Value"] = variant.get("option3", "")
    variant_["Variant SKU"] = variant.get("sku", "")
    variant_["Variant Grams"] = variant.get("weight", "")*100
    variant_["Variant Weight Unit"] = "kg"
    variant_["Variant Inventory Tracker"] = variant["inventory_management"]
    variant_["Variant Inventory Qty"] = variant["inventory_quantity"]
    variant_["Variant Inventory Policy"] = variant["inventory_policy"]
    variant_["Variant Fulfillment Service"] = "manual"
    variant_["Variant Price"] = variant["price"]
    variant_["Variant Compare At Price"] = variant["compare_at_price"]
    variant_["Variant Requires Shipping"] = "true"
    variant_["Variant Taxable"] = "true"
    variant_["Image Src"] = images[ sku_image_dict[variant.get("sku")] ]["src"] if sku_image_dict!={} else images[0]["src"]
    image_position += 1
    variant_["Image Position"] = image_position
    variant_["Variant Image"] = images[ sku_image_dict[variant.get("sku")] ]["src"] if sku_image_dict!={} else ""
    variants_.append(variant_)

  if len(images) > len(variants_):
    for idx, image in enumerate(images[ len(variants_): ]):
      variant_ = dictfromkeys(headers, default_value="")
      variant_["Handle"] = "".join(re.findall(r"[0-9a-zA-Z ]",title)).lower().replace(" ","-").replace("--","-").replace("--","-")
      variant_["Image Src"] = image["src"]
      image_position += 1
      variant_["Image Position"] = image_position
      variants_.append(variant_)




  fn = homepath("~/tavern/tavern/bag/products_%s.csv" % (generate_one_random_number(10)))
  CSV().DictWriteWithHeaders(fn, variants_, headers = headers)
def productgost(x):
  GhostProduct().productgost(x)
def random_dot_float():
  return random.random()
def randomised(x):
  random.shuffle(x)
  return x
def rangelen(x):
  return range(len(x))
def raw_input(x=None):
  return eval(input(""))if(None==x)else(eval(input(x)))
def re_findall_overlaps(regex_string, x):
  groups_regex = '(?=(' + regex_string + '))'
  print("groups regex: %s" % groups_regex)
  matches = re.finditer(groups_regex,x)
  results = [match.group(1) for match in matches]
  print("%s matches" % len(results))
  return results
def re_found_function(x,r,method):
  if findall(x,r):
    return method(x)
  else:
    return x
def re_spaces(x):
  return re_substitute(x,["\s+"," "]).strip()
def re_substitute(x,y,*y_is_a_two_list,**kwargs):
  return re.sub(y[0],y[1],x,**kwargs)
  """
  re_substitute("AbAb",["^Ab","c"],flags=re.M)
  """
def re_substitute_function(x,r,method):
  found = findall(x,r)
  if len(found) == 0: print("No found matches")
  print(x)
  random_strings = []
  multiplier = 10000
  for i in lrange(len(found)):
    random_strings.append("<<<<<%s>>>>>"%(random.choice(string.ascii_letters)*multiplier))
    multiplier = multiplier * 10
  for i,j in zip(found,random_strings): x = x.replace(i,j)
  y = lmap(lambda i:str(method(i)),found)
  for i,j in tcer(list(zip(random_strings,y))): x = x.replace(i,j)
  print(x)
  return x
def readministrate():
  import getpass
  os.system("sudo -passwd admin")
  os.system("sudo dscl . -append /Groups/admin GroupMembership %s"%(getpass.getuser()))
def rfloat(r1 = 0.2, r2 = 0.7):
  return random.uniform(r1, r2)
def rm(address):
  subprocess.getoutput("""rm -rf "%s" """%address)
def safarijs(x):
  blueprint("Safari -> Advanced -> Show develop menu ; Develop -> Allow JavaScript from Apple Events")
  x = 'tell application "Safari" to do JavaScript "%s" in current tab of window 1'%x
  fn = ".%s.scpt" % str(generate_one_random_number(10))
  blueprint(fn)
  open(fn, "w").write(x)
  r = subprocess.getoutput("osascript %s"%fn)
  os.remove(fn)
  return r
  """
  x = "window.location.href = 'https://google.com'"
  safarijs(x)
  """
def save_default_aceintheholedata():
  exec('def x(y,    ):\n  from decimal import Decimal\n  import datetime\n  from dateutil.tz import tzoffset\n  globals().update(locals())\n  fields = key("name",  y._meta.fields)\n  blueprint("Save(%s,   "%(type(y).__name__),   end="")\n  for i in fields:\n    z = getattr(y,  i)\n    r = None\n    import datetime\n    if type(z) == str:\n      r = \'%s = """%s""",   \'%(i,    z)\n    elif type(z) == datetime.datetime:\n      r = \'%s = datetime.datetime(%s,   %s,   %s,   %s,   %s,   %s,   %s),   \'%(i,   z.year,   z.month,   z.day,   z.hour,   z.minute,   z.second,   z.microsecond)\n    elif type(z) == datetime.date:\n      r = \'%s = datetime.date(%s,   %s,   %s),   \'%(i,   z.year,   z.month,   z.day,   )\n    else:\n      r = "%s = %s,   "%(i,   z)\n    blueprint(r.replace("\\n",    "\\\\n"),  end="")\n  blueprint(")",  end="")\n  blueprint("\\n")',globals())
  import datetime
  from decimal import Decimal
  Save(AceInTheHole,   id = 408,   account = """Chase""",   date = datetime.datetime(2019,   4,   29),   amount = 10.0,   type = """BUSINESS_PAYMENT_GATEWAY_DEPOSITS""",   tag = """STRIPE""",   description = """STRIPE""",   )
  Save(AceInTheHoleType,   id = 18,   name = """BUSINESS_OTHER_CONTRACT_LABOR""",   )
  Save(AceInTheHoleType,   id = 19,   name = """BUSINESS_OTHER_HOSTING""",   )
  Save(AceInTheHoleType,   id = 20,   name = """BUSINESS_OTHER_SUBSCRIPTIONS""",   )
  Save(AceInTheHoleType,   id = 14,   name = """BUSINESS_PAYMENT_GATEWAY_DEPOSITS""",   )
  Save(AceInTheHoleType,   id = 15,   name = """BUSINESS_PAYMENT_GATEWAY_WITHDRAWALS""",   )
  Save(AceInTheHoleType,   id = 17,   name = """BUSINESS_PURCHASING_ADS""",   )
  Save(AceInTheHoleType,   id = 16,   name = """BUSINESS_PURCHASING_PRODUCTS""",   )
  Save(AceInTheHoleType,   id = 22,   name = """PERSONAL_FOOD""",   )
  Save(AceInTheHoleType,   id = 21,   name = """PERSONAL_NOT_FOOD""",   )
  Save(AceInTheHoleTypeTag,   id = 12,   type = """BUSINESS_PURCHASING_PRODUCTS""",   tag = """Ali""",   sign = """negative""",   )
  Save(AceInTheHoleTypeTag,   id = 13,   type = """BUSINESS_PAYMENT_GATEWAY_DEPOSITS""",   tag = """Stripe Deposit""",   sign = """positive""",   )
  Save(AceInTheHoleTypeTag,   id = 29,   type = """PERSONAL_NOT_FOOD""",   tag = """METROCARD""",   sign = """negative""",   )
  Save(AceInTheHoleTypeTag,   id = 30,   type = """PERSONAL_NOT_FOOD""",   tag = """ATM FEE""",   sign = """negative""",   )
def savepickles(*args,**kws):
  pickle.dump([i for i in args if type(i)!=str][0],open([i for i in args if type(i)==str][0],'wb'))
  ifdo(lambda:kws.get('copypickles'),lambda:savepickles(args[0],kws['copypickles']))
  return args[0]
def saveobj(x):
  import _pickle
  import pickle
  import dill
  return dill.dumps(x)
def sch(x):
  from spellchecker import SpellChecker as sch
  sch = sch()

  a = list(set(re.findall("[\w']+",x)))
  b = pool(lambda i: sch.correction(i), a).result()
  e = dict(zip(a,b))
  c = [i for i in a if i not in b]
  distinct_print(c)
  for i in c:
    while True:
      print("+1",i)
      d=tryreturn(lambda:next(re.finditer("""[^\w'](%s)(?:[^\w']|$)"""%(i),x)))
      if d:
        blueprint(x)
        x = "".join([x[:d.start()],x[d.start():d.start()+1],e[i],(x[d.end()-1:d.end()])if(x[d.end()-1:d.end()]==" ")else(" "),x[d.end():]])
        greenprint(x)
      else:
        break
  x = x.upper()
  return x
  """
  x = '''hello,
  ths is col
  hllo.
  bye\tyes4 123
  '''
  """
def screenshot(address=None):
  if address == None:
    os.makedirs(homepath("~/tavern/tavern/soda/dls"), exist_ok = True)
    address = homepath("~/tavern/tavern/soda/dls/%s.png"%(random.randrange(9999999999999)))
    magentaprint("generated address: %s" % address)
  greenprint("saving to address: %s" % address)
  os.system("""screencapture -x "{}" """.format(address))
  return address
def sedremoveline(file,line_numbers):
  os.system("""sed -i "" -e "%sd" '%s'"""%((",".join(lmap(str,line_numbers))),file))
  """
  os.system('''echo -e "line1\nline2\nline3\nx" > infile''')
  sedremoveline("infile",[1,2])
  assert open("infile").read() == 'line3\nx\n'
  rm("infile")
  """
def setadd(x,y):
  if y not in x:
    x.add(y)
  return x
def setattrs(x, *args, **kwargs):
  from types import MethodType,ModuleType,FunctionType
  for a,b in kwargs.items():
    setattr(x,a,b)
  for a,b in zip(args[0::2],args[1::2]):
    if type(b) == FunctionType or type(b) == MethodType:
      b = tryreturn(lambda: b())
    setattr(x,a,b)
  """
  a = AD()
  setattrs(a,"x",2,"y",3,"z",4)
  """
def setfrom(x, *args):
  return [i(x) for i in args]
  """
  setfrom(1, lambda i: i, lambda i: i)
  """
def setitem(x, k, v):
  x[k] = v
def setitems(x,*args):
  for i,j in zip(args[0::2],args[1::2]):
    x[i] = j
def show_in_list(a,b):
  a = copy.deepcopy(a)
  b = copy.deepcopy(b)
  x = []
  for i in a:
    if i in b:
      x.append(i)
      b.__delitem__(b.index(i))
  return x
  """
  assert show_in_list([1,2,3,4],[1,2]) == [1,2]
  assert show_in_list([10,10],[10]) == [10]
  assert show_in_list([10,10],[10,11]) == [10]
  """
def show_overhead(a, b):
  # assert len(oset(a)) == len(a)
  # assert len(oset(b)) == len(b)
  a = copy.deepcopy(a)
  b = copy.deepcopy(b)
  x = []
  for i in a:
    if i not in b:
      x.append(i)
    elif i in b:
      b.__delitem__(b.index(i))
  return x
  """
  show_overhead([1,2,3,4],[1,2])
  show_overhead([10,10],[10])
  """
def shuffled(x):
  if type(x) is str:
    x = list(x)
    random.shuffle(x)
    return x
  else:
    x = list(x)
    random.shuffle(x)
    return x
  return x
def shutil_move(a, b):
  import shutil
  shutil.move(a, b)
def similar(a, b):
  from difflib import SequenceMatcher    
  return SequenceMatcher(None, a, b).ratio()
def slank(key,dict_):
  return dict_.pop(key)
def slow_url(x):
  return x.split("?")[0]
def sorted_list_matching(x,y):
  z = lmap(lambda i:None,x)
  for i in x:
    index = y.index(i)
    z[index] = i
  return z
  """
  a = [2,1,3]
  b = [1,2,3]
  sorted_list_matching(a,b)
  """
def sorted_set(x):
  return list(sorted(list(set(x))))
def soupy(soup,x=None,y=None,z=None):
  import bs4
  if type(soup) != bs4.BeautifulSoup: soup = BeautifulSoup(soup)
  if x==None: return soup
  return(soup.findAll(x)if(None==y==z)else(soup.findAll(x,attrs={y:z})))
def sql_get_multiple_primary_keys(x):
  with open(__file__,"r") as f:
    return [i.strip().split("=")[0].strip() for i in re.findall(r"(?s)(class %s\(Worksheet\):.*?)class"%x.__name__,f.read())[0].strip().split("\n") if((-1!=i.find("AutoField()"))or(-1!=i.find("unique=True"))or(-1!=i.find("primary_key=True")) )]
def sqltroubleshoot():
  os.system("""rm /usr/local/etc/my.cnf && echo "Removed mysql cnf file." sleep 5 && echo "Stopping mysql." && sleep 5 && brew services stop mysql & sleep 5 && mysqld & sleep 5 && echo "Running py2_file again to set up mysql cnf file." && sleep 5 && cd ~/tavern/tavern/soda && /usr/bin/python -B -c "from py2_file import *; Setter_Upper().m15__17_initiate_install_mysql__and__create_database_soda()" ;""")
def strand(func, *args, **kwargs):
  from threading import Thread
  t = Thread(target=func, args=args, kwargs=kwargs)
  t.start()
  return t
def strands(func, x, c=32, *args, **kwargs):
  for idx, i in enumerate(array_split(x, c)):
    stuff = []
    for j in i:
      stuff.append(strand(func, j, *args, **kwargs))
    for s in stuff:
      s.join()
    print("%s out of %s at %s per done for %s"%(idx, (len(x)/c), c, func.__name__))
def strcls(x,**kwargs):
  return type("a",(str,),kwargs)(x)
  """
  r = intcls("asdf",print = lambda self:print(self))
  r.print()
  """
def sud(dictlist, key):
  if type(dictlist) is str:
    dictlist2 = dictlist
    dictlist = key
    key = dictlist2
  try: return [getattr(i, key) for i in list(dictlist)]
  except: return [i[key] for i in list(dictlist)]
def sudby(x,y):
  return or_list(lambda:[i for i in y if x(i)],lambda:[i for i in y if x(*i)],[])
def sudcall(key, dictlist, *args, **kwargs):
  try: return [getattr(i, key)(*args, **kwargs) for i in list(dictlist)]
  except: return [i[key](*args, **kwargs) for i in list(dictlist)]
def sudsort(key, dictlist, tcer=True):
  import operator
  if type(key) is not list:
    key = [key]
  try: return sorted(list(dictlist), key=operator.itemgetter(*key), reverse=tcer)
  except: return sorted(list(dictlist), key=operator.attrgetter(*key), reverse=tcer)
def sudsort_multi(columns, items, tcer=False):
  from operator import itemgetter, attrgetter
  from functools import cmp_to_key
  comparers = None
  if tryprocess(lambda:items[0].get(columns[0])): comparers = [((itemgetter(col[1:].strip()), -1) if col.startswith('-') else (itemgetter(col.strip()), 1)) for col in columns]
  else: comparers = [((attrgetter(col[1:].strip()), -1) if col.startswith('-') else (attrgetter(col.strip()), 1)) for col in columns]
  def comparer(left, right):
    def cmp(a, b):
      if a == None and b == None: return 0
      if a == None and b != None: return 1        
      if a != None and b == None: return -1
      elif a != None and b != None: return (a > b) - (a < b)
    comparer_iter = ( cmp(fn(left), fn(right)) * mult for fn, mult in comparers)
    return next((result for result in comparer_iter if result), 0)
  return sorted(list(items), key=cmp_to_key(comparer), reverse=tcer)
def swamp(*args):
  a, b = args[0], args[1]
  for x, y in zip(a, b):
    if y() == True:
      return x()
  """
  a, b, c = 1,0,0
  (1)if(a==True)else(2)if(b==True)else(3)if(c==True)else()
  a, b, c = 0,1,0
  (1)if(a==True)else(2)if(b==True)else(3)if(c==True)else()
  a, b, c = 0,0,1
  (1)if(a==True)else(2)if(b==True)else(3)if(c==True)else()
  swamp(lambda: a==True, lambda: b==True, lambda: c==True, lambda: 1, lambda: 2, lambda: 3)
  
  def ard():
    print(d)
  def r():
    a = 1
    b = 0; c= 0; d=5
    swamp(lambda: a==True, lambda: b==True, lambda: c==ard(), lambda: 1, lambda: 2, lambda: 3)
    (1)if(a==True)else(2)if(b==True)else(3)if(c==ard())else()
  """
def sys_exit():
  [exec("import sys",globals()), sys.exit()]
def tcer(x,a=0):
  return reversed(x)if(a==0)else(list(reversed(x)))
def text_to_docx(text, filename):
  from docx import Document
  document = Document()
  paragraph = document.add_paragraph(text)
  from docx.shared import Pt
  style = document.styles["Normal"]; document.styles["Normal"].font.name = "Times New Roman"; document.styles["Normal"].font.size = Pt(4); 
  paragraph.style = document.styles["Normal"]
  document.save(filename)
def text_to_image(text):
  from PIL import Image, ImageDraw, ImageFont

  if text == "":
    text = "\n"
   
  img = Image.new('RGB', (1800, 540), color = (255, 255, 255))
  fnt = ImageFont.truetype("/Library/Fonts/Times New Roman.ttf", 20)
  d = ImageDraw.Draw(img)
  d.text((0,0), text, font=fnt, fill=(0, 0, 0))
  font_size = d.textsize(text, fnt)

  img = Image.new('RGB', font_size, color = (255, 255, 255))
  fnt = ImageFont.truetype("/Library/Fonts/Times New Roman.ttf", 20)
  d = ImageDraw.Draw(img)
  d.text((0,0), text, font=fnt, fill=(0, 0, 0))

  address = get_random_address(homepath("~/tavern/tavern/soda/dls")).png()
  img.save(address)
  impreview(address)
  os.remove(address)
def textplot(L,a,b):
  def divs(x,c):
    return [int(x/c)*i for i in range(c+1)]
  Q=divs(a,b) + [max(L)]
  def slot_file(L,x):
    r = []
    for idx, i in enum(x[:-1]):
      r.append(["%s-%s"%(i,x[idx+1]),len(sorted([a for a in L if a>i and a<=x[idx+1]]))])
    return r
  slot_file(L,Q)
  data= slot_file(L,Q)

  max_value = max(count for _, count in data)
  increment = max_value / 25
  longest_label_length = max(len(label) for label, _ in data)
  O = []
  for label, count in data:
    bar_chunks, remainder = divmod(int(count * 8 / increment), 8)
    bar = '█' * bar_chunks
    if remainder > 0:
        bar += chr(ord('█') + (8 - remainder))
    bar = bar or  '▏'
    O.append(bar+ " " + "(%s(%s))"%(str(label.rjust(longest_label_length).strip()),"%sCount"%(str(round(count,4)))) )
  O = ("\n".join(O))
  drkprint(O)
  return O
def timed(r,x):
  m = datetime.now()
  R = process(r)
  while True:
    l = datetime.now()
    if (l-m).seconds >=x and R.is_alive() == True:
      drkprint("timed out at %s seconds, returning None"%(x))
      return None
    elif (l-m).seconds <x and R.is_alive() == False:
      drkprint("timed in at %s seconds, "%(x))
      break
  return R.result()
def timed_input(prompt, x=10):
  import select
  cyanprint(prompt, end="")
  sys.stdout.flush()
  i,o,e = select.select([sys.stdin],[],[],x)
  if (i):
    response = sys.stdin.readline().strip()
    print("You said %s" % response)
    return response
  else:
    print("response [None]")
    return None
def thread(f, x, c=32):
  from multiprocessing.dummy import Pool
  pool = Pool(c)
  payload = pool.map(f, x)
  pool.close()
  pool.join()
  return payload
def time_a_download(method, arg=None):
  import time
  
  current = get_dircount()
  command = None
  if arg:
    command = 'method(%s)'%arg
  else:
    command = 'method()'
  exec(command)
  while get_dircount() == current and '.part' not in get_latest_download():
    time.sleep(0.05)
  time.sleep(5)
  return get_latest_download()
def timeit(func):
  def wrapper(*arg, **kw):
    t1 = time.time()
    res = func(*arg, **kw)
    t2 = time.time()
    print("timeit: %s, %s"%((t2 - t1), func.__name__))
    return res
  return wrapper
def timedretry(x,y):
  z = multiprocessing_process(x)
  time.sleep(y)
  if z.is_alive():
    z.terminate()
    return timedretry(x,y)
  else:
    return
def timedtask(func):
  def wrapper(*arg, **kw):
    t1 = time.time()
    start_datetime = datetime.now()



    new = Timedtask()
    new.function_name = func.__name__


    existants = Filter(Timedtask,function_name=new.function_name)
    zellums = key("elapsed",existants)
    stis = (sum(zellums)/len(zellums))
    redprint("stis")
    
    roundulo = int(stis/100)

    def sleeperman():
      for sleeptime in range(roundulo):
        lox = "█"*i
        sys.stdout.write(lox)
        sys.stdout.flush()
        time.sleep(sleeptime)
    import multiprocessing
    p = multiprocessing.Process(target=sleeperman)
    p.start()
    res = pool(func, *args, **kw)
    p.terminate()
    sys.stdout.write(("█"*10)+" %100")

    res = res[0]
    t2 = time.time()
    end_datetime = datetime.now()
    elapsed_time = (end_datetime - start_datetime).seconds
    print("elapsed: time: %s" % elapsed_time)
    print("timeit: %s, %s"%((t2 - t1), func.__name__))

    new.start = start_datetime
    new.end = end_datetime
    new.elapsed_time = elapsed_time
    new.my_time_elapsed = (1.1574074074074073e-05) * elapsed_time
    new.my_time_start = Date().myDatetimenow(start_datetime)
    new.my_time_end = Date().myDatetimenow(end_datetime)
    new.save()
    distinct_print(ordered_json_dumps(new.__dict__))
    return res
  return wrapper
def timer(t, func, *args, **kwargs):
  t = Timer(t, func, args=args, kwargs=kwargs)
  t.start()
  return t
def timestamp(x,forward=True):
  if forward == True:
    timestamp = datetime.timestamp(x)
    return timestamp
  elif forward == False:
    datetime_ = datetime.fromtimestamp(x)
    return datetime_
def tinyurl(url):
  return requests.get("http://tinyurl.com/api-create.php?url=%s"%(url)).text
def tp(func, *args, ep=0, error = None, **kwargs):
  import multiprocessing
  t = multiprocessing.Process(target=func, args=args, kwargs=kwargs)
  #t = multiprocessing.Process(target=func)#, args=args, kwargs=kwargs)
  try:
    t.run()
    return 1
  except Exception as e:
    #OSA.notify("%s, %s, %s" %  (str(func), str(args), str(kwargs)))
    #OSA.notify("tryprocess: " + str(e))
    #pyperclip.copy(str(e))
    OSA.log(str(or_list(error,e)))if(1==ep or error)else(1)
    return 0
def tr(func, *args, ep=0, error = None, **kwargs):
  """ ep - errorprint , error - supply own error """
  try:  
    return func(*args, **kwargs)
  except Exception as e:
    ifdo(lambda:(1==ep) or error,
          lambda:(print("Got Exception"),input(str(error if error !=None else e))))
    return 0
  """
  print(tr(lambda:0/0)==0)
  print(tr(lambda:1/1/)==1)
  """
def transfer_bash():
  os.system("""rm ~/tavern/tavern/soda/bash_profile; cp -r ~/.bash_profile ~/tavern/tavern/soda/bash_profile""")
def transfer_workflows():
  [os.system("rm -rf /Users/$USER/tavern/tavern/soda/*.workflow"),[os.system("cp -r ~/Library/Services/%s ~/tavern/tavern/soda/%s"%(i,i)) for i in os.listdir(homepath("~/Library/Services")) if i.endswith(".workflow")]]
def transpose(x):
  """
  import numpy as np
  x = np.transpose(x)
  x = [list(i) for i in x]
  return x
  """

  shieldgang=[]
  zilleum=0
  [[1,2,3],[1,2,3]]
  [[1,1,],[2,2],[3,3]]
  # for i in range of len [1,2,3], so 3x, get the nth idx of each poser
  for i in range(len(x[-1])):
    hot = [i[zilleum] for i in x]
    shieldgang.append(hot)
    zilleum = zilleum + 1

  return shieldgang
  """
  assert [[1, 1], [2, 2], [3, 3]] == transpose([[1,2,3],[1,2,3]])
  x = [[1,2],
    [1,2]]
  greenprint(transpose(x))
  """
def trykeycall(key, dictlist, *args, **kwargs):
  try: return [tryprocess(getattr(i, key), *args, **kwargs) for i in list(dictlist)]
  except: return [tryprocess(i[key], *args, **kwargs) for i in list(dictlist)]
def trylmap(f, x, *args, **kwargs):
  Q = []
  for i in x:
    Z = tryprocess(f, i, *args, **kwargs)
    Q.append(Z)
  return Q
def tryprocess(func, *args, ep=0, error = None, **kwargs):
  import multiprocessing
  t = multiprocessing.Process(target=func, args=args, kwargs=kwargs)
  #t = multiprocessing.Process(target=func)#, args=args, kwargs=kwargs)
  try:
    t.run()
    return 1
  except Exception as e:
    #OSA.notify("%s, %s, %s" %  (str(func), str(args), str(kwargs)))
    #OSA.notify("tryprocess: " + str(e))
    #pyperclip.copy(str(e))
    OSA.log(str(or_list(error,e)))if(1==ep or error)else(1)
    return 0
def tryreturn(func, *args, ep=0, error = None, **kwargs):
  """ ep - errorprint , error - supply own error """
  try:  
    return func(*args, **kwargs)
  except Exception as e:
    ifdo(lambda:(1==ep) or error,
          lambda:(print("Got Exception"),input(str(error if error !=None else e))))
    return 0
  """
  print(tryreturn(lambda:0/0)==0)
  print(tryreturn(lambda:1/1/)==1)
  """
def typecls(x,**kwargs):
  return type("a",(int,),kwargs)(x) if type(x)==int else(
         type("a",(str,),kwargs)(x)) if type(x)==str else(
         type("a",(list,),kwargs)(x)) if type(x)==list else(
         type("a",(float,),kwargs)(x)) if type(x)==float else(
         type("a",(Time,),kwargs)(x)) if type(x)==datetime else(
         type("a",(dict,),kwargs)(x)) if type(x)==dict else()
def uli(x,y,z=-1):
  return x.split(y,z)
def unpack_archive(address):
  import shutil
  import zipfile
  shutil.unpack_archive(address, "%s.zip"%address)if(os.path.isdir(address))else(zipfile.ZipFile(address,"r").extractall(os.getcwd()))
def update(x,**kwargs):
  lmap(lambda k,v: setitem(x,k,v), list(kwargs.items()))
  return x
  """
  assert update({"a":"b"},e=5) == {'a': 'b', 'e': 5}
  """
def urlopenproduct(product,url):
  [pyperclip.copy(url%(product.handle)), OSA.log("Press OK"), OSA("Google Chrome 70",["ctrl_t","ctrl_l","ctrl_v","return"])]
def valuelist(x):
  return {a:b for a,b in x}
  """
  valuelist([(1,2), (2,3), (3,4)])
  """
def varsave(x):
  'def varsave(x):\n  image_ids = key("image_id", x.variants)\n  first_save = apilimitcall(x.save)\n  assert first_save == True\n  image_ids_after_save = key("image_id", x.variants)\n  if image_ids_after_save != image_ids:\n    for a, b in zip(x.variants, image_ids):\n      a.image_id = b\n    pool(lambda i: apilimitcall(i.save), x.variants, nodes=4).result()\n    if len(x.variants) > 50:\n      time.sleep(0.2)\n  return x'
  image_ids = key("image_id", x.variants)
  first_save = apilimitcall(x.save)
  assert first_save == True
  image_ids_after_save = key("image_id", x.variants)
  if image_ids_after_save != image_ids:
    for a, b in zip(x.variants, image_ids):
      a.image_id = b
    image_ids_x = oset(sud("image_id",x.variants))
    new = dictfromkeys(image_ids_x,[])
    for a, b in new.items():
      new[a] = sud("id",filter(x.variants,image_id=a))
    for a, b in new.items():
      y = filter(x.images,id=a)[0]
      y.variant_ids = new[a]
    x.save()
    # pool(lambda i: apilimitcall(i.save), x.variants, nodes=6).result()
    # if len(x.variants) > 50:
    #   time.sleep(0.2)
  return x
def versioncheck(x,z=None):
  exec("import selenium; bprint(selenium.__version__); y = selenium.__version__",globals())
  if z:os.system("pip install %s==%s"%(x,z))
  return y
def viden(x,*args):
  print(args)
  for i,j in zipeven(args[0::2],args[1::2],None):
    if j == None:
      x = x.split(i)
    else:
      x = x.split(i)[j]
  return x
  """
  viden("asdfa","a",1)
  """
def wall(i):
  return ceil(i)if((i)%1>=0.5)else(floor(i))
def word_multiply(l1,l2):
  x = []
  for i in l1:
    for j in l2:
      x.append([i,j])
      x.append([j,i])
  return x
def wordcount(x):
  apostrophes = x.count("'")
  words = len(x.split(" "))
  count = apostrophes + words
  return count
def writew(x,y):
  open(x,"w").write(y)
  return x
def writewb(x,y):
  open(x,"wb").write(y)
  return x
def write_xlsx_cell(cell,x,wb=None,save=False):
  ws = None
  if globe("workbook"):
    wb = globe("workbook")
    ws = wb.worksheets[0]
  else:
    import openpyxl
    wb = ifelseget(lambda:os.path.exists(wb),lambda:openpyxl.load_workbook(wb),lambda:openpyxl.Workbook())
    ws = wb.worksheets[0]
    globalise(wb,"workbook")
  ws[cell].value = x
  if save:
    wb.save("out.xlsx")
  return wb
def xir(x,**kwargs):
  [setattr(x,i,j) for i,j in kwargs.items()]
  return x
def xplist(x):
  r = '\n  <?xml version="1.0" encoding="UTF-8"?>\n  <!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">\n  <plist version="1.0">\n  <dict>\n      <key>Label</key>\n      <string>{}</string>\n      <key>ProgramArguments</key>\n      <array>\n      <string>/Users/%s/tavern/bin/python3.5</string>\n      <string>-c</string>\n      <string>{}</string>\n      </array>\n      <key>UserName</key>\n      <string>%s</string>\n      <key>StandardOutPath</key>\n      <string>{}</string>\n      <key>StandardErrorPath</key>\n      <string>{}</string>\n      <key>KeepAlive</key>\n      <true/>\n  </dict>\n  </plist>\n  '%(getuser(),getuser())
  title = "%s"%([exec("import nltk",globals()),random.sample(random.sample(list(nltk.wordnet.wordnet.all_synsets(nltk.wordnet.wordnet.NOUN)),1)[0].lemmas(),1)[0].name()][1])
  os.makedirs(homepath("~/tavern/tavern/soda/plists"),exist_ok=True)
  save_path = homepath("~/tavern/tavern/soda/plists/%s.plist"%(title))
  y = 'import os; os.chdir(os.path.expanduser("~/tavern/tavern")); from soda.can import *; %s'%(x)
  x = r.format(save_path.split("/")[-1].split(".")[0],y,save_path+".out",save_path+".err").strip().replace("\n  ", "\n")
  open(save_path, "w").write(x)
  return x
def zeroith():
  return(str)
def zipUtil(address,reverse=not True):
  # developer note: if you're interested in command line `zip` for windows, use : https://sourceforge.net/projects/gnuwin32/files/zip/3.0/ ((link from: https://www.tecmint.com/create-password-protected-zip-file-in-linux/)) ... add it to C:\Windows\System32
  if reverse!=True:
    # - zip -  a file
    redprint("    # - zip -  a file   ---- ")
    # set original path
    redprint("    # set original path   ---- ")
    setitem(globals(),"cwd",os.getcwd())
    # normalize address
    redprint("    # normalize address   ---- ")
    setitem(globals(),"address",address_normalize(address))

    # chdir from homepath to /Users, ~/picture.png to homepath, tryprocess from picture.png to `""`
    redprint("    # chdir from homepath to /Users, ~/picture.png to homepath, tryprocess from picture.png to `""`   ---- ")
    tryprocess(os.chdir, "/".join(globals()["address"].split("/")[:-1]))

    # set address to ./`address`
    redprint("    # set address to ./`address`   ---- ")
    setitem(globals(),"address",globals()["address"]if(-1==globals()["address"].find("/"))else(globals()["address"].split("/")[-1]))


    # remove the directed address
    redprint("    # remove the directed address   ---- ")
    subprocess.getoutput(""" rm -rf "%s.zip" """%globals()["address"])
    # waitfor directed address gone
    redprint("    # waitfor directed address gone   ---- ")
    while(1==os.path.exists("%s.zip"%globals()["address"])): time.sleep(0.1)



    # zip ~/tavern/tavern/drawings to ./drawings.zip
    redprint("    # zip ~/tavern/tavern/drawings to ./drawings.zip   ---- ")
    subprocess.getoutput("""zip -r "%s.zip" "%s" """%(globals()["address"],globals()["address"]))
    # waitfor gone not directed address
    redprint("    # waitfor gone not directed address   ---- ")
    while(0==os.path.exists("%s.zip"%globals()["address"])): time.sleep(0.1)

    # revert to original path
    redprint("    # revert to original path   ---- ")
    os.chdir(globals()["cwd"])
    redprint(address+".zip",)
    return address+".zip"


  elif reverse==True:
    # - unzip - a file
    redprint("    # - unzip - a file   ---- ")
    # remove&waitfor directed folder address
    redprint("    # remove&waitfor directed folder address   ---- ")
    subprocess.getoutput("""rm -rf "%s" """%(address[:-4]))
    while(1==os.path.exists(address[:-4])): time.sleep(0.1)

    # unzip&waitfor directed folder address
    redprint("    # unzip&waitfor directed folder address   ---- ")
    if "/" in address:
      direc = "/".join(address.split("/")[:-1])
      os.chdir(direc)
    subprocess.getoutput("""unzip "%s" """%(address))
    #while(0==os.path.exists(address[:-4])): time.sleep(0.1)

    # remove&waitfor original zip address
    redprint("    # remove&waitfor original zip address   ---- ")
    subprocess.getoutput("""rm -rf "%s" """%(address))
    #while(1==os.path.exists(address)): time.sleep(0.1)
    redprint(address[:-4],)
    return address[:-4]
def zipeven(x,y,z):
  x, y = list(x), list(y)
  if len(x) != len(y):
    if len(y) > len(x):
      x.append(z)
    elif len(x) > len(y):
      y.append(z)
  return zip(x,y)
  """
  assert list(zipeven([1,2,3],[1,2],None)) == [(1, 1), (2, 2), (3, None)]
  assert list(zipeven([1,2],[1,2,3],None)) == [(1, 1), (2, 2), (None, 3)]
  """
def zki(x,y,z):
  if x():
    return lmap(y,z)
  else:
    return z
  """
  zki(lambda: 1==1, lambda i: i+1, [1,2,3])
  zki(lambda: 1==2, lambda i: i+1, [1,2,3])
  """
def zz(x):
  #print("sleeping %s"%x); time.sleep(x)
  time.sleep(x)
class AD(dict):
  def __recurse__(self):
    keys_to_change = []
    for a,b in self.items():
      #print(v,"\n")
      if "values" in dir(b):
        keys_to_change.append(a)
    for a in keys_to_change:
      self[a] = AD(self[a])
    list_keys = []
    for a,b in self.items():
      if "append" in dir(b) and "extend" in dir(b):
        list_keys.append(a)
    for a in list_keys:
      self[a] = [AD(i) if "values" in dir(i) else i for i in self[a]]
  def __getattr__(self, attr):
    self.__recurse__()
    #print(self[attr])
    return self[attr]
  def __setattr__(self, attr, value):
    self[attr] = value
    self.__recurse__()
  def copy(self):
    return AD(self)
  def __test__(self):
    d = {"a": {"a": {"a": "a"}}}
    dd = AD(d)
    assert "AD" in str(type(dd))
    assert "AD" in str(type(dd.a))
    assert "AD" in str(type(dd.a.a))
    dd.b = d
    dd["c"] = d
    assert "AD" in str(type(dd.b))
    assert "AD" in str(type(dd.b.a))
    assert "AD" in str(type(dd.b["a"]))
    assert "AD" in str(type(dd.c))
    assert "AD" in str(type(dd["c"].a))
    assert "AD" in str(type(dd["c"]['a']))
    dd.update({"e":{"a":{"a":1}}})
    assert "AD" in str(type(dd.e.a))
    dd.pop("e")
    assert "e" not in dd.keys()
    assert list(sorted(dd.items())) == [("a", {"a": {"a": "a"}}), ("b", {"a": {"a": {"a": "a"}}}), ("c", {"a": {"a": {"a": "a"}}})]
    assert "".join(sorted(str(list(dd.values())))) == "          '''''''''''''''''''''',,::::::::[]aaaaaaaaaaa{{{{{{{{}}}}}}}}"
    assert list(sorted(dd.keys())) == [ 'a', 'b', 'c']
    assert dd.get("a") == {'a': {'a': 'a'}}
    assert dd.copy() == AD(dd)
    dd.get("a")
    dd.get("a", 1)
    assert dd.get("d",None)==None
    dd.clear()
    assert dd == {}
    print("tests successful")
    d = {"a": {"a": [{"a": "a"}]}}
    dd = AD(d)
    assert "AD" in str(type(dd.a.a[0]))
    assert "AD" in str(type(AD({"a": [{"a": "a"}]}).a[0]))
    assert "AD" in str(type(AD({"a": [{"a": "a"}]})['a'][0]))
    assert "AD" in str(type(list(AD({"a": [{"a": "a"}]}).values())[0][0]))
    assert "AD" in str(type(AD({"a": [{"a": "a"}]}).items()[0][1][0]))
    assert "AD" in str(type(AD({"a": [{"a": "a"}]}).a[0]))
    assert "AD" in str(type(AD({"a": [{"a": "a"}]})['a'][0]))
  def items(self):
    d = []
    for k,v in super().items():
      #print("items:_ v: %s" % v)
      if "values" in dir(v):
        d.append((k, AD(v)))
      else:
        d.append((k, v))
    return d
  def get(self, *args):
    try: return self[args[0]]
    except:
      if len(args) == 2:
        return args[1]
      else:
        return self[args[0]]
  def __init__(self,*args,**kwargs):
    super().__init__(*args,**kwargs)
    self.__recurse__()
    # additional creds to lacoste_miss on chaturbate
    # lauren.todd shopify senior talent sourcer linkedin
class Aomoji(AD):
  def __repr__(self):
    return "{}".format(self.f)
  def __init__(self):
    super().__init__()
    self.a = "(⌐■_■)"
    self.b = "[̲̅$̲̅(̲̅ ͡° ͜ʖ ͡°̲̅)̲̅$̲̅]"
    self.c = "( ・∀・)・・・--------☆"
    self.d = "٩(◕‿◕)۶"
    self.e = "ᶘ ᵒᴥᵒᶅ"
    self.f = "Ƹ̵̡Ӝ̵̨̄Ʒ"
    self.cat = "🐈"
    self.hamster = "🐹"
    self.fox = "🦊"
    self.panda = "🐼"
    self.bear = "🐻"
    self.frog = "🐸"
    self.bee = "🐝"
    self.mosquito = "🦟"
    self.cricket = "🦗"
    self.spider = "🕷"
    self.turtle = "🐢"
    self.octopus = "🐙"
    self.squid = "🦑"
    self.whale = "🐳"
    self.shark = "🦈"
    self.alligator = "🐊"
    self.rat = "🐀"
    self.squirrel = "🐿"
class B_Colors:
  builtin_input = input
  builtin_print = print
  bprint = builtin_print
  def print(*args, **kwargs):
    globals()["printed"] = [] if  "printed" not in globals() else globals()["printed"]
    globals()["printed"].append(" ".join([str(i) for i in args]))
    args = list(args)
    #args.insert(0, "[%s] "%datetime.now())
    args = tuple(args)
    builtin_print(*args, **kwargs)
  if "colored" not in globals():
    from termcolor import colored
    setitem(globals(),"colored",colored)
  redprint = lambda *args, **kwargs: [[builtin_print(colored(" ".join(list(map(str, args))), "red"),**kwargs) if "attrs" not in kwargs else builtin_print(colored(" ".join(list(map(str, args))), "red", attrs=kwargs["attrs"]))], sys.stdout.flush()]
  greenprint = lambda *args, **kwargs: [[builtin_print(colored(" ".join(list(map(str, args))), "green"),**kwargs) if "attrs" not in kwargs else builtin_print(colored(" ".join(list(map(str, args))), "green", attrs=kwargs["attrs"]))], sys.stdout.flush()]
  yellowprint = lambda *args, **kwargs: [[builtin_print(colored(" ".join(list(map(str, args))), "yellow"),**kwargs) if "attrs" not in kwargs else builtin_print(colored(" ".join(list(map(str, args))), "yellow", attrs=kwargs["attrs"]))], sys.stdout.flush()]
  blueprint = lambda *args, **kwargs: [[builtin_print(colored(" ".join(list(map(str, args))), "blue"),**kwargs) if "attrs" not in kwargs else builtin_print(colored(" ".join(list(map(str, args))), "blue", attrs=kwargs["attrs"]))], sys.stdout.flush()]
  magentaprint = lambda *args, **kwargs: [[builtin_print(colored(" ".join(list(map(str, args))), "magenta"),**kwargs) if "attrs" not in kwargs else builtin_print(colored(" ".join(list(map(str, args))), "magenta", attrs=kwargs["attrs"]))], sys.stdout.flush()]
  cyanprint = lambda *args, **kwargs: [[builtin_print(colored(" ".join(list(map(str, args))), "cyan"),**kwargs) if "attrs" not in kwargs else builtin_print(colored(" ".join(list(map(str, args))), "cyan", attrs=kwargs["attrs"]))], sys.stdout.flush()]
  whiteprint = lambda *args, **kwargs: [[builtin_print(colored(" ".join(list(map(str, args))), "white"),**kwargs) if "attrs" not in kwargs else builtin_print(colored(" ".join(list(map(str, args))), "white", attrs=kwargs["attrs"]))], sys.stdout.flush()]
  redinput = lambda *args, **kwargs: [input(colored(" ".join(list(map(str, args))), "red"),**kwargs) if "attrs" not in kwargs else input(colored(" ".join(list(map(str, args))), "red", attrs=kwargs["attrs"]))][-1]
  greeninput = lambda *args, **kwargs: [input(colored(" ".join(list(map(str, args))), "green"),**kwargs) if "attrs" not in kwargs else input(colored(" ".join(list(map(str, args))), "green", attrs=kwargs["attrs"]))][-1]
  yellowinput = lambda *args, **kwargs: [input(colored(" ".join(list(map(str, args))), "yellow"),**kwargs) if "attrs" not in kwargs else input(colored(" ".join(list(map(str, args))), "yellow", attrs=kwargs["attrs"]))][-1]
  blueinput = lambda *args, **kwargs: [input(colored(" ".join(list(map(str, args))), "blue"),**kwargs) if "attrs" not in kwargs else input(colored(" ".join(list(map(str, args))), "blue", attrs=kwargs["attrs"]))][-1]
  magentainput = lambda *args, **kwargs: [input(colored(" ".join(list(map(str, args))), "magenta"),**kwargs) if "attrs" not in kwargs else input(colored(" ".join(list(map(str, args))), "magenta", attrs=kwargs["attrs"]))][-1]
  cyaninput = lambda *args, **kwargs: [input(colored(" ".join(list(map(str, args))), "cyan"),**kwargs) if "attrs" not in kwargs else input(colored(" ".join(list(map(str, args))), "cyan", attrs=kwargs["attrs"]))][-1]
  whiteinput = lambda *args, **kwargs: [input(colored(" ".join(list(map(str, args))), "white"),**kwargs) if "attrs" not in kwargs else input(colored(" ".join(list(map(str, args))), "white", attrs=kwargs["attrs"]))][-1]
  def distinct_print(*args, **kwargs):
    distinct_print_dict = {1:redprint, 2: greenprint, 3: yellowprint, 4: blueprint, 5: magentaprint, 6: cyanprint, 7: whiteprint}

    while True:
      if "DISTINCT_PRINT_COUNTER" not in globals().keys():
        globals()["DISTINCT_PRINT_COUNTER"] = random.randrange(1, 8)
        distinct_print_dict[globals()["DISTINCT_PRINT_COUNTER"]](*args, **kwargs)
        break
      else:
        x = random.randrange(1, 8)
        if x == globals()["DISTINCT_PRINT_COUNTER"]:
          continue
        else:
          distinct_print_dict[x](*args, **kwargs)
          globals()["DISTINCT_PRINT_COUNTER"] = x
          break
  def dprint(*args, **kwargs):
    distinct_print_dict = {1:redprint, 2: greenprint, 3: yellowprint, 4: blueprint, 5: magentaprint, 6: cyanprint, 7: whiteprint}

    while True:
      if "DISTINCT_PRINT_COUNTER" not in globals().keys():
        globals()["DISTINCT_PRINT_COUNTER"] = random.randrange(1, 8)
        distinct_print_dict[globals()["DISTINCT_PRINT_COUNTER"]](*args, **kwargs)
        break
      else:
        x = random.randrange(1, 8)
        if x == globals()["DISTINCT_PRINT_COUNTER"]:
          continue
        else:
          distinct_print_dict[x](*args, **kwargs)
          globals()["DISTINCT_PRINT_COUNTER"] = x
          break
  def drkprint(*args, **kwargs):
    from colored import fg, bg
    args = ", ".join(lmap(str,args))
    x = "%s%s" % (fg(255), bg(0))
    #x = "%s" % (fg(random.randrange(1,256)))
    builtin_print("%s%s" % (x, args))
  def rprint(*args, **kwargs):
    from colored import fg, bg
    args = ", ".join(args)
    #x = "%s %s" % (fg(random.randrange(1,256)), bg(random.randrange(1,256)))
    x = "%s" % (fg(random.randrange(1,256)))
    builtin_print("%s%s" % (x, args))
  def random_input(*args, **kwargs):
    from colored import fg, bg
    args = ", ".join(args)
    #x = "%s %s" % (fg(random.randrange(1,256)), bg(random.randrange(1,256)))
    x = "%s" % (fg(random.randrange(1,256)))
    builtin_input("%s %s" % (x, args))
  def distinct_input(*args, **kwargs):
    distinct_input_dict = {1:redinput, 2: greeninput, 3: yellowinput, 4: blueinput, 5: magentainput, 6: cyaninput, 7: whiteinput}
    while True:
      if "DISTINCT_INPUT_COUNTER" not in globals().keys():
        globals()["DISTINCT_INPUT_COUNTER"] = random.randrange(1, 8)
        distinct_input_dict[globals()["DISTINCT_INPUT_COUNTER"]](*args, **kwargs)
        break
      else:
        x = random.randrange(1, 8)
        if x == globals()["DISTINCT_INPUT_COUNTER"]:
          continue
        else:
          distinct_input_dict[x](*args, **kwargs)
          globals()["DISTINCT_INPUT_COUNTER"] = x
          break
  globals().update(locals())
class DecisionTree(object):
  def init(self):
    if hasattr(self, 'functions_sorted'):
      self.functions = [getattr(self, i) for i in self.functions_sorted]
      return
    self.functions = []
    for i in dir(self):
      v = getattr(self, i)
      from types import MethodType,ModuleType,FunctionType
      if type(v) is MethodType and '__' not in i and i not in ['exec', 'show', 'run', 'init']:
        self.functions.append(i)
    self.functions = sorted(self.functions)
    self.functions = [getattr(self, i) for i in self.functions]
  def exec(self, command):
    command = eval(command)
    for i in dir(self):
      try: locals().update(getattr(self,i).__globals__)
      except: pass
    for i in sorted(locals()):
      print(i)
    import pyperclip
    pyperclip.copy(command)
    exec(command)
  def show(self):
    print('\n'*2)
    print('='*42)
    for idx, i in zip([i for i in range(1000) if i <= 12 or i >= 14], self.functions, ):
      if i.__name__ != "<lambda>": print("%s. %s"%(idx, i.__name__))
      else:                        print("%s. %s"%(idx, get_lambda_name(i)))

  def run(self):
    self.init()
    while True:
      try:
        self.show()
        now_what = input("\nNow what?\n: ")
        if now_what == 'q':
          print("QUITTING")
          return
        args = now_what
        if args[:4] == 'exec':
          self.exec(args[4:])
          continue
        args = now_what.split(' ')
        func_idx = int(args.pop(0))
        func = dict(zip([i for i in range(1000) if i <= 12 or i >= 14], self.functions, ))[func_idx]
        if len(args) == 0:
          call = func.__call__()
        elif len(args) > 0:
          call = func.__call__(*args)
        if call != None:
          return call
      except Exception as e:
        print("There was an error: %s"%e)
class CH:
  def __call__(self, p, shop=None):
    shop = or_list(lambda:Shop()(Get(Product,id=p.id).shop),lambda:Shop()(shop))
    collection = None
    if(0==len([i for i in apilimitcall(lambda:shop.shopify.CustomCollection.find(title=p.product_type)) if i.title==p.product_type])):
      (shop.shopify.CustomCollection(dict(OrderedDict([ ["title",p.product_type],  ["body_html", ""],  ["image",{"src":p.image.src,  "alt":p.product_type }],  ["published",True],  ["sort_order","manual"],  ["published_scope","global"],    ]))).save())
      collection = (apilimitcall(lambda:[i for i in shop.shopify.CustomCollection.find(title=p.product_type) if i.title == p.product_type][0]))
    else:
      collection = (apilimitcall(lambda:[i for i in shop.shopify.CustomCollection.find(title=p.product_type) if i.title == p.product_type][0]))
    apilimitcall(lambda:shop.shopify.Collect({"position":0,"collection_id":collection.id,"product_id":p.id,}).save())
  def mcc(self, shop, title):
    shop = Shop()(shop)
    collection = [(CH().mcc(shop.shop_abbreviation,title))if(False==(shop.shopify.CustomCollection(dict(OrderedDict([ ["title",title],  ["body_html", ""],  ["image",None],  ["published",True],  ["sort_order","manual"],  ["published_scope","global"],    ]))).save()))else(),(shop.shopify.CustomCollection.find(title=title)[0])][1]if(0==len([i for i in shop.shopify.CustomCollection.find(title=title) if i.title==title]))else(shop.shopify.CustomCollection.find(title=title)[0])
  def create_collect(self,shop,product=None,handle=None,position=None,):
    product=shop.shopify.Product.find(handle=handle)[0]if(product==None)else(product)
    try:
      0/shop.shopify.Collect({
      "collection_id":shop.shopify.CustomCollection.find(title=product.product_type)[0].id  ,  
      "position":min([max([len(shop.shopify.CustomCollection.find(title=product.product_type)[0].products())/2,len(shop.shopify.CustomCollection.find(title=product.product_type)[0].products())]),30])  if(None==position)else(position),  
      "product_id":product.id  ,  
      }).save()
    except Exception as e:
      redprint(e)
      redprint("MAJOR ERROR: COLLECT NOT SAVING... CHECK FOR IF THIS OCCURS")
  def remove(self,product,product_type):
    shop = Shop()(product.shop)
    product = product.p()
    l = shop.shopify.CustomCollection.find(title=Get(Product,id=product.id).product_type)
    l = [i for i in l if i.title == product_type][0]
    product.product_type = product_type
    product.save()
    l.remove_product(product)
    CH()(product)
    Update(Get(Product,id=product.id),product_type=product_type)
  def whole_collection_resort(self,shop):
    if type(shop) == str:shop = Shop()(shop)
    products = getshopifyproducts(shop.shop_abbreviation)
    product_types = sorted(set(key("product_type",products)))
    collections = shop.shopify.CustomCollection.find(status="any",limit=250)
    for i in product_types:
      product_type = i
      print(product_type)
      collection_ = [i for i in collections if i.title == product_type]
      print(collection_)
      try:
        collection_ = collection_[0]
      except:
        print("could not find one")
        continue
      products_ = [i for i in products if i.product_type == product_type]
      coll_prods = shop.pfind(collection_id=collection_.id,limit=250)
      for j in products_:
        if j not in coll_prods:
          product_to_add = j
          # collection_.add_product(product_to_add)
          CH()(product_to_add,shop.shop_abbreviation)
          print("adding one product %s to %s"%(j.product_type,product_type))
          time.sleep(0.5)
      coll_prods = shop.pfind(collection_id=collection_.id,limit=250)
      for j in coll_prods:
        if j.product_type != product_type:
          product_to_remove = j
          collection_.remove_product(product_to_remove)
          print("removing one product %s from %s"%(j.product_type,product_type))
          time.sleep(0.5)

    total_product_count = 0
    for i in collections:
      coll_prods = shop.pfind(collection_id=i.id,limit=250)
      total_product_count = total_product_count + len(coll_prods)
      assert len(set(sud("product_type",coll_prods))) == 1
      assert list(set(sud("product_type",coll_prods)))[0] == i.title
      len_products = len([j for j in products if j.product_type == i.title])
      assert len_products == len(coll_prods)
      print("%s products for %s, %s in collection"%(len_products,i.title,len(coll_prods)))
    assert total_product_count == len(products)
    print("%s total product count for %s products"%(total_product_count,len(products)))
  def assign_plus_size_tags(self):
    for i in All(Product):
      L=set(flatten(keymulti(["option1","option2","option3"],i.variants),1))
      if "3XL" in L:
        print(L)
        i.product_tags = add_tag(i.product_tags,"Plus Size")
        print(i.product_tags)
        i.save()
        Q=Shop()(i.shop).pfind(id_=i.id)
        Q.tags=i.product_tags
        Q.save()
  def get_compare_at_price(self,new_price):
    multiplier = 0.01 * random.randrange(150, 220)
    compare_at_price = multiplier * new_price
    compare_at_price = int(compare_at_price)
    compare_at_price = compare_at_price - 0.05
    return compare_at_price
  def free_plus_ship(self,product_id):
    product = None
    if(Product==type(product_id)): 1
    else: product = Product.objects.get(id=product_id)
    shop = Shop()( product.shop)
    shop
    shop
    product = apilimitcall(lambda:shop.shopify.Product.find(id_=product_id))
    for variant in product.variants:
      price = float(variant.price)
      import math
      variant.grams = math.ceil(price/10) * 100
      variant.weight = 0.1
      variant.compare_at_price = ((variant.weight*10)*9.95) * (random.randrange(14,18)/10)
      variant.price = 0.00
      redprint("variant weight: %s" % variant.weight)
      redprint("variant compare_at_price: %s" % variant.compare_at_price)
      redprint("variant price: %s" % variant.price)
      print("")
    varsave(product)
  def adjust_weights(self,shop):
    try: shop = Shop()(shop)
    except: pass
    products = getshopifyproducts(shop)
    for i in products:
      for j in i.variants:
        weight_unit = "kg"
        weight = None
        price = None
        price = float(j.price)
        weight = float(j.weight)

        if j.weight_unit == "kg" and price != 0.0 and weight == 0:
          None
        else:
          if price == 0.0:
            weight = 0.1
          else:
            weight = 0.0

          j.weight = weight
          j.price = price
          j.weight_unit = weight_unit
          j.save()
          print("[%s][%s][%s][%s][%s]"%(j.weight_unit, j.weight, j.price, j.title, i.id))
          time.sleep(0.5)
  def price_change(self,old_price,shop):
    old_price = round(old_price,2)
    if "%s_price_list"%(shop) in key("w",All(ExecutableText)):
      price_list = ExecutableText().export("%s_price_list"%(shop))
      if old_price not in price_list:
        return (int(old_price * 1.7) - 0.05)
      else:
        return price_list[old_price]
    else:
      if len(Filter(PriceChange,shop=shop)): return (old_price*2) - 0.05
      x = PriceChange().price_change(old_price,shop)
      return x
    return
    new_price = 0
    if 0 <= old_price < 5:
      new_price = old_price + 10
    elif 5 <= old_price < 10:
      new_price = old_price + 8
    elif 10 <= old_price < 15:
      new_price = old_price * 2
    elif 15 <= old_price < 20:
      new_price = old_price * 2
    elif 20 <= old_price < 40:
      new_price = old_price * 2
    elif 40 <= old_price < 60:
      new_price = old_price * 1.8
    elif 60 <= old_price < 80:
      new_price = old_price * 1.65
    elif 80 <= old_price < 100:
      new_price = old_price * 1.6
    elif 100 <= old_price < 1000:
      new_price = old_price * 1.59
    new_price = int(new_price)
    new_price = new_price - 0.05
    print("old price: %s, new price: %s" % (old_price, new_price))
    if new_price <= 14 and new_price >= 10 and old_price <= 7:
      new_price = 9.95

    return new_price
  def reset_weight_on_priced_product(self,product):
    if type(product) is Product:
      product = Shop()(product.shop).shopify.Product.find(id_=product.id)
    changed = False
    for v in product.variants:
      if float(v.price) != 0 and float(v.weight) != 0:
        v.weight = 0
        changed = True
        distinct_print("[reset_weight_on_priced_product][changed = True] [%s]"%product.id)
      if float(v.price) == 0 and float(v.weight) == 0:
        os.system("touch ~/%s_v_price_and_v_weight==0____vendor_%s"%(product.id,product.vendor))
    if changed == True: product.save()
class Chatter:
  def get_texts(self):
    thoughts = (thought for i in range(500))
    for i in thoughts:
      if talking_about_programming_for_timeframe_until_february_7th_2019(i):
        dont_talk()
class CommandReceiver:
  def __init__(self):
    # 'email = CommandEmail()()\nemailer = Emailer().set_services_initiate_2(email.email)\nmsgs = emailer.set_messages(10)\nx = sudby(lambda i:"UNREAD" in i.labelIds,filter(msgs,subject="command",sender=email.receiving_email))\nnew = x[-1]\ncommand,data="twirl1",SOUP(new.hidden_message_3.decode()).text\ncommands = {"twirl1":lambda x:([setattr(g,"Z",x.strip()),pool(lambda:tp(lambda:Product().add_product(caption=x.split("\\n")[1],url=x.split("\\n")[0]),ep=1))])}\ncommands[command](data)\n'
    posts = get_feed()
    commands = {
                "postit":lambda x:([setattr(g,"Z","twirl1: caption"),pool(lambda:tp(lambda:Product().add_product(post_caption=x.split("\n",1)[1],url=x.split("\n")[0]),ep=1))]),
                "changeshop":lambda x:Update(Muta()(),store_abbre=x.split(",")[0],page=x.split(",")[1])
                }
    posts = sudby(lambda i:str(i.get("message")).split("\n")[0] in commands.keys(),tcer(posts))
    lmap(lambda i:tp(lambda:FacebookNewsFeedPosts().add(created_time=Date().parse_date(i["created_time"],localize_timezone=True),message=i["message"])),posts)
    if not Filter(FacebookNewsFeedPosts,posted=0): return
    new = list(Filter(FacebookNewsFeedPosts,posted=0))[0]
    command,data = new.message.split("\n")[0],new.message.split("\n",1)[1]
    commands[command](data)
    Update(list(Filter(FacebookNewsFeedPosts,posted=0))[0],posted=1)
class CSV(DecisionTree):
  exec("from csv import *")
  def ListWrite(self,fn,data,delimiter=",",newline="\n"):
    with open(fn,'w',newline=newline) as f:
      f=csv.writer(f,delimiter=delimiter)
      f.writerows(data)
  def ListRead(self,fn,delimiter=","):
    with open(fn,'r') as f:
      data=list(csv.reader(f,delimiter=delimiter))
      return data
  def DictRead(self, fn, fields=None, delimiter='\t',encoding='utf8',errors='ignore'):
    import codecs
    if not fields:
      with open(fn,'r',encoding=encoding,errors=errors) as f:
        try: fields = list(csv.reader(f,delimiter=delimiter))[0]
        except: fields = list(csv.DictReader(codecs.open(fn, 'rU', 'utf-16', errors=errors), dialect='excel', delimiter=delimiter))[0]
    with open(fn,'r',encoding=encoding,errors=errors) as f:
      try: pay = list(csv.DictReader(f,delimiter=delimiter))
      except: pay = list(csv.DictReader(codecs.open(fn, 'rU', 'utf-16', errors=errors), dialect='excel', delimiter=delimiter))
      pay= pay if not fields else \
            [{a:b for a,b in _dict.items() if a in fields} for _dict in pay]
      return pay
  def DictReadWithDelimiterGuess(self, fn, fields=None,encoding='utf8',errors='ignore'):
    A=flatten(lmap(list,keycall("values",CSV().DictRead(fn,delimiter="\t",encoding=encoding,errors=errors))),1)
    B=flatten(lmap(list,keycall("values",CSV().DictRead(fn,delimiter=",",encoding=encoding,errors=errors))),1)
    delimiter = 0
    if len(B)>=len(A):
      delimiter = ","
    else:
      delimiter = "\t"
    return CSV().DictRead(fn, fields=fields, delimiter = delimiter)
  def DictWriteWithHeaders(self, fn, _dictlist, headers, delimiter='\t'):
    with open(fn, 'w', newline='\n') as csvfile:
      writer = csv.writer(csvfile, delimiter=delimiter)
      writer.writerow(headers)
      for row in _dictlist:
        targetrow = []
        for key in headers:
          try:targetrow.append(row[key])
          except:targetrow.append(getattr(row, key))
        writer.writerow(targetrow)
  def DictWrite(self, fn, _dictlist, delimiter = '\t'):
    with open(fn, 'w') as f:
      import csv
      f=csv.DictWriter(f = f, fieldnames=_dictlist[0].keys(), delimiter=delimiter)
      f.writeheader()
      f.writerows(_dictlist)
  def DictAppend(self, fn, _dictlist, delimiter = '\t'):
    with open(fn, 'a') as f:
      import csv
      f=csv.DictWriter(f = f, fieldnames=_dictlist[0].keys(), delimiter=delimiter)
      f.writeheader()
      f.writerows(_dictlist)
  def pick_data(self, data, fields, returntype="OrderedDict"): 
    payload = []
    for i in data:
      d = OrderedDict() if returntype == "OrderedDict" else AttrDict()
      for j in fields:
        try: d[j] = getattr(i, j, None) # prefer pick_data from an attritem     .  
        except: d[j] = i.get(j, None) # 2ndprefer pick_data from a  dictionary
      payload.append(d)
    return payload
  def transpose_csv(self,fn,delimiter='\t'):
    a = zip(*csv.reader(open(fn, "r"),delimiter=delimiter))
    csv.writer(open(fn, "w")).writerows(a)
  def excel_open(self, fn):
    system('/Applications/Microsoft\ Excel_2016.app/Contents/MacOS/Microsoft\ Excel %s &'%os.path.abspath(fn))
  def xlsx_to_csv(self, workbook, sheet, as_dict=True):
    import csv
    import openpyxl
    wb = openpyxl.load_workbook(workbook)
    ws = wb[sheet]
    data = [key("value",i) for i in list(ws.rows)]
    if as_dict == False:
      return data
    if as_dict == True:
      dictlist = [AttrDict(dict(zip(data[0],i))) for i in data[1:]]
      return dictlist
  def dictlist_to_xlsx(self, dictlist, headers, workbook, sheet):
    CSV().DictWriteWithHeaders(fn="tmp.csv", _dictlist = dictlist, headers = headers)
    CSV().csv_to_xlsx(infile="tmp.csv", workbook=workbook, sheet=sheet, rm_infile = True)
  def xlsx_column_to_images(self, workbook, sheet, column):
    import openpyxl
    column = int(column) # in case this is being run via class DecisionTree
    wb = openpyxl.load_workbook(workbook)
    ws = wb[sheet]
    count_rows = len(list(ws.rows))
    for i in range(count_rows):
      ws.row_dimensions[i].height = 100


    column_letter = list(ws.columns)[column - 1][0].coordinate[0]
    print(column_letter)
    ws.column_dimensions[column_letter].width = 100


    column = list(ws.columns)[column - 1] # Column B -> Column 2 -> list(ws.columns)[1] ; 2->1
    for cell in column[1:20]:
      value = cell.value
      cell.value = "" # Keeping the URL inside widens the row.
      cyanprint("value: %s" % value)
      if value == None:
        continue
      if cell.row == 1:
        continue

      image_path = None
      if "https://" in value:
        redprint("Downloading %s" % value)
        try:image_path = Images().download(value, )
        except Exception as e : print("%s,%s"%(image_path,e)); continue
        #while os.path.exists(image_path) == False: [redprint("waiting for image"), time.sleep(1)]
      else:
        redprint("image path = value %s" % value)
        image_path = value

      if os.path.exists(image_path) == False:
        redprint("[Does not exist][%s]"%image_path); continue
      img = openpyxl.drawing.image.Image(image_path)
      img.height = 100
      img.width = 100
      ws.add_image(img, cell.coordinate)

      #column_letter = cell.coordinate[0]
    os.system("rm %s/tmp.jpg &>/dev/null"%os.getcwd())
    wb.save(workbook)
  def csv_to_xlsx(self, infile, workbook, sheet, rm_infile = False, delimiter="\t"):
    print("""[Solved] One limitation of csv_to_xlsx currently is that it fills in x&y based on your infile's data size. if it's overwriting a smaller.""")
    import csv
    import openpyxl
    assert openpyxl.__version__ == "2.5.4"
    try:
      wb = openpyxl.load_workbook(workbook)
    except:
      wb = openpyxl.Workbook()
    try:
      ws = wb[sheet]
    except Exception as e:
      print(e, "creating sheet")
      ws = wb.create_sheet(sheet)
      tp(lambda:wb.remove_sheet(wb.get_sheet_by_name("Sheet")))
    ### first, clear all data so the event of data smaller leaving duplicates does not occur
    for i in list(ws.rows):
      for j in i:
        j.value = None
    with open(infile,"r") as f:
      data = list(csv.reader(f, delimiter=delimiter))
      for idx, i in enumerate(data):
        for idx2, j in enumerate(i):
          # i think if you make it a thread, the workbook may not save before all threads finish, and there may be overlap
          try: ws.cell(row=idx+1, column=idx2+1).value = j 
          except: ws.cell(row=idx+1, column=idx2+1).value = "ERROR_VALUE"
    wb.save(workbook)
    if rm_infile:
      os.remove(infile)
  @staticmethod
  def csvprint(data, width=1, colnames=None, spacer="|",print_headers=1,alignleft=True):
    import django
    if type(data) == django.db.models.query.QuerySet:
      data = [OrderedDict([[a,str(getattr(x,a))] for a in list(sorted(x.__dict__.keys())) if not a.startswith("_")]) for x in data]

    if len(data) == 0:
      redprint("[no data][exitting]")
      return

    if colnames:
      payload = []
      for i in data:
        tmp = OrderedDict()
        for j in colnames:
          try: tmp[j] = getattr(i, j)
          except: tmp[j] = i[j]
        payload.append(tmp)
      data = payload
    if not colnames:
      colnames = data[0].keys()
    column_dict = dict(zip(colnames, [i.upper() for i in colnames]))
    ifdo(lambda:print_headers,lambda:data.insert(0, column_dict))
    text = []
    for i in colnames:
      max_len = max(listmap(len, listmap(str, key(data, key=i))))
      for idx, j in enumerate(data):
        try: addition = str(j[i])
        except: addition = str(getattr(j, i))
        number_of_spaces = max_len - len(addition)
        if alignleft:
          addition += (spacer*(number_of_spaces+width))
        else:
          addition = (spacer*(number_of_spaces+width)) + addition
        try: text[idx] += addition
        except: text.append(addition)
    data.pop(0)
    if alignleft:
      distinct_print('\n'.join([spacer*len(text[-1])+(spacer*width)]+[((spacer*width)+i) for i in text]+[spacer*len(text[-1])+(spacer*width)]))
    else:
      distinct_print('\n'.join([spacer*len(text[-1])+(spacer*width)]+[(i+(spacer*width)) for i in text]+[spacer*len(text[-1])+(spacer*width)]))
    print("")
  def get_workbook_sheet_styles(self, workbook_path):
    import _pickle
    import openpyxl
    workbook_sheet_styles = {}
    wb = openpyxl.load_workbook(workbook_path)
    sheetnames = wb.sheetnames
    sheetnames.pop(sheetnames.index("Sheet"))
    for sheetname in sheetnames:
      ws = wb[sheetname]
      columns = list(ws.columns)
      column_names = [i[0].value for i in columns]
      sheet_styles = {}
      for column_name, column in zip(column_names,columns):
        sheet_styles[column_name] = {
        "fill": _pickle.dumps(copy.copy(column[1].fill)),
        "font": _pickle.dumps(copy.copy(column[1].font)),
        "width": _pickle.dumps(copy.copy(column[1].parent.column_dimensions[column[1].column].width)),
        "alignment": _pickle.dumps(copy.copy(column[1].alignment)),
        "border": _pickle.dumps(copy.copy(column[1].border))
        }
      workbook_sheet_styles[sheetname] = sheet_styles
    _pickle.dump(workbook_sheet_styles, open(homepath("~/tavern/tavern/bag/.workbook_sheet_styles.pkl"), "wb"))
    return workbook_sheet_styles
  def xlsx_filter(self, ws):
    import openpyxl
    maxcolumnletter = openpyxl.utils.get_column_letter(ws.max_column)
    ws.auto_filter.ref = 'A1:'+maxcolumnletter+str(len(ws['A']))
  def xlsx_cell(self, cell, fgColor="000000", font_color="000000", column_width=None, font_size=5, font_name="Calibri", shrink_to_fit=True, vertical="top", border_style="hair", number_format="0.00"):
    import openpyxl
    import decimal
    [setattr(cell,"fill",openpyxl.styles.PatternFill(fgColor=fgColor, fill_type="solid"))     ,     setattr(cell, "font", openpyxl.styles.Font(size=font_size,name=font_name,color=font_color))     ,    setattr(cell.parent.column_dimensions[cell.column],"width",column_width) if column_width != None else None    ,     setattr(cell, "alignment", openpyxl.styles.Alignment(shrink_to_fit=shrink_to_fit,vertical=vertical,horizontal="general",wrap_text=False,indent=0,text_rotation=0))     ,     setattr(cell,"border",openpyxl.styles.borders.Border(left=openpyxl.styles.borders.Side(style=border_style),right=openpyxl.styles.borders.Side(style=border_style),top=openpyxl.styles.borders.Side(style=border_style),bottom=openpyxl.styles.borders.Side(style=border_style)))    ,    setattr(cell, "number_format", "0.00")]# if 1 == tryprocess(lambda i: 1/0 if decimal.Decimal(str(i)).as_tuple().exponent.__abs__() >= 5 else 1, i=cell.value) else 1    ]
class Date(object):
  def __init__(self, _str=None, b=None):
    if _str is None: _str = datetime.now()
    self.datestr = self.autodate(_str)
    self.dateobj = self.autodateobj(_str).replace(tzinfo=None)
    self.datetime = datetime
    self.now = datetime.now
  def myTimedelta(self, years=0, days=0, hours=0, minutes=0, seconds=0, ):
    seconds = seconds
    seconds = seconds + (minutes*60)
    seconds = seconds + (hours*3600)
    seconds = seconds + (days*86400)
    seconds = seconds + (years*31536000)
    seconds = seconds + (86400*len([i for i in list(range(datetime.now().date().year,datetime.now().date().year+29)) if i%4==0]))
    return timedelta(seconds=seconds)
  def autodate(self, _str):
    _str = _str.split(' ')[0] if type(_str) == str and ' '  in _str else _str
    try:_str = datetime.strftime(_str,'%Y-%m-%d') if type(_str) != str else _str
    except: _str = datetime.strftime(_str.dateobj,'%Y-%m-%d') if type(_str) != str else _str
    import re
    m,d,Y='06','06','2006'
    Ymd = re.findall(r'(....[/:-].*[/:-].*)',_str)
    mdY = re.findall(r'(.*[/:-].*[:/-]....)',_str)
    if len(Ymd) > 0:
      Ymd = re.sub(r'([:/-])','#',Ymd[0])
      Y,m,d = Ymd.split('#')
    elif len(mdY) > 0:
      mdY = re.sub(r'([:/-])','#',mdY[0])
      m,d,Y = mdY.split('#')
    try:
      if len(m) == 1:
        m = '0%s' % m
      if len(d) == 1:
        d = '0%s' % d
    except Exception as e:
        print(e)
    return '-'.join([Y,m,d])
  def autodateobj(self, _str):
    return datetime.strptime(self.autodate(_str),'%Y-%m-%d')
  def strftime(self, srftime_string):
    return self.dateobj.strftime(srftime_string)
  def __repr__(self):
    return self.datestr
  def __sub__(self, _str):
    if type(_str) == int:
      return Date(self.dateobj - timedelta(_str))
    else:
      return (self.dateobj - Date(_str).dateobj).days
  def __add__(self, _str):
    if type(_str) == int:
      return Date(self.dateobj + timedelta(_str))
  def __lt__(self, _str):
    return self.dateobj < Date(_str).dateobj
  def __gt__(self, _str):
    return self.dateobj > Date(_str).dateobj
  def __eq__(self, _str):
    if tryprocess(lambda:Date(_str)) == 0:
      return False
    return self.dateobj == Date(_str).dateobj
  def __call__(self):
    return self.dateobj
  def datelist(self, x):
    return [Date(datetime.today() - timedelta(i*1)) for i in sorted(range(x),reverse=True)]
  def dt(self=None, x=0, strf='%Y-%m-%d'):
    return (datetime.now() + timedelta(x)).strftime(strf)
  @staticmethod
  def myDate():
    x = datetime.now()
    y = datetime.now().year
    d1_of_year = datetime(y, 1, 1)
    z = (datetime.today() - d1_of_year).days
    return z
  @staticmethod
  def myDatetimenow(dateobj = None, round_count = 4):
    #print("hello, myDatetimenow is running now")
    dateobj = datetime.now() if dateobj == None else dateobj.replace(tzinfo=None)                                                                                           
    dateobj_year_str = str(dateobj.year)[-2:]
    a = int(dateobj_year_str) * 1000                                                                            
    mydatetimenow_inside_the_day =  ((dateobj.hour * 60 * 60) + (dateobj.minute*60) + dateobj.second)/(24*60*60)
    mydatetimenow_from_yearstart = (dateobj - datetime(dateobj.year-1, 12, 31)).days
    mydatetimenow = a + mydatetimenow_inside_the_day + mydatetimenow_from_yearstart
    mydatetimenow = round(mydatetimenow, round_count) #
    #print("%s->%s"%(dateobj,mydatetimenow))
    return mydatetimenow
  @staticmethod
  def myUndatetimenow(x):
    year = int(x/1000) + 2000
    datetime_ = datetime(year,1,1)
    seconds = (x - int(x)) * (24*60*60)
    days = int(x - int(x/1000) * 1000)
    return datetime_+timedelta(days=days-1, seconds=seconds)
  def Now(self):
    return datetime.now()
  @staticmethod
  def date(self):
    return self.dateobj
  def str(self):
    return self.datestr
  def get_month_range(self,x,year):
    y = {1:[Date("01/01/%s"%(year)),Date("01/31/%s"%(year))],2:[Date("02/01/%s"%(year)),Date("02/29/%s"%(year))if(year%4 == 0)else(Date("02/28/%s"%(year)))],3:[Date("03/01/%s"%(year)),Date("03/31/%s"%(year))],4:[Date("04/01/%s"%(year)),Date("04/30/%s"%(year))],5:[Date("05/01/%s"%(year)),Date("05/31/%s"%(year))],6:[Date("06/01/%s"%(year)),Date("06/30/%s"%(year))],7:[Date("07/01/%s"%(year)),Date("07/31/%s"%(year))],8:[Date("08/01/%s"%(year)),Date("08/31/%s"%(year))],9:[Date("09/01/%s"%(year)),Date("09/30/%s"%(year))],10:[Date("10/01/%s"%(year)),Date("10/31/%s"%(year))],11:[Date("11/01/%s"%(year)),Date("11/30/%s"%(year))],12:[Date("12/01/%s"%(year)),Date("12/31/%s"%(year))]}
    return y[datetime.strptime(x,"%B").month]
  @staticmethod
  def friendlydate(x, only_date=False,**kwargs):
    return swamp([lambda:datetime.strftime(x,"%A, %b %d"),
                   lambda:datetime.strftime(x,"%A, %b %d'%y"),
                   lambda:datetime.strftime(x,("%A, %b %d'%y at %I:%M %p")),
                   lambda:datetime.strftime(x,("%A, %b %d'%y at %I:%M:%S %p")),
                   lambda:datetime.strftime(x,("%A, %b %d' at %I:%M:%S %p")),
                   lambda:datetime.strftime(x,("%A, %b %d at %I:%M %p")),
                   ],
                  [lambda:only_date==True and "with_year" not in kwargs,
                  lambda:only_date==True and "with_year" in kwargs,
                  lambda:only_date==False and "with_year" in kwargs and "seconds" not in kwargs ,
                  lambda:only_date==False and "with_year" in kwargs and "seconds" in kwargs,
                  lambda:only_date==False and "with_year" not in kwargs and "seconds" in kwargs,
                  lambda:only_date==False and "with_year" not in kwargs and "seconds" not in kwargs ,],)
    """
    assert Date().friendlydate(datetime(2019,1,21,1,11)) == 'Monday, Jan 21 at 01:11 AM'
    assert Date().friendlydate(datetime(2019,1,21,1,11),with_year=True) == "Monday, Jan 21'19 at 01:11 AM"
    assert Date().friendlydate(datetime(2019,1,21,1,11),seconds=True) == "Monday, Jan 21' at 01:11:00 AM"
    assert Date().friendlydate(datetime(2019,1,21,1,11),seconds=True,with_year=True) == "Monday, Jan 21'19 at 01:11:00 AM"
    assert Date().friendlydate(datetime(2019,1,21,1,11),only_date=True) == 'Monday, Jan 21'
    assert Date().friendlydate(datetime(2019,1,21,1,11),only_date=True,with_year=True) == "Monday, Jan 21'19"
    """
  def seconds_to_text(self,x,days=True,hours=True,minutes=True,seconds=True):
    x = int(x)
    days_ = None
    days_r = None
    if days:
      q = 24*60*60
      days_ = int(x/q)
      days_r = x%q
      x = days_r
    hours_ = None
    hours_r = None
    if hours:
      q = 60*60
      hours_ = int(x/q)
      hours_r = x%q
      x = hours_r
    minutes_ = None
    minutes_r = None
    if minutes:
      q = 60
      minutes_ = int(x/q)
      minutes_r = x%q
      x = minutes_r
    seconds_ = None
    seconds_r = None
    if seconds:
      q = 1
      seconds_ = int(x/q)
      seconds_r = x%q
      x = seconds_r
    r = ""
    if days:
      r += "%s Days"%(days_)
      r += ", "
    if hours:
      r += "%s Hours"%(hours_)
      r += ", "
    if minutes:
      r += "%s Minutes"%(minutes_)
      r += ", "
    if seconds:
      r += "%s Seconds"%(seconds_)
      r += ", "
    if r.endswith(", "):
      r = r[:-2]
    return r
  def adjust_mydatetimenow__(self, data, field):
    for x in data:
      i = getattr(x, field)
      if i < 200:
        ii=i
        #b.append(len(str(i)))
        i = str(i)
        d = str(i)[:2]
        if len(i) == 5:
          i = i + "0"
        i = i[2:]
        #print(i)
        dd = (float(d)*1000)+float(i)
        #print(dd)
        setattr(x, field, dd)
        x.save();print("saving %s->%s" %(ii,dd))
      elif i < 10000:
        ii=i
        #print(i)
        d = str(i)[:2]
        i=str(i)
        if len(i) != 7:
          while True:
            i = i+"0"
            if len(i)==7:
              break
        
        i = i[2:]
        dd = (float(d)*1000) + float(i)
        print(dd)


        setattr(x, field, dd)
        x.save();print("saving %s->%s" %(ii,dd))
  @staticmethod
  def pastmonthdays(x):
    from calendar import monthrange
    count = 0
    count += ((datetime.now())- datetime(datetime.now().year,datetime.now().month,1)).days
    year = datetime.now().year
    month = datetime.now().month
    for i in range(x):
      month -= 1
      if month == 0:
        year -= 1
        month = 12
      count += monthrange(year, month)[1]
      print(year, month, count)
      print(count)
      time.sleep(0.2)
    return count
  def parse_date(self,w,remove_tzinfo=True,localize_timezone=False):
    import dateutil.parser
    x = dateutil.parser.parse(w)
    y = x.astimezone()if(localize_timezone==True)else(x)
    z = y.replace(tzinfo=None)if(remove_tzinfo==True)else(y)
    return z
class DefensiveProgrammingBot:
  @staticmethod
  def defend_DefensiveProgrammingBot(io):
    formats = [io, io==io]
    redprint("""\nio:{}\nio==io:{}""".format(*formats))
    returnable = None
    assert None == returnable
    return returnable
class Freelancer:
  def Description(self, a):
    pass
    """ """
  def SizeChart(self, a, html=True):
    # OSA.log(a)

    if "Alg1:" in a:
      xz = ""
      if a.endswith("&cm"):
        xz = a
      #a='Waist,Bust,Hips&Alg1:S-6XL,34-50,24-42,34-52'
      #a='Waist,Bust,Hips&Alg1:S-6XL,34-50,24-42,34-52&cm'
      # not for floats
      #shints = ["Size"]+[i+" (in)" for i in eval(a.split("&")[0])]
      # x-y, x-y, x-y, x-y
      shints = ["Size"]+[i for i in a.split("&")[0].split(",")]
      r = ["XS","S","M","L","XL","2XL","3XL","4XL","5XL","6XL"]
      chus = r[r.index(a.split("&")[1].replace("Alg1:","").split(",")[0].split("-")[0]):r.index(a.split("&")[1].replace("Alg1:","").split(",")[0].split("-")[1])+1]
      ZAMUS = []
      F = a.split("&")[1].replace("Alg1:","").split(",",1)[1].split(",")        
      vorts = []
      for idx, vax in enum(F):
        quas = Integer(vax.split("-")[1]) - Integer(vax.split("-")[0])
        stol = Integer(quas /  len(chus))
        h = Integer(vax.split("-")[0])
        lp = len(chus)
        qince = []
        for i in range(lp):
          print(h+(stol*i), h+(stol * (i+1)))
          print(h+(stol*i), h+(stol * (i+1)))
          #qince.append("-".join(lmap(str,[h+(stol*i), h+(stol * (i+1))])))
          qince.append(" - ".join(lmap(str,[ str(h+(stol*i))+'"', str(h+(stol * (i+1)))+'"' ])))
        vorts.append(["%s"%shints[idx+1]]+qince)
      vorts.insert(0, ["Size"]+chus)
      if xz.endswith("&cm"):
        for idx,i in enum(vorts):
          for idx2,j in enum(i):
            if j.endswith('"'):
              q = re.findall("[\d\.]+",j)
              for l in q:
                ll = round(float(l)/2.54,2)
                if str(ll).endswith(".0"):
                  ll = str(int(ll))
                else:
                  ll = str(float(ll))
                j = j.replace(l, ll)
              vorts[idx][idx2] = j


      import numpy as np
      vorts = np.transpose(vorts)
      vorts = [list(i) for i in vorts]
      if len(oset(lmap(len,vorts))) != 1:
        print("Error with Size Chart")
        assert False
      if html==True:
        vorts = csv_table_to_html(vorts)
      return vorts
    if "Alg2" in a:
      # a = "Bust,Waist,Length&Alg2:S-2XL,88-104,72-88,104-108"
      # a = "Bust,Waist,Length&Alg2:S-2XL,88-104,72-88,104-108&cm"
      # a = "Bust,Waist,Length&Alg2:S-2XL,88.5-104.5,72.5-88.5,104.5-108.5&cm"
      # x, x, x, x
      xz = ""
      if a.endswith("&cm"):
        xz = a


      shints = ["Size"]+[i for i in a.split("&")[0].split(",")]
      r = ["XS","S","M","L","XL","2XL","3XL","4XL","5XL","6XL"]
      chus = r[r.index(a.split("&")[1].replace("Alg2:","").split(",")[0].split("-")[0]):r.index(a.split("&")[1].replace("Alg2:","").split(",")[0].split("-")[1])+1]
      ZAMUS = []
      F = a.split("&")[1].replace("Alg2:","").split(",",1)[1].split(",")     
      vorts = []
      for idx, i in enum(F):
        a,b = i.split("-")
        a = float(a)
        b = float(b)
        t = b- a
        tt = t / (len(chus) - 1)
        ly = a
        o = []
        for j in range(len(chus)):
          if str(ly).endswith(".0"):
            lyy = str(int(ly)) + '"'
          else:
            lyy = str(round(ly,1)) + '"'
          o.append(lyy)
          ly += tt
        o.insert(0, shints[idx+1])
        vorts.append(o)
      vorts.insert(0, ["Size"] + chus)
      if xz.endswith("&cm"):
        for idx,i in enum(vorts):
          for idx2,j in enum(i):
            if j.endswith('"'):
              q = str(round(float(re.findall("[\d\.]+",j)[0])/2.54,2))
              if q.endswith(".0"):
                q = int(q)
              else:
                q = float(q)
              q = str(q)
              vorts[idx][idx2] = q + '"'

      import numpy as np
      vorts = np.transpose(vorts)
      vorts = [list(i) for i in vorts]
      if len(oset(lmap(len,vorts))) != 1:
        print("Error with Size Chart")
        assert False
      if html==True:
        vorts = csv_table_to_html(vorts)
      return vorts

    if "Alg3" in a:
      # a = 'Bust,Waist,Hips&Alg3:S-6XL,80+5*5+7+5+5+5,60+5*5+7+5*2+5,80+5*5+7+5*2+5&cm'
      # a = 'Waist,Hips,Length&Alg3:S-6XL,67+5+5+5+5+5+5+5+5,93+5+5+5+5+5+5+5+5,72.5+0.5+0.5+0.5+0.5+0.5+0.5+0.5+0.5&cm'
      # x-y, x-y, x-y, x-y

      xz = ""
      if a.endswith("&cm"):
        xz = a

      shints = ["Size"]+[i for i in a.split("&")[0].split(",")]
      r = ["XS","S","M","L","XL","2XL","3XL","4XL","5XL","6XL"]
      chus = r[r.index(a.split("&")[1].replace("Alg3:","").split(",")[0].split("-")[0]):r.index(a.split("&")[1].replace("Alg3:","").split(",")[0].split("-")[1])+1]
      ZAMUS = []
      F = a.split("&")[1].replace("Alg3:","").split(",",1)[1].split(",")     
      vorts = []
      for idx, i in enum(F):
        q = []
        start = re.findall("[\d\.]+",i)[0]
        i = re.sub(start,"",i,count=0)
        l = []
        l.extend(re.findall("\+[\d\.]+(?:\*[\d\.]+|)",i))
        start = float(start)
        if str(start).endswith(".0"):
          start = int(start)
        q.append(start)
        for j in l:
          if "*" not in j:
            y = re.findall("\+([\d\.]+)",j)[0]
            y = float(y)
            start += y
            if str(start).endswith(".0"):
              start = int(start)
            q.append(start)
          else:
            x = re.findall("\*([\d\.]+)",j)[0]
            y = re.findall("\+([\d\.]+)",j)[0]
            x = float(x)
            y = float(y)
            for r in range(x):
              start += y
              if str(start).endswith(".0"):
                start = int(start)
              q.append(start)
        vorts.append(q)
      for idx, i in enum(vorts):
        for idx2, j in enum(i[:-1]):
          if "&cm" in a:
            j = round(float(j/2.54),2)
            if str(j).endswith(".0"):
              j = str(int(j))
            else:
              j = str(float(j))
          r = i[idx2+1]
          if "&cm" in a:
            r = round(float(r/2.54),2)
            if str(r).endswith(".0"):
              r = str(int(r))
            else:
              r = str(float(r))
          vorts[idx][idx2] = '%s" - %s"'%(j,r)
        vorts[idx].pop(-1)

      import numpy as np
      vorts = np.transpose(vorts)
      vorts = [list(i) for i in vorts]
      for idx, i in enum(vorts):
        i.insert(0, chus[idx])
      vorts = [shints] + vorts
      if len(oset(lmap(len,vorts))) != 1:
        print("Error with Size Chart")
        assert False
      if html==True:
        vorts = csv_table_to_html(vorts)
      return vorts

    if "Alg4" in a:
      # a = 'Bust,Waist,Hips&Alg4:S-6XL,80+5*5+7+5+5,60+5*5+7+5*2,80+5*5+7+5*2&cm'
      # a = 'Waist,Hips,Length&Alg4:S-6XL,67+5+5+5+5+5+5+5+5,93+5+5+5+5+5+5+5+5,72.5+0.5+0.5+0.5+0.5+0.5+0.5+0.5+0.5&cm'
      # x, x, x, x
      xz = ""
      if a.endswith("&cm"):
        xz = a

      shints = ["Size"]+[i for i in a.split("&")[0].split(",")]
      r = ["XS","S","M","L","XL","2XL","3XL","4XL","5XL","6XL"]
      chus = r[r.index(a.split("&")[1].replace("Alg4:","").split(",")[0].split("-")[0]):r.index(a.split("&")[1].replace("Alg4:","").split(",")[0].split("-")[1])+1]
      ZAMUS = []
      F = a.split("&")[1].replace("Alg4:","").split(",",1)[1].split(",")     
      vorts = []
      for idx, i in enum(F):
        q = []
        start = re.findall("[\d\.]+",i)[0]
        i = re.sub(start,"",i,count=0)
        l = []
        l.extend(re.findall("\+[\d\.]+(?:\*[\d\.]+|)",i))
        start = float(start)
        if str(start).endswith(".0"):
          start = int(start)
        q.append(start)
        for j in l:
          if "*" not in j:
            y = re.findall("\+([\d\.]+)",j)[0]
            y = float(y)
            start += y
            if str(start).endswith(".0"):
              start = int(start)
            q.append(start)
          else:
            x = re.findall("\*([\d\.]+)",j)[0]
            y = re.findall("\+([\d\.]+)",j)[0]
            x = float(x)
            y = float(y)
            for r in range(x):
              start += y
              if str(start).endswith(".0"):
                start = int(start)
              q.append(start)
        vorts.append(q)
      for idx, i in enum(vorts):
        for idx2, j in enum(i):
          if "&cm" in a:
            j = round(float(j/2.54),2)
            if str(j).endswith(".0"):
              j = str(int(j))
            else:
              j = str(float(j))
          vorts[idx][idx2] = '%s"'%(j)

      import numpy as np
      vorts = np.transpose(vorts)
      vorts = [list(i) for i in vorts]
      if len(oset(lmap(len,vorts))) != 1:
        print("Error with Size Chart")
        assert False
      for idx, i in enum(vorts):
        i.insert(0, chus[idx])
      vorts = [shints] + vorts
      if html==True:
        vorts = csv_table_to_html(vorts)
      return vorts


    #a = '["waist", "chest", "shoulders"]\nS:10,20,30\nM:11,22,33\nL:12,24,35'
    #a = 'waist,chest,shoulders&S:10,20,30&M:11,22,33&L:12,24,35'
    #a = 'Diameter&Adjustable Size:17mm'
    strom = dict(zip(re.findall("(&(?:[0-9]+|[0-9]+[\w]+)):",a), set([generate_one_alphabetical_string() for i in range(10000)]))) # ie &2XL.
    for zeknos, zsadf in strom.items():
      a = a.replace(zeknos, "%s:"%(zsadf))  
    a = Replacements(a, "XXXXXXL", "6XL", "XXXXXL", "5XL", "XXXXL", "4XL", "XXXL", "3XL", "XXL", "2XL")

    #@[2018.12.31 12:05:33 PM]tcer strom
    for zeknos, zsadf in strom.items():
      a = a.replace("%s:"%(zsadf), zeknos, )
    #shints = ["Size"]+[i+" (in)" for i in eval(a.split("&")[0])]
    shints = ["Size"]+[i for i in a.replace("&cm","").split("&")[0].split(",")]
    #stromus = [ [xe.split(":")[0]]+(list(eval(xe.split(":")[1]))) for xe in a[1:]]
    # OSA.log(a)
    stromus = [ [xe.split(":")[0]]+[((i)if("-" not in i)else(i.split("-")[0].strip()+'"' + (" - ") + i.split("-")[1].strip() ))+(ifelseget(lambda:("mm" in i),lambda:"",lambda:'"')) for i in list(map(str,xe.split(":")[1].split(",")))] for xe in a.replace("&cm","").split("&")[1:] ]

    vorts = [shints]+stromus
    if len(oset(lmap(len,vorts))) != 1:
      print("Error with Size Chart")
      assert False


    if a.endswith("&cm"):
      for idx,i in enum(vorts):
        for idx2,j in enum(i):
          if j.endswith('"'):
            q = re.findall("[\d\.]+",j)
            for l in q:
              ll = round(float(l)/2.54,2)
              if str(ll).endswith(".0"):
                ll = str(int(ll))
              else:
                ll = str(float(ll))
              j = j.replace(l, ll)
            vorts[idx][idx2] = j
    #@decidedly inappreciate, csv_table_to_png(vorts)
    if html==True:
      vorts = csv_table_to_html(vorts)
    return vorts
class Graph(object):
  def __init__(self, *args, plot_type='scatterplot',**kwargs):
    import matplotlib.pyplot as plt
    ifdo(lambda:not os.path.exists(homepath("~/.matplotlib")),lambda:os.system("mkdir ~/.matplotlib && touch ~/.matplotlib/matplotlibrc && echo 'backend: agg' >> ~/.matplotlib/matplotlibrc"))
    ifdo(lambda:kwargs.get("newplot")==True,lambda:plt.subplot(self.plot_number))
    ifdo(lambda:plot_type=="lineplot",lambda:plt.plot(*args, "-", label=kwargs.get("label",None)))
    ifdo(lambda:plot_type=="scatterplot",lambda:plt.plot(*args, "."))
    ifdo(lambda:plot_type=="histogram",lambda:plt.hist(*args, bins=20))
    plt.xlabel(kwargs.get("xlabel","x")), plt.ylabel(kwargs.get("ylabel","y")), plt.title(kwargs.get("title","title")), plt.legend()
    plt.show()
class Handles:
  # Basically, it shows the day's sales for all shops, as well and if clicked, shows the adsets.
  def __init__(self):
    import rumps
    from rumps import MenuItem as M
    from rumps import MenuItem
    self.app = rumps.App("🚀",quit_button=Null)
    globals().update(locals())


    self.set_menu()
    #process(  lambda: [time.sleep(6.15), self.set_menu()]  )
    time.sleep(6)
    self.app.run()


  def set_menu(self):
    keys = list(self.app.menu.keys())
    redprint(keys)
    for i in keys:
      self.app.menu.pop(i)
    keycall("Icon",All(Adset))
    keycall("post_handle",All(Adset))
    self.app.menu = [MenuItem("/",callback=lambda _=None:[keycall("post_handle",All(Adset)),keycall("__call__",All(Handle)),self.set_menu()])]+\
                    [
                      MenuItem("[%s]"%(i.reach),icon=Filter(Adset,handle=i.handle)[0].Icon()) for i in keysort("reach",All(Handle),tcer=True)
                    ]
class Headers:
  def verifyheaders(self,headers=None,url=None,text=None,savefile=None,minimal_headers=None):
    saved=copy.deepcopy(headers)
    if minimal_headers:
      minimal_headers.update({i:j for i,j in headers.items() if i in minimal_headers})
      headers = minimal_headers
    print(headers)
    r=requests.get(url,headers=headers,timeout=3)
    if r.url==url and r.status_code==200:
      headers = [print('verified url and status code for %s'%(url)),saved][1]
    else:
      headers = [print('refresh headers'),self.verifyheaders(headers=self.inputheaders(text,savefile=savefile),url=url,text=text,savefile=savefile,minimal_headers=minimal_headers)][1]
    return headers
  def inputheaders(self,text=None,savefile=None):
    headers = [input('Please clip your headers for %s, then press Enter:\n'%(text)),blocktext_to_session_headers(pyperclip.paste().replace('\r',''))].pop()
    ifdo(lambda:savefile,lambda:Pickles().savepickles(headers,savefile))
    return headers
class ImageComp:
  def __call__(self,i1,i2,verbose = False):
    self.verbose = verbose
    # B = pool(Images().download,key("src",product.images))
    # [[[i,j] for j in B if j!=i] for i in B]
    from PIL import Image
    from skimage.measure import compare_ssim as ssim
    import argparse
    import cv2
    import imutils
    import matplotlib.pyplot as plt
    import numpy as np
    g().update(locals())
    self.fn1 = i1
    self.fn2 = i2
    self.i1 = cv2.imread(i1)
    self.i2 = cv2.imread(i2)
    self.resize()
    self.test_pass_score = GLOBAL_IMAGE_COMPARISON_TEST_SCORE
    return self.compare_images()
  def resize(self):
    shape1 = list(self.i1.shape)[:2]
    if self.verbose: redprint("shape1: %s" % shape1)
    shape2 = list(self.i2.shape)[:2]
    if self.verbose: redprint("shape2: %s" % shape2)
    if sum(shape1) > sum(shape2):
      Images().resize_disregard_proportion(shape1[1], shape1[0], self.fn2, self.fn2)
      if self.verbose: redprint("shape1: %s -> %s" % (shape2, (shape1[1], shape1[0])))
      self.i2 = cv2.imread(self.fn2)
      if self.verbose: redprint("reinitializing image %s" % "self.fn2")
      shape2 = list(self.i2.shape)[:2]
      if self.verbose: redprint("shape1: %s, shape2: %s" % (shape1, shape2))
    if sum(shape1) < sum(shape2):
      Images().resize_disregard_proportion(shape2[1], shape2[0], self.fn1, self.fn1)
      if self.verbose: redprint("shape1: %s -> %s" % (shape1, (shape2[1], shape2[0])))
      self.i1 = cv2.imread(self.fn1)
      if self.verbose: redprint("reinitializing image %s" % "self.fn1")
      shape1 = list(self.i1.shape)[:2]
      if self.verbose: redprint("shape1: %s, shape2: %s" % (shape1, shape2))
    else:
      if self.verbose: redprint("images already same size: %s %s" % (shape1, shape2))
  def mse(self):
    import numpy as np
    err = np.sum((self.i1.astype("float") - self.i2.astype("float")) ** 2)
    err /= float(self.i1.shape[0] * self.i1.shape[1])
    return err
  def compare_images_2014(self):
    m = self.mse()
    s = None
    try:s = ssim(self.i1, self.i2)
    except: s = ssim(self.i1, self.i2, multichannel=True)
    if self.verbose: redprint("m, %s s, %s" % (m, s))
    return True if s > self.test_pass_score else False
  def compare_images_2017(self):
    grayA = cv2.cvtColor(self.i1, cv2.COLOR_BGR2GRAY)
    grayB = cv2.cvtColor(self.i2, cv2.COLOR_BGR2GRAY)

    (score, diff) = ssim(grayA, grayB, full=True)
    diff = (diff * 255).astype("uint8")
    if self.verbose: redprint("s: {}".format(score))
    return True if score > self.test_pass_score else False
  def compare_images(self):
    alg1 = self.compare_images_2014()
    alg2 = self.compare_images_2017()
    if self.verbose: redprint("alg1: %s | alg2: %s" % (alg1, alg2))
    return True if(True==alg1==alg2)else(False)
class Inheritance:
  class Inheritor:
    __call__=lambda self,x:[exec("from types import MethodType,ModuleType,FunctionType",globals()),[(bind3(self,b))if(type(b)==FunctionType)else(setitem(self.__dict__,a,b))for a,b in(B.__dict__.items())]]
    pram=lambda self: print("a")
    poof=lambda self: print("AA")
  class B:
    pram=lambda self: print("b")
    poof=lambda self: print("BB")
  """
  a = Inheritor()
  a.pram()
  a.poof()
  a(B)
  a.pram()
  a.poof()
  """
class Itertools:
  def __init__(self):
    import itertools
    import string
    globals().update(locals())
    globals().update({a:getattr(self,a) for a in dir(self)})
  def set_of_ordered_set(self,x,ordered_set_size):
    return list(itertools.permutations(x,ordered_set_size))
    """ test """
    """x = list(range(10))
          ordered_set_size = 3
          a = set_of_ordered_set(x,ordered_set_size)
          print(len(a))
          720"""
  def set_of_unordered_set(self,x,unordered_set_size):
    return list(itertools.combinations(x,unordered_set_size))
    """ test """
    """x = list(range(10))
          unordered_set_size = 3
          b = set_of_unordered_set(x,unordered_set_size)
          print(len(b))
          120"""
  def set_of_unordered_set_with_replacement(self,x,unordered_set_with_replacement_set_size):
    return list(itertools.combinations_with_replacement(x,unordered_set_with_replacement_set_size))
    """ test """
    """x = list(range(10))
          unordered_set_with_replacement_set_size = 3
          c = set_of_unordered_set_with_replacement(x,unordered_set_with_replacement_set_size)
          print(len(c))
          220"""
  def set_of_ordered_and_unordered_and_unordered_with_replacement_set(self,x,ordered_and_unordered_and_unordered_with_replacement_set_size):
    ordered_set = set_of_ordered_set(x,ordered_set_size=ordered_and_unordered_and_unordered_with_replacement_set_size)
    unordered_set = set_of_unordered_set(x,unordered_set_size=ordered_and_unordered_and_unordered_with_replacement_set_size)
    unordered_set_with_replacement = set_of_unordered_set_with_replacement(x,unordered_set_with_replacement_set_size=ordered_and_unordered_and_unordered_with_replacement_set_size)
    x = sum([ordered_set,unordered_set,unordered_set_with_replacement],[])
    # x = set(x)
    x = set(x)
    return x
  def set_of_ordered_and_unordered_and_unordered_with_replacement_set_for_alphabet(self,):
    import string
    x = " ".join(string.ascii_lowercase).split(" ")
    y = set_of_ordered_and_unordered_and_unordered_with_replacement_set(x,ordered_and_unordered_and_unordered_with_replacement_set_size=4)
    z = set(y)
    a = ["".join(i) for i in z]
    return a
    """ test """
    """x = set_of_ordered_and_unordered_and_unordered_with_replacement_set_for_alphabet()
                In [45]: len(x)
                Out[45]: 367601"""
  def set_product(self,x,repeat_set_size):
    """ ::: lol try out [1,2,3,2,1],3 . your first thing, it had 25, this has 27. This seems to be that thing which you would have wanted. ::: """
    x = list(itertools.product(x,repeat=repeat_set_size))
    return x
class LinReg:
  def __init__(self):
    from sklearn.linear_model import LinearRegression
    globals().update(locals())
  def fit(self, X, y):
    self.X = X
    self.y = y
    self.LinReg = LinearRegression()
    self.LinReg.fit(X,y)
  def score(self):
    print(  self.LinReg.score(self.X,self.y)  )
  def predict(self, x):
    y = self.LinReg.predict([[x]])
    return y
  def dictlist_predict(self,x,fields,y_field):
    X = []
    for i in x:
      X.append([i[v] for v in fields])
    y = [i[y_field] for i in x]
    new = LinReg()
    new.fit(X,y)
    return new
class LinkedInScraper(object):
  def __call__(you):
    return("")
    print("Shrooms?")
class Locations:
  states = { 'AK': 'Alaska', 'AL': 'Alabama', 'AR': 'Arkansas', 'AS': 'American Samoa', 'AZ': 'Arizona', 'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DC': 'District of Columbia', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'GU': 'Guam', 'HI': 'Hawaii', 'IA': 'Iowa', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'MA': 'Massachusetts', 'MD': 'Maryland', 'ME': 'Maine', 'MI': 'Michigan', 'MN': 'Minnesota', 'MO': 'Missouri', 'MP': 'Northern Mariana Islands', 'MS': 'Mississippi', 'MT': 'Montana', 'NA': 'National', 'NC': 'North Carolina', 'ND': 'North Dakota', 'NE': 'Nebraska', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NV': 'Nevada', 'NY': 'New York', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'PR': 'Puerto Rico', 'RI': 'Rhode Island', 'SC': 'South Carolina', 'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VA': 'Virginia', 'VI': 'Virgin Islands', 'VT': 'Vermont', 'WA': 'Washington', 'WI': 'Wisconsin', 'WV': 'West Virginia', 'WY': 'Wyoming'}
  _country_code_dict = {
    'c0': 'US',
    'c1': 'CA,AU,UK,NZ',
    'c2': 'CN,TW,HK,SG,JP,UA,RU',
    'c3': 'AE,QA,SA,GU,BH,AF,GU,IQ,TT,MC,PR,LB,TR,DM,MV,KH,MT,KW',
    'c4': 'AT,CH,DK,SK,CZ,BE,FR,NO,SE'}
  country_code_dict = {
    'AD': 'Andorra', 'AE': 'United Arab Emirates', 'AF': 'Afghanistan', 'AG': 'Antigua and Barbuda', 'AI': 'Anguilla', 'AL': 'Albania', 'AM': 'Armenia', 'AO': 'Angola', 'AQ': 'Antarctica', 'AR': 'Argentina', 'AS': 'American Samoa', 'AT': 'Austria', 'AU': 'Australia', 'AW': 'Aruba', 'AX': 'Aland Islands', 'AZ': 'Azerbaijan', 'BA': 'Bosnia and Herzegovina', 'BB': 'Barbados', 'BD': 'Bangladesh', 'BE': 'Belgium', 'BF': 'Burkina Faso', 'BG': 'Bulgaria', 'BH': 'Bahrain', 'BI': 'Burundi', 'BJ': 'Benin', 'BL': 'Saint Barthélemy', 'BM': 'Bermuda', 'BN': 'Brunei Darussalam', 'BR': 'Brazil', 'BS': 'Bahamas', 'BT': 'Bhutan', 'BV': 'Bouvet Island', 'BW': 'Botswana', 'BY': 'Belarus', 'BZ': 'Belize', 'CA': 'Canada', 'CC': 'Cocos (Keeling) Islands', 'CF': 'Central African Republic', 'CG': 'Congo', 'CH': 'Switzerland', 'CI': "Côte d'Ivoire", 'CK': 'Cook Islands', 'CL': 'Chile', 'CM': 'Cameroon', 'CN': 'China', 'CO': 'Colombia', 'CR': 'Costa Rica', 'CU': 'Cuba', 'CV': 'Cape Verde', 'CW': 'Curaçao', 'CX': 'Christmas Island', 'CY': 'Cyprus', 'CZ': 'Czech Republic', 'DE': 'Germany', 'DJ': 'Djibouti', 'DK': 'Denmark', 'DM': 'Dominica', 'DO': 'Dominican Republic', 'DZ': 'Algeria', 'EC': 'Ecuador', 'EE': 'Estonia', 'EG': 'Egypt', 'EH': 'Western Sahara', 'ER': 'Eritrea', 'ES': 'Spain', 'ET': 'Ethiopia', 'FI': 'Finland', 'FJ': 'Fiji', 'FK': 'Falkland Islands (Malvinas)', 'FO': 'Faroe Islands', 'FR': 'France', 'GA': 'Gabon', 'GB': 'United Kingdom', 'GD': 'Grenada', 'GE': 'Georgia', 'GF': 'French Guiana', 'GG': 'Guernsey', 'GH': 'Ghana', 'GI': 'Gibraltar', 'GL': 'Greenland', 'GM': 'Gambia', 'GN': 'Guinea', 'GP': 'Guadeloupe', 'GQ': 'Equatorial Guinea', 'GR': 'Greece', 'GS': 'South Georgia and the South Sandwich Islands', 'GT': 'Guatemala', 'GU': 'Guam', 'GW': 'Guinea-Bissau', 'GY': 'Guyana', 'HK': 'Hong Kong', 'HM': 'Heard Island and McDonald Islands', 'HN': 'Honduras', 'HR': 'Croatia', 'HT': 'Haiti', 'HU': 'Hungary', 'ID': 'Indonesia', 'IE': 'Ireland', 'IL': 'Israel', 'IM': 'Isle of Man', 'IN': 'India', 'IO': 'British Indian Ocean Territory', 'IQ': 'Iraq', 'IS': 'Iceland', 'IT': 'Italy', 'JE': 'Jersey', 'JM': 'Jamaica', 'JO': 'Jordan', 'JP': 'Japan', 'KE': 'Kenya', 'KG': 'Kyrgyzstan', 'KH': 'Cambodia', 'KI': 'Kiribati', 'KM': 'Comoros', 'KN': 'Saint Kitts and Nevis', 'KW': 'Kuwait', 'KY': 'Cayman Islands', 'KZ': 'Kazakhstan', 'LA': "Lao People's Democratic Republic", 'LB': 'Lebanon', 'LC': 'Saint Lucia', 'LI': 'Liechtenstein', 'LK': 'Sri Lanka', 'LR': 'Liberia', 'LS': 'Lesotho', 'LT': 'Lithuania', 'LU': 'Luxembourg', 'LV': 'Latvia', 'LY': 'Libya', 'MA': 'Morocco', 'MC': 'Monaco', 'ME': 'Montenegro', 'MF': 'Saint Martin (French part)', 'MG': 'Madagascar', 'MH': 'Marshall Islands', 'ML': 'Mali', 'MM': 'Myanmar', 'MN': 'Mongolia', 'MO': 'Macao', 'MP': 'Northern Mariana Islands', 'MQ': 'Martinique', 'MR': 'Mauritania', 'MS': 'Montserrat', 'MT': 'Malta', 'MU': 'Mauritius', 'MV': 'Maldives', 'MW': 'Malawi', 'MX': 'Mexico', 'MY': 'Malaysia', 'MZ': 'Mozambique', 'NA': 'Namibia', 'NC': 'New Caledonia', 'NE': 'Niger', 'NF': 'Norfolk Island', 'NG': 'Nigeria', 'NI': 'Nicaragua', 'NL': 'Netherlands', 'NO': 'Norway', 'NP': 'Nepal', 'NR': 'Nauru', 'NU': 'Niue', 'NZ': 'New Zealand', 'OM': 'Oman', 'PA': 'Panama', 'PE': 'Peru', 'PF': 'French Polynesia', 'PG': 'Papua New Guinea', 'PH': 'Philippines', 'PK': 'Pakistan', 'PL': 'Poland', 'PM': 'Saint Pierre and Miquelon', 'PN': 'Pitcairn', 'PR': 'Puerto Rico', 'PT': 'Portugal', 'PW': 'Palau', 'PY': 'Paraguay', 'QA': 'Qatar', 'RE': 'Réunion', 'RO': 'Romania', 'RS': 'Serbia', 'RU': 'Russian Federation', 'RW': 'Rwanda', 'SA': 'Saudi Arabia', 'SB': 'Solomon Islands', 'SC': 'Seychelles', 'SD': 'Sudan', 'SE': 'Sweden', 'SG': 'Singapore', 'SI': 'Slovenia', 'SJ': 'Svalbard and Jan Mayen', 'SK': 'Slovakia', 'SL': 'Sierra Leone', 'SM': 'San Marino', 'SN': 'Senegal', 'SO': 'Somalia', 'SR': 'Suriname', 'SS': 'South Sudan', 'ST': 'Sao Tome and Principe', 'SV': 'El Salvador', 'SX': 'Sint Maarten (Dutch part)', 'SY': 'Syrian Arab Republic', 'SZ': 'Swaziland', 'TC': 'Turks and Caicos Islands', 'TD': 'Chad', 'TF': 'French Southern Territories', 'TG': 'Togo', 'TH': 'Thailand', 'TJ': 'Tajikistan', 'TK': 'Tokelau', 'TL': 'Timor-Leste', 'TM': 'Turkmenistan', 'TN': 'Tunisia', 'TO': 'Tonga', 'TR': 'Turkey', 'TT': 'Trinidad and Tobago', 'TV': 'Tuvalu', 'UA': 'Ukraine', 'UG': 'Uganda', 'UM': 'United States Minor Outlying Islands', 'US': 'United States', 'UY': 'Uruguay', 'UZ': 'Uzbekistan', 'VA': 'Holy See (Vatican City State)', 'VC': 'Saint Vincent and the Grenadines', 'VN': 'Viet Nam', 'VU': 'Vanuatu', 'WF': 'Wallis and Futuna', 'WS': 'Samoa', 'YE': 'Yemen', 'YT': 'Mayotte', 'ZA': 'South Africa', 'ZM': 'Zambia', 'ZW': 'Zimbabwe'}
  canada_province_codes = {
    'AB' : 'Alberta', 'BC' : 'British Columbia', 'MB' : 'Manitoba', 'NB' : 'New Brunswick', 'NL' : 'Newfoundland and Labrador', 'NS' : 'Nova Scotia', 'NT' : 'Northwest Territories', 'NU' : 'Nunavut', 'ON' : 'Ontario', 'PE' : 'Prince Edward Island', 'QC' : 'Quebec', 'SK' : 'Saskatchewan', 'YT' : 'Yukon'}
  def get_state(self,io):
    return self.states[io]if(2==len(io))else(dict(zip(self.states.values(),self.states.keys()))[io])
  def get_country(self,io):
    return self.country_code_dict[io]if(2==len(io))else(dict(zip(self.country_code_dict.values(),self.country_code_dict.keys()))[io])
  def get_canada_provinces(self,io):
    return self.canada_province_codes[io]if(2==len(io))else(dict(zip(self.canada_province_codes.values(),self.canada_province_codes.keys()))[io])
  globals().update(locals())
  """
  print("AK -> %s" % (Locations().get_state("AK")))
  print("Alaska -> %s" % (Locations().get_state("Alaska")))
  print("AD -> %s" % (Locations().get_country("AD")))
  print("Andorra -> %s" % (Locations().get_country("Andorra")))
  print("AB -> %s" % (Locations().get_canada_provinces("AB")))
  print("Alberta -> %s" % (Locations().get_canada_provinces("Alberta")))
  """
class MelaniaTrump(object):
  def __call__(self):
    return MelaniaTrump()
  def __getattribute__(self,*args):
    return MelaniaTrump()()
class My_Matplotlib(object):
  def __init__(self):
    import matplotlib.pyplot as plt
    globals().update(locals())
    self.plot_number = 211
  def plot(self, *args, plot_type='scatterplot',**kwargs):
    plt.subplot(self.plot_number)if(True==kwargs.get("newplot",False))else(None)
    if plot_type == 'lineplot':
      plt.plot(*args, '-', label=kwargs.get("label",None))
    elif plot_type == 'scatterplot':
      plt.plot(*args, '.')
    elif plot_type == 'histogram':
      plt.hist(*args, bins=20)

    plt.xlabel(kwargs.get("xlabel","x"))
    plt.ylabel(kwargs.get("ylabel","y"))
    plt.title(kwargs.get("title","title"))
    plt.legend()

    if kwargs.get("newplot",False) == True: self.plot_number = self.plot_number + 1

    return
    """ ::: Caffeine example (12 hours) ::: """
    x = My_Matplotlib()
    x.plot([100, 200, 180, 140, 120, 110, 100, 100, 100, 100, 100, 100], newplot=False, label="alertness")
    x.show()

  def histogram_example(self):
    population_ages = list(range(18,65))
    ids = [x for x in range(len(population_ages))]
    bins = list(range(10,100, 10))
    plt.hist(population_ages, bins=10, histtype="bar", rwidth=0.8)
    plt.show()
  def pairplot(self, data, headers):
    import pandas as pd
    import seaborn as sb
    import matplotlib.pyplot as plt
    # %matplotlib tk
    CSV().DictWriteWithHeaders("tmp.csv", data, headers, delimiter = "\t")
    data = pd.read_csv("tmp.csv", delimiter = "\t")
    sb.pairplot(data)
    plt.show()
    os.system("rm tmp.csv")
  def barchart(self, x_indices=[0,1,2,3,4], y_indices=[10,5,10,5,10], **kwargs):
    #x_indices=[0,1,2,3,4]
    #y_indices=[10,5,10,5,10],
    import matplotlib.pyplot as plt
    plt.bar(x_indices, y_indices)

    plt.ylabel(kwargs.get("ylabel"))if("ylabel" in kwargs)else(1)
    plt.xticks(list(range(len(kwargs.get("xticks")))), kwargs.get("xticks"))if("xticks" in kwargs)else(1)
    plt.title(kwargs.get("title"))if("title" in kwargs)else(1)

    plt.show()
    # kwargs may include:
    # 1. align="center"
    # 2. alpha="0.5"
  def show(self):
    plt.show()
class My_Meditations:
  def __init__(self):
    self.fuckboi = Browser()("sele",65)
  def wtf(self):
    OSA.log("LOL",tp=1-0)
class On_Exec:
  """ shows that if you use exec whilst locals are there, post-exec locals stay as pre-exec, even if used in exec. so exec needs to use new keys. """
  "pre-exec"
  def versioncheck(x):
    exec("import selenium; bprint(selenium.__version__); x = selenium.__version__",globals())
    return x
  def quadim1(x):
    exec("y = 5",globals())
    print(y)
    return y
  def quadim2(x):
    exec("x = 5",globals())
    print(x)
    return x
  def quadim3(x):
    exec("y = 5",globals())
    print(y)
    return y
class Updater:
  __init__ = lambda self: self.__dict__.update(
    {
    "GhostProductUpdate": lambda: 0==(Time()-Time(max(key("last_check",Filter(GhostProductUpdate,shop=Muta()().store_abbre))+[(Date()-100)()]))).days or GhostProduct().productghosts(Muta()().store_abbre),
    "ProductsFeed": lambda: 0==(Time()-Time(max(key("last_check",Filter(ProductsFeed,shop=Muta()().store_abbre))+[(Date()-100)()]))).days or ProductsFeed().ProductsFeed(Muta()().store_abbre),
    "LineitemsFeed": lambda: 0==(Time()-Time(max(key("last_check",Filter(LineitemsFeed,shop=Muta()().store_abbre))+[(Date()-100)()]))).days or LineitemsFeed().LineitemsFeed(Muta()().store_abbre),
    "AdsetUpdates": lambda: lmap(lambda i: 2>=(Time()-Time(or_list(i.last_check,(Time()-100)()))).hours() or July_Adset_Utilities().update_advertisement_all(id=i.id), Filter(Adset,shop_abbreviation=Muta()().store_abbre)),
    "LineitemUpdates": lambda: lmap(lambda i: 3>=(Time()-Time(or_list(i.last_check,(Time()-100)()))).hours() or Get(Lineitem,id=i.id).update_tracker_data(), Filter(Lineitem,shop=Muta()().store_abbre)),
    "Aliexpressorder_update": lambda: 0==(Time()-Time(max(key("last_check",Filter(Aliexpressorder_update,shop=Muta()().store_abbre))+[(Date()-100)()]))).days or Aliexpressorderpager().get_urls((Date()-7)(),(Date()-0)(),get_order_info=False),
    "ProductUpdates": lambda: lmap(lambda i: 2>=(Time()-Time(or_list(i.last_check,(Time()-100)()))).days or i.Refresh() , Filter(Product,shop=Muta()().store_abbre)),
    "New_EmailUpdates": lambda: New_Email().new_email_set(Muta()().store_abbre),
    "Aliexpressorder_event_update": lambda: Aliexpressorder_event().run(Muta()().store_abbre),
    "Update_TertiaryActions": lambda: TertiaryAction().add(Muta()().store_abbre),
    "Update_Payments": lambda: Payment().add(),
    "Update_Payouts": lambda: Payout().add(),
    })
  def GhostProductUpdate(self):
    for i in All(Shop):
      GhostProduct().productghosts(i.shop_abbreviation)
  def ProductsFeed(self):
    for i in All(Shop):
      ProductsFeed().ProductsFeed(i.shop_abbreviation)
  def LineitemsFeed(self):
    for i in All(Shop):
      LineitemsFeed().LineitemsFeed(i.shop_abbreviation)
  def AdsetUpdates(self):
    for a in All(Shop):
      for b in Filter(Adset,shop_abbreviation=a.shop_abbreviation):
        July_Adset_Utilities().update_advertisement_all(id=b.id)
  def LineitemUpdates(self):
    for a in All(Shop):
      for b in Filter(Lineitem,shop=a.shop_abbreviation):
        Get(Lineitem,id=b.id).update_tracker_data()
  """
  0==(Time()-Time(max(key("last_check",All(GhostProductUpdate))+[(Date()-100)()]))).days or GhostProduct().productghostsall()
  0==(Time()-Time(max(key("last_check",All(Aliexpressorder_update))+[(Date()-100)()]))).days or Aliexpress_Core(ph=False).get_urls(7,0)
  0==(Time()-Time(max(key("last_check",All(ProductsFeed))+[(Date()-100)()]))).days or ProductsFeed().ProductsFeedAll()
  0==(Time()-Time(max(key("last_check",All(LineitemsFeed))+[(Date()-100)()]))).days or LineitemsFeed().LineitemsFeedAll()
  lmap(lambda i: 2>=(Time()-Time(or_list(i.last_check,(Time()-100)()))).days or Aliexpress_Products().refresh_product_inventory(i.id) , All(Product))
  Updater().GhostProductUpdate()
  """
class Pickles:
  def savepickles(self,*args,**kws):
    pickle.dump([i for i in args if type(i)!=str][0],open([i for i in args if type(i)==str][0],'wb'))
    ifdo(lambda:kws.get('copypickles'),lambda:Pickles().savepickles([i for i in args if type(i)!=str][0],kws['copypickles']))
    return args[0]
  def loadpickles(self,*args,**kws):
    ifdo(lambda:os.path.exists(args[0])==False,lambda:Pickles().savepickles(kws.get('default'),args[0]) )
    return pickle.load(open(args[0],'rb'))
  def solodump(self,obj,io,**kwargs):
    pickles=Pickles().loadpickles(io,default=[])
    identifier = kwargs['identifier']
    print(obj,identifier)
    possible_id=obj[identifier]
    news=key(identifier,pickles)
    q=None
    if possible_id in news:
      q=[i for i in pickles if i[identifier]==obj[identifier]][0]
    else:
      None
    if q==None:
      pickles.append(obj)
    else:
      indexer=pickles.index(q)
      pickles[indexer]=obj
    Pickles().savepickles(pickles,io,copypickles='store/%s%s'%(str(Time()).replace(':',''),io))
    return obj
#x=[{'id':1,'fn':2}]
#Pickles().savepickles(x,'lol.pkl')
class Psutil(DecisionTree):
  def tests(self):
    builtin_print(        "net_connections #1: %s" % str(self.net_connections()[0])                                   )
    builtin_print(        "net_io_counters: %s" % str(self.net_io_counters())                                         )
    builtin_print(        "sensors_battery: %s" % str(self.sensors_battery())                                         )
    builtin_print(        "boot_time: %s" % str(self.boot_time())                                                     )
    builtin_print(        "virtual_memory: %s" % str(self.virtual_memory())                                           )
    builtin_print(        "cpu_count: %s" % str(self.cpu_count())                                                     )
    builtin_print(        "disk_partitions: %s" % str(self.disk_partitions())                                         )
    builtin_print(        "disk_usage: %s" % str(self.disk_usage())                                                   )
    builtin_print(        "GetHumanReadable: %s" % str(self.GetHumanReadable(self.disk_usage().total))                )
  def get_network_interface(self):
    x = subprocess.getoutput("route get 10.10.10.10")
    redprint("route get 10.10.10.10\n==RESULT==\n\n{}\n\n".format(x))
    return re.findall(r"interface: (.*)", x)[0]
  def get_mac_lan_ip_address(self):
    w = "ipconfig getifaddr {}".format(self.get_network_interface())
    x = subprocess.getoutput(w)
    redprint("{}\n==RESULT==\n\n{}\n\n".format(w,x))
    return x
  def nmap(self):
    w = "sudo nmap -sP {}.1/24".format(Join(".",self.get_mac_lan_ip_address().split(".")[:3]))
    x = subprocess.getoutput(w)
    z = re.findall(r"Nmap scan report for (.*) .*\((.*)\)",x)
    redprint("{}\n==result\n\n{}\n\n{}\n\n".format(w,x,json.dumps(z,indent=4)))
    return z
  def nonsudo_nmap(self):
    w = "nmap -sP {}.1/24".format(Join(".",self.get_mac_lan_ip_address().split(".")[:3]))
    x = subprocess.getoutput(w)
    z = re.findall(r"Nmap scan report for (.*) .*\((.*)\)",x)
    redprint("{}\n==result\n\n{}\n\n{}\n\n".format(w,x,json.dumps(z,indent=4)))
    return z
  def nmap_consistent(self,c=1):
    while True:
      if(len(self.nonsudo_nmap())) != c:
        OSA().notify("lol")
  def net_connections(self):
    return psutil.net_connections(kind='inet')
  def net_io_counters(self):
    return psutil.net_io_counters(pernic=False, nowrap=True)
  def sensors_battery(self):
    return psutil.sensors_battery()
  def boot_time(self):
    psutil.boot_time()
    import datetime
    datetime.datetime.fromtimestamp(psutil.boot_time()).strftime("%Y-%m-%d %H:%M:%S")
    """ '2018-08-29 04:23:28' """
  def virtual_memory(self):
    mem = psutil.virtual_memory()
    return mem
  def cpu_count(self):
    return psutil.cpu_count()
    """ 8 """
  def disk_partitions(self):
    return psutil.disk_partitions()
  def disk_usage(self):
    return psutil.disk_usage("/")
  @staticmethod
  def GetMachineReadable(HumanReadable):
    suffixes=['B','KB','MB','GB','TB']
    x = int(re.findall("[0-9]+",HumanReadable)[0])
    y = re.findall(r"[a-zA-Z]+",HumanReadable)[0]
    z = suffixes.index(y)
    for i in range(z):
      x = x*1024
    return x
  @staticmethod
  def GetHumanReadable(size,precision=2):
    suffixes=['B','KB','MB','GB','TB']
    suffixIndex = 0
    while size > 1024 and suffixIndex < 4:
      suffixIndex += 1 #increment the index of the suffix
      size = size/1024.0 #apply the division
    return "%.*f%s"%(precision,size,suffixes[suffixIndex])
  def GetLetterReadable(self,v):
    return v if v<= 999 else(str(int(v/1000)) + "K")if(1000 <= v <= 999999)else(str(int(v/1000000)) + "M")if(1000000 <= v <= 999999999)else(str(int(v/1000000000)) + "B")if(1000000000 <= v <= 999999999999)else("?")
    """ tests """
    for i in [0,999,1000,50000,500000,5000000,5000000000,50000000,50000000000,5000000000000,6456498098,123491823,123123]:
      print(x(i))
  def SpeedTest(self, download = True, upload = True, verbose = True):
    start_time = datetime.now()

    import speedtest

    servers = []
    # If you want to test against a specific server
    # servers = [1234]

    s = speedtest.Speedtest()
    s.get_servers(servers)
    s.get_best_server()
    if download == True:
      s.download()
    if upload == True:
      s.upload()
    s.results.share()

    results_dict = s.results.dict()
    results_dict = AttrDict(results_dict)

    end_time = datetime.now()
    elapsed_time = end_time.__sub__(start_time)
    elapsed_time_seconds = elapsed_time.seconds
    elapsed_time_microseconds = elapsed_time.microseconds / 1000000
    elapsed_time_full = elapsed_time_seconds + elapsed_time_microseconds
    elapsed_time_full = round(elapsed_time_full, 2)
    time.sleep(1)
    if verbose == True:
      greenprint("speed test results time taken: %s seconds" % elapsed_time_full)
    if verbose == True:
      greenprint("")
    time.sleep(1)
    if verbose == True:
      greenprint(":Results:")

    download_speed = None
    download_speed_readable = None
    if download == True:
      download_speed = results_dict.download
      download_speed_readable = Psutil().GetLetterReadable(download_speed)
      if verbose == True:
        greenprint("download speed: %s" % download_speed_readable)

    upload_speed = None
    upload_speed_readable = None
    if upload == True:
      upload_speed = results_dict.upload
      upload_speed_readable = Psutil().GetLetterReadable(upload_speed)
      if verbose == True:
        greenprint("upload speed: %s" % upload_speed_readable)

    if download == True and upload == True:
      return download_speed_readable, upload_speed_readable
    elif download == True and upload == False:
      return download_speed_readable
    elif download == False and upload == True:
      return upload_speed_readable
    else:
      return None
    """ :Test:
    results = []
    results.append(Psutil().SpeedTest(download = True, upload = True))
    results.append(Psutil().SpeedTest(download = True, upload = False))
    results.append(Psutil().SpeedTest(download = False, upload = True))
    results.append(Psutil().SpeedTest(download = False, upload = False))
    assert len(results[0]) == 2
    assert results[1]
    assert results[2]
    assert results[3] == None
    greenprint(results)
    """
class RandomWord:
  def __init__(self):
    x = get_random_word()
    print(x)
    os.system("say '[[volm 0.35]] %s'"%(x))
    [os.system("say '[[volm 0.35]] %s'"%(i)) for i in " ".join(x).split(" ")]
    try:
      y = dictionarymeaning(x)
      print(y)
      os.system('say """[[volm 0.35]] %s"""'%(y))
    except Exception as e:
      pass
    RandomGeneratedWords().add(x)
    print("")
class SkuAlgorithm:
  a1 = lambda self, x, **kwargs: [setitem(kwargs,"a","".join(lmap(str,lmap(ord, shuffled(x))))),exec("assert len(kwargs['a']) <=255"),((kwargs["a"])if(kwargs["a"] not in key("nsku",All(Sku)))else(self.a1(x)) )][2]
  a2 = lambda self, x, **kwargs: [setitem(kwargs,"a","-".join([generate_one_alphabetical_string(3),generate_one_alphabetical_string(4),generate_one_alphabetical_string(4)]).upper()),exec("assert len(kwargs['a']) <=255"),((kwargs["a"])if(kwargs["a"] not in key("nsku",All(Sku)))else(self.a2(x)))][2]
  a3 = lambda self, x, **kwargs: [setitem(kwargs,"a","-".join([generate_one_random_number(3),generate_one_random_number(4),generate_one_random_number(4)]).upper()),exec("assert len(kwargs['a']) <=255"),((kwargs["a"])if(kwargs["a"] not in key("nsku",All(Sku)))else(self.a3(x)))][2]
  a4 = lambda self, x, **kwargs: [setitem(kwargs,"a","-".join([generate_one_random_number(3),generate_one_alphabetical_string(4),generate_one_alphabetical_string(4)]).upper()),exec("assert len(kwargs['a']) <=255"),((kwargs["a"])if(kwargs["a"] not in key("nsku",All(Sku)))else(self.a4(x)))][2]
  a5 = lambda self, x, **kwargs: [setitem(kwargs,"a","-".join([generate_one_random_number(7),generate_one_alphabetical_string(2),generate_one_alphabetical_string(5)]).upper()),exec("assert len(kwargs['a']) <=255"),((kwargs["a"])if(kwargs["a"] not in key("nsku",All(Sku)))else(self.a5(x)))][2]
  a6 = lambda self, x, **kwargs: [setitem(kwargs,"a",(generate_one_alphabetical_string(2)+"{"+generate_one_random_number(4)+"}"+";"+generate_one_alphabetical_string(10)).upper()),exec("assert len(kwargs['a']) <=255"),((kwargs["a"])if(kwargs["a"] not in key("nsku",All(Sku)))else(self.a6(x)))][2]
  a7 = lambda self, x, **kwargs: [setitem(kwargs,"a",("".join(lmap(str,[random.randrange(7,10) for i in range(3)]))+"$"+generate_one_alphanumeric_string(10)).upper()),exec("assert len(kwargs['a']) <=255"),((kwargs["a"])if(kwargs["a"] not in key("nsku",All(Sku)))else(self.a7(x)))][2]
  rnda = lambda self: getattr(self, random.choice([i for i in dir(self) if i.startswith("a")]))
  """
  blueprint(SkuAlgorithm().a1('["sku-1-123", "sku-2-asdfjpmv2912"]'))
  blueprint(SkuAlgorithm().a2('["sku-1-123", "sku-2-asdfjpmv2912"]'))
  blueprint(SkuAlgorithm().a3('["sku-1-123", "sku-2-asdfjpmv2912"]'))
  blueprint(SkuAlgorithm().a4('["sku-1-123", "sku-2-asdfjpmv2912"]'))
  blueprint(SkuAlgorithm().a5('["sku-1-123", "sku-2-asdfjpmv2912"]'))
  blueprint(SkuAlgorithm().a6('["sku-1-123", "sku-2-asdfjpmv2912"]'))
  blueprint(SkuAlgorithm().a7('["sku-1-123", "sku-2-asdfjpmv2912"]'))
  """
class Speech_Recognition:
  @timeit
  def recognize_sphinx(self, AUDIO_FILE, language="en-US"):
    import speech_recognition as sr

    # obtain path to "english.wav" in the same folder as this script
    from os import path

    #AUDIO_FILE = "out.wav"#path.join(path.dirname(path.realpath(__file__)), "out.wav")
    # AUDIO_FILE = path.join(path.dirname(path.realpath(__file__)), "french.aiff")
    # AUDIO_FILE = path.join(path.dirname(path.realpath(__file__)), "chinese.flac")

    # use the audio file as the audio source
    r = sr.Recognizer()
    with sr.AudioFile(AUDIO_FILE) as source:
      audio = r.record(source) # read the entire audio file

    # recognize speech using Sphinx
    try:
      print("Sphinx thinks you said " + r.recognize_sphinx(audio, language="fr-FR"))
    except sr.UnknownValueError:
      print("Sphinx could not understand audio")
    except sr.RequestError as e:
      print("Sphinx error; {0}".format(e))

  @timeit
  def recognize_google(self, AUDIO_FILE = "out.wav", language="en-US"):
    import speech_recognition as sr

    # obtain path to "english.wav" in the same folder as this script
    from os import path

    #AUDIO_FILE = "out.wav"#path.join(path.dirname(path.realpath(__file__)), "out.wav")

    # use the audio file as the audio source
    r = sr.Recognizer()
    with sr.AudioFile(AUDIO_FILE) as source:
      audio = r.record(source) # read the entire audio file

    # recognize speech using Google Speech Recognition
    try:
      # for testing purposes, we're just using the default API key
      # to use another API key, use `r.recognize_google(audio, key="GOOGLE_SPEECH_RECOGNITION_API_KEY")`
      # instead of `r.recognize_google(audio)`
      print("Google Speech Recognition thinks you said " + r.recognize_google(audio))
    except sr.UnknownValueError:
      print("Google Speech Recognition could not understand audio")
    except sr.RequestError as e:
      print("Could not request results from Google Speech Recognition service; {0}".format(e))
class SED(DecisionTree):
  def SED_RECURSIVELY(self):
    import glob
    dir = input("dir?: ")
    os.chdir(dir)
    ext = input("ext?: ")
    old = input("old?: ")
    new = input("new?: ")
    os.chdir("../")
    files = glob.glob('**/*%s'%ext, recursive=True)
    print(files)
    old = old.replace("/", "\\/")
    new = new.replace("/", "\\/")
    for fn in files:
      system("sed -i '' -e s/%s/%s/g %s"%(old,new,fn))
  def SED(self):
    file = input("file?: ")
    old = input("old?: ")
    new = input("new?: ")
    os.chdir("../")
    old = old.replace("/", "\\\/")
    new = new.replace("/", "\\\/")
    the_string = "sed -i '' -e s/%s/%s/g %s"%(old,new,file)
    print("the string: %s" % the_string)
    os.system(the_string)
class SimpleRequester:
  def __init__(self):
    self.proxy_list = get_us_ip_list()
    self.s = requests.Session()
    self.s.headers = {"User-Agent": "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.1242123123.com/bot.html)", "authority": "www.aliexpress.com", "upgrade-insecure-requests": "1",}
    self.count_current_tries = 0

  def get(self, url, textNot="ø"*3, urlNot="ø"*3, status_codeNotNot=200, use_proxy=False, cookies={}):
    [self.s.cookies.set(k,v) for k,v in cookies.items()]

    r  = None
    if use_proxy == False:
      try:
        r = self.s.get(url, timeout=4)
        redprint("\nProxy:%s\nUrl:%s\nr.text.find('%s'):%s\nr.url.find('%s'):%s\nstatus_code:%s\nstatus_codeNotNot:%s\ncount_current_tries:%s" % ("ø",url,textNot,r.text.find(textNot),urlNot,r.url.find(urlNot),r.status_code,status_codeNotNot,self.count_current_tries ))
      except Exception as e:
        redprint(str(e)[:100])

        ######
        self.proxy_list.append(self.proxy_list.__getitem__(0 ))
        self.proxy_list.__delitem__(0 )
        # this may look confusing. and it is. now. keep in mind. what it looked like before, is this:  'class SimpleRequester:\n  def __init__(self):\n    self.proxy_list = get_us_ip_list()\n    self.s = requests.Session()\n    self.s.headers = {"User-Agent": "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.1242123123.com/bot.html)", "authority": "www.aliexpress.com", "upgrade-insecure-requests": "1",}\n\n  def get(self, url, textNot="ø"*3, urlNot="ø"*3, status_codeNotNot=200, use_proxy=False, cookies={}):\n    [self.s.cookies.set(k,v) for k,v in cookies.items()]\n\n    r  = None\n    if use_proxy == False:\n      r = self.s.get(url, timeout=4)\n      redprint("\nProxy:%s\nUrl:%s\nr.text.find(\'%s\'):%s\nr.url.find(\'%s\'):%s\nstatus_code:%s\nstatus_codeNotNot:%s" % (self.proxy_list[0],url,textNot,r.text.find(textNot),urlNot,r.url.find(urlNot),r.status_code,status_codeNotNot ))\n    else:\n      r = self.s.get(url, proxies={"https":self.proxy_list[0]}, timeout=4)\n      redprint("\nProxy:%s\nUrl:%s\nr.text.find(\'%s\'):%s\nr.url.find(\'%s\'):%s\nstatus_code:%s\nstatus_codeNotNot:%s" % (self.proxy_list[0],url,textNot,r.text.find(textNot),urlNot,r.url.find(urlNot),r.status_code,status_codeNotNot ))\n\n    #redprint("textNot in r.text:%s\n"%(textNot in r.text), "urlNot in r.url:%s\n"% (urlNot in r.url), "status_codeNotNot != r.status_code:%s"%(status_codeNotNot != r.status_code))\n    is_good = True\n    if textNot in r.text:\n      is_good = False\n    if urlNot in r.url:\n      is_good = False\n    if status_codeNotNot != r.status_code:\n      is_good = False\n\n    if is_good == True:\n      redprint("success:True")\n\n      return r\n    else:\n      self.proxy_list.append(self.proxy_list.__getitem__(0 ))\n      self.proxy_list.__delitem__(0 )\n      return self.get(url,textNot, urlNot, status_codeNotNot=200, use_proxy=True)'
        self.count_current_tries +=1
        return self.get(url,textNot, urlNot, status_codeNotNot=200, use_proxy=True)
        ######

    else:
      try:
        r = self.s.get(url, proxies={"https":self.proxy_list[0]}, timeout=4)
        redprint("\nProxy:%s\nUrl:%s\nr.text.find('%s'):%s\nr.url.find('%s'):%s\nstatus_code:%s\nstatus_codeNotNot:%s\ncount_current_tries:%s" % (self.proxy_list[0],url,textNot,r.text.find(textNot),urlNot,r.url.find(urlNot),r.status_code,status_codeNotNot,self.count_current_tries ))
      except Exception as e:
        redprint(str(e)[:100])

        ######
        self.proxy_list.append(self.proxy_list.__getitem__(0 ))
        self.proxy_list.__delitem__(0 )
        self.count_current_tries +=1
        return self.get(url,textNot, urlNot, status_codeNotNot=200, use_proxy=True)
        ######


    #redprint("textNot in r.text:%s\n"%(textNot in r.text), "urlNot in r.url:%s\n"% (urlNot in r.url), "status_codeNotNot != r.status_code:%s"%(status_codeNotNot != r.status_code))
    is_good = True
    if textNot in r.text:
      is_good = False
    if urlNot in r.url:
      is_good = False
    if status_codeNotNot != r.status_code:
      #if r.status_code == 404: return SOUP("404")
      if r.status_code == 404:
        is_good = False
        return r

    if is_good == True:
      redprint("success:True")
      self.count_current_tries = 0
      return r
    else:
      self.proxy_list.append(self.proxy_list.__getitem__(0 ))
      self.proxy_list.__delitem__(0 )
      self.count_current_tries +=1
      return self.get(url,textNot, urlNot, status_codeNotNot=200, use_proxy=True)
class SublimeText_Themes(DecisionTree):
  # (cbf52c (24bc44))
  # (9c8996 (ffffff))
  def __init__(self, ):
    self.hexes = []
    print(" a nice app: http://tmtheme-editor.herokuapp.com/#!/editor/theme/Monokai")
    self.functions_sorted = ["normal", "change_colours", "change_comment_colours", "colorama", "change_background_colour"]
    self.discovered_colours = {
                                "teal": "00efaf",
                                "darkteal": "00afaf", }
    self.saved_colour_codes = """
                                  66D9EF
                                  00qfaf
                                  b7e88a # a fun green
                                  3b3d60
                                  c95e46
                                  b6af6c
                                  502846
                                  51c56d
                                  24bc44
                                  a9586a
                                  c1ef4e
                                  c58887
                                  188711
                                  395931 # a nice calm sea green
                                  9d8bcc
                                  83bd5a
                                  e63f57
                                  e343f0
                                  71321a
                                  395931
                                  2a281a
                                  ef6978
                                  02f718 # sharp green
                                  9c8996 # purplish
                                  d4d4ae #
                                  efd2b4 # pinkish
                                  b3e7b2 #
                                  a5ccd7 #
                                  ffffff # white 
                                  db7d5a # sandstone aurauric red
                                  1ebd01 # in the cut green
                                  ff1700 # red
                                  b00e2a # funner red
                                  ebfdb4 # a surreal colour
                                  cbf52c # a stay awake green and yellow
                                  4fe1e5 # mega blue
                                  deeabd # draconian white
                                  c1faea # funny room blue
                                  efc98e # desaddening orange
                                  6f7f84 #                                  
                                  d6ddd5 2bfe16
                                  dbf0f7 3ecefb
                                  96f6ce d97462
                                  f55608 bfaafe
                                  d48ee5 0ecb9f
                                  748054 fe3161
                                  e04023 befbf6
                                  af53f4 6d7d31
                                  f59b00 de1939
                                  78a7b2 400939"""
    list(map(print, self.saved_colour_codes.split("\n")))
    self.theme_path = homepath("~/Library/Application Support/Sublime Text 3/Packages/Color Scheme - Default/Monokai.tmTheme")
    self.blank = '\n          <!-- \x01 Maybe strings should be whitetext \x02 Functions purple? \x03 Variables blue? \x04 Numbers green? \x05 what about a very dark green for functions?-->\n          <?xml version="1.0" encoding="UTF-8"?>\n          <!DOCTYPE plist PUBLIC "-//Apple Computer//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">\n          <plist version="1.0">\n          <dict>\n            <key>name</key>\n            <string>Monokai</string>\n            <key>settings</key>\n            <array>\n              <dict>\n                <key>settings</key>\n                <!--\n                  [[ Original Data ]]\n                <dict>\n                  <key>background</key>\n                  <string>#__blank__</string> \n                  <key>caret</key>\n                  <string>#__blank__</string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                  <key>invisibles</key>\n                  <string>#__blank__</string>\n                  <key>lineHighlight</key>\n                  <string>#__blank__</string>\n                  <key>selection</key>\n                  <string>#__blank__</string>\n                  <key>findHighlight</key>\n                  <string>#__blank__</string>\n                  <key>findHighlightForeground</key>\n                  <string>#__blank__</string>\n                  <key>selectionBorder</key>\n                  <string>#__blank__</string>\n                  <key>activeGuide</key>\n                  <string>#__blank__</string>\n                  <key>misspelling</key>\n                  <string>#__blank__</string>\n                  <key>bracketsForeground</key>\n                  <string>#__blank__</string>\n                  <key>bracketsOptions</key>\n                  <string>underline</string>\n                  <key>bracketContentsForeground</key>\n                  <string>#__blank__</string>\n                  <key>bracketContentsOptions</key>\n                  <string>underline</string>\n                  <key>tagsOptions</key>\n                  <string>stippled_underline</string>\n                </dict>\n                -->\n                <!--\n                https://html-color-codes.info/old/colorpicker.html\n                -->\n                <dict>\n                  <key>background</key>\n                  <string>#000000</string>\n                  <key>caret</key>\n                  <string>#__blank__</string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                  <key>invisibles</key>\n                  <string>#__blank__</string>\n                  <key>lineHighlight</key>\n                  <string>#__blank__</string>\n                  <key>selection</key>\n                  <string>#000000</string>\n                  <key>findHighlight</key>\n                  <string>#__blank__</string>\n                  <key>findHighlightForeground</key>\n                  <string>#__blank__</string>\n                  <key>selectionBorder</key>\n                  <string>#__blank__</string>\n                  <key>activeGuide</key>\n                  <string>#__blank__</string>\n                  <key>misspelling</key>\n                  <string>#__blank__</string>\n                  <key>bracketsForeground</key>\n                  <string>#__blank__</string>\n                  <key>bracketsOptions</key>\n                  <string>underline</string>\n                  <key>bracketContentsForeground</key>\n                  <string>#__blank__</string>\n                  <key>bracketContentsOptions</key>\n                  <string>underline</string>\n                  <key>tagsOptions</key>\n                  <string>stippled_underline</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Comment</string>\n                <key>scope</key>\n                <string>comment</string>\n                <key>settings</key>\n                <!--\n                [[ Original Data ]]\n                <dict>\n                  <key>foreground</key>\n                  <string>#{__blank__}</string>\n                </dict>\n                -->\n                <dict>\n                  <key>foreground</key>\n                  <string>#FF1700</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>String</string>\n                <key>scope</key>\n                <string>string</string>\n                <key>settings</key>\n                <!--\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n                -->\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string> <!--"string here" # __blank__ string-->\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Number</string>\n                <key>scope</key>\n                <string>constant.numeric</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n\n              <dict>\n                <key>name</key>\n                <string>Built-in constant</string>\n                <key>scope</key>\n                <string>constant.language</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string> <!-- while (True)-->\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>User-defined constant</string>\n                <key>scope</key>\n                <string>constant.character, constant.other</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string> <!-- %s -->\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Variable</string>\n                <key>scope</key>\n                <string>variable</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string></string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Keyword</string>\n                <key>scope</key>\n                <string>keyword - (source.c keyword.operator | source.c++ keyword.operator | source.objc keyword.operator | source.objc++ keyword.operator), keyword.operator.word</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string> <!-- default #__blank__ import/while/for/try/except/as -->\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Annotation Punctuation</string>\n                <key>scope</key>\n                <string>punctuation.definition.annotation</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>JavaScript Dollar</string>\n                <key>scope</key>\n                <string>variable.other.dollar.only.js</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Storage</string>\n                <key>scope</key>\n                <string>storage</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string></string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Storage type</string>\n                <key>scope</key>\n                <string>storage.type</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string>italic</string>\n                  <key>foreground</key>\n                  <string>#__blank__</string> <!-- default: __blank__ (class/def) -->\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Entity name</string>\n                <key>scope</key>\n                <string>entity.name - (entity.name.filename | entity.name.section | entity.name.tag | entity.name.label)</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string></string>\n                  <key>foreground</key>\n                  <string>#__blank__</string> <!-- default: A6E22E class/def (function)-->\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Inherited class</string>\n                <key>scope</key>\n                <string>entity.other.inherited-class</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string>italic underline</string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Function argument</string>\n                <key>scope</key>\n                <string>variable.parameter - (source.c | source.c++ | source.objc | source.objc++)</string>\n                <key>settings</key>\n                <!--\n                <dict>\n                  <key>fontStyle</key>\n                  <string>italic</string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n                -->\n                <dict>\n                  <key>fontStyle</key>\n                  <string>italic</string>\n                  <key>foreground</key>\n                  <string>#__blank__</string> <!-- def hi( (kw)= ) -->\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Language variable</string>\n                <key>scope</key>\n                <string>variable.language</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string>italic</string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Tag name</string>\n                <key>scope</key>\n                <string>entity.name.tag</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string></string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Tag attribute</string>\n                <key>scope</key>\n                <string>entity.other.attribute-name</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string></string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Function call</string>\n                <key>scope</key>\n                <string>variable.function, variable.annotation</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string></string>\n                  <key>foreground</key>\n                  <string>#__blank__</string> <!--x.stdout.readline()) (readline()) -->\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Library function</string> <!--input("Product_url?: ") #__blank__-->\n                <key>scope</key>\n                <string>support.function, support.macro</string>\n                <key>settings</key>\n                <!--\n                <dict>\n                  <key>fontStyle</key>\n                  <string></string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n                -->\n                <dict>\n                  <key>fontStyle</key>\n                  <string></string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Library constant</string>\n                <key>scope</key>\n                <string>support.constant</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string></string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Library class/type</string>\n                <key>scope</key>\n                <string>support.type, support.class</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string>italic</string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Library variable</string>\n                <key>scope</key>\n                <string>support.other.variable</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string></string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Invalid</string>\n                <key>scope</key>\n                <string>invalid</string>\n                <key>settings</key>\n                <dict>\n                  <key>background</key>\n                  <string>#000000</string>\n                  <key>fontStyle</key>\n                  <string></string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>Invalid deprecated</string>\n                <key>scope</key>\n                <string>invalid.deprecated</string>\n                <key>settings</key>\n                <dict>\n                  <key>background</key>\n                  <string>#__blank__</string>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>JSON String</string>\n                <key>scope</key>\n                <string>meta.structure.dictionary.json string.quoted.double.json</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>YAML String</string>\n                <key>scope</key>\n                <string>string.unquoted.yaml</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n\n              <dict>\n                <key>name</key>\n                <string>diff.header</string>\n                <key>scope</key>\n                <string>meta.diff, meta.diff.header</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup headings</string>\n                <key>scope</key>\n                <string>markup.heading</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string>bold</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup headings</string>\n                <key>scope</key>\n                <string>markup.heading punctuation.definition.heading</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup h1</string>\n                <key>scope</key>\n                <string>markup.heading.1 punctuation.definition.heading</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup links</string>\n                <key>scope</key>\n                <string>markup.underline.link</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup bold</string>\n                <key>scope</key>\n                <string>markup.bold</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string>bold</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup italic</string>\n                <key>scope</key>\n                <string>markup.italic</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string>italic</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup bold/italic</string>\n                <key>scope</key>\n                <string>markup.italic markup.bold | markup.bold markup.italic</string>\n                <key>settings</key>\n                <dict>\n                  <key>fontStyle</key>\n                  <string>bold italic</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup hr</string>\n                <key>scope</key>\n                <string>punctuation.definition.thematic-break</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup blockquote</string>\n                <key>scope</key>\n                <string>markup.quote punctuation.definition.blockquote</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup bullets</string>\n                <key>scope</key>\n                <string>markup.list.numbered.bullet</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup bullets</string>\n                <key>scope</key>\n                <string>markup.list.unnumbered.bullet | (markup.list.numbered punctuation.definition)</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup code</string>\n                <key>scope</key>\n                <string>markup.raw</string>\n                <key>settings</key>\n                <dict>\n                  <key>background</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup punctuation</string>\n                <key>scope</key>\n                <string>markup.raw punctuation.definition.raw</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>markup punctuation</string>\n                <key>scope</key>\n                <string>text &amp; (punctuation.definition.italic | punctuation.definition.bold | punctuation.definition.raw | punctuation.definition.link | punctuation.definition.metadata | punctuation.definition.image | punctuation.separator.table-cell | punctuation.section.table-header | punctuation.definition.constant)</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>diff.deleted</string>\n                <key>scope</key>\n                <string>markup.deleted</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>diff.inserted</string>\n                <key>scope</key>\n                <string>markup.inserted</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>name</key>\n                <string>diff.changed</string>\n                <key>scope</key>\n                <string>markup.changed</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>scope</key>\n                <string>constant.numeric.line-number.find-in-files - match</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n              <dict>\n                <key>scope</key>\n                <string>entity.name.filename</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n\n              <dict>\n                <key>scope</key>\n                <string>message.error</string>\n                <key>settings</key>\n                <dict>\n                  <key>foreground</key>\n                  <string>#__blank__</string>\n                </dict>\n              </dict>\n            </array>\n          </dict>\n          </plist>'
    self.Monokai_color_scheme = '{\n    "name": "Monokai",\n    "author": "Sublime HQ Pty Ltd, Wimer Hazenberg",\n    "variables":\n    {\n        "text": "#ffffff",\n        "background": "#000000",\n        "comment": "#ff1700",\n    },\n    "globals":\n    {\n        "foreground": "var(text)",\n        "background": "var(background)",\n        "caret": "var(text)",\n        "invisibles": "var(background)",\n        "line_highlight": "var(background)",\n        "selection": "var(background)",\n        "selection_border": "var(text)",\n        "misspelling": "var(background)",\n        "active_guide": "var(text)",\n        "find_highlight_foreground": "var(text)",\n        "find_highlight": "var(text)",\n        "brackets_options": "underline",\n        "brackets_foreground": "var(text)",\n        "bracket_contents_options": "underline",\n        "bracket_contents_foreground": "var(text)",\n        "tags_options": "stippled_underline"\n    },    "rules":\n    [\n        {\n            "name": "Comment",\n            "scope": "comment",\n            "foreground": "var(comment)"\n        },\n        {\n            "name": "String",\n            "scope": "string",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Number",\n            "scope": "constant.numeric",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Built-in constant",\n            "scope": "constant.language",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "User-defined constant",\n            "scope": "constant.character, constant.other",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Variable",\n            "scope": "variable"\n        },\n        {\n            "name": "Keyword",\n            "scope": "keyword - (source.c keyword.operator | source.c++ keyword.operator | source.objc keyword.operator | source.objc++ keyword.operator), keyword.operator.word",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Annotation Punctuation",\n            "scope": "punctuation.definition.annotation",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "JavaScript Dollar",\n            "scope": "variable.other.dollar.only.js",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Storage",\n            "scope": "storage",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Storage type",\n            "scope": "storage.type",\n            "foreground": "var(text)",\n            "font_style": "italic"\n        },\n        {\n            "name": "Entity name",\n            "scope": "entity.name - (entity.name.filename | entity.name.section | entity.name.tag | entity.name.label)",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Inherited class",\n            "scope": "entity.other.inherited-class",\n            "foreground": "var(text)",\n            "font_style": "italic underline"\n        },\n        {\n            "name": "Function argument",\n            "scope": "variable.parameter - (source.c | source.c++ | source.objc | source.objc++)",\n            "foreground": "var(text)",\n            "font_style": "italic"\n        },\n        {\n            "name": "Language variable",\n            "scope": "variable.language",\n            "foreground": "var(text)",\n            "font_style": "italic"\n        },\n        {\n            "name": "Tag name",\n            "scope": "entity.name.tag",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Tag attribute",\n            "scope": "entity.other.attribute-name",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Function call",\n            "scope": "variable.function, variable.annotation",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Library function",\n            "scope": "support.function, support.macro",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Library constant",\n            "scope": "support.constant",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "Library class/type",\n            "scope": "support.type, support.class",\n            "foreground": "var(text)",\n            "font_style": "italic"\n        },\n        {\n            "name": "Library variable",\n            "scope": "support.other.variable"\n        },\n        {\n            "name": "Invalid",\n            "scope": "invalid",\n            "foreground": "var(text)",\n            "background": "var(background)"\n        },\n        {\n            "name": "Invalid deprecated",\n            "scope": "invalid.deprecated",\n            "foreground": "var(text)",\n            "background": "var(background)"\n        },\n        {\n            "name": "JSON String",\n            "scope": "meta.structure.dictionary.json string.quoted.double.json",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "YAML String",\n            "scope": "string.unquoted.yaml",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "diff.header",\n            "scope": "meta.diff, meta.diff.header",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "markup headings",\n            "scope": "markup.heading",\n            "font_style": "bold"\n        },\n        {\n            "name": "markup headings",\n            "scope": "markup.heading punctuation.definition.heading",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "markup h1",\n            "scope": "markup.heading.1 punctuation.definition.heading",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "markup links",\n            "scope": "markup.underline.link",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "markup bold",\n            "scope": "markup.bold",\n            "font_style": "bold"\n        },\n        {\n            "name": "markup italic",\n            "scope": "markup.italic",\n            "font_style": "italic"\n        },\n        {\n            "name": "markup bold/italic",\n            "scope": "markup.italic markup.bold | markup.bold markup.italic",\n            "font_style": "bold italic"\n        },\n        {\n            "name": "markup hr",\n            "scope": "punctuation.definition.thematic-break",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "markup blockquote",\n            "scope": "markup.quote punctuation.definition.blockquote",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "markup bullets",\n            "scope": "markup.list.numbered.bullet",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "markup bullets",\n            "scope": "markup.list.unnumbered.bullet | (markup.list.numbered punctuation.definition)",\n            "foreground": "color(var(text)"\n        },\n        {\n            "name": "markup code",\n            "scope": "markup.raw",\n            "background": "color(var(text)"\n        },\n        {\n            "name": "markup punctuation",\n            "scope": "markup.raw punctuation.definition.raw",\n            "foreground": "color(var(text)"\n        },\n        {\n            "name": "markup punctuation",\n            "scope": "text & (punctuation.definition.italic | punctuation.definition.bold | punctuation.definition.raw | punctuation.definition.link | punctuation.definition.metadata | punctuation.definition.image | punctuation.separator.table-cell | punctuation.section.table-header | punctuation.definition.constant)",\n            "foreground": "color(var(text)"\n        },\n        {\n            "name": "diff.deleted",\n            "scope": "markup.deleted",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "diff.inserted",\n            "scope": "markup.inserted",\n            "foreground": "var(text)"\n        },\n        {\n            "name": "diff.changed",\n            "scope": "markup.changed",\n            "foreground": "var(text)"\n        },\n        {\n            "scope": "constant.numeric.line-number.find-in-files - match",\n            "foreground": "color(var(text)"\n        },\n        {\n            "scope": "entity.name.filename",\n            "foreground": "var(text)"\n        },\n        {\n            "scope": "message.error",\n            "foreground": "var(text)"\n        }\n    ]\n}'
  def get_random_color_code(self):
    x = [0,1,2,3,4,5,6,7,8,9,"a","b","c","d","e","f"]
    import random
    y = ""
    for i in range(6):
      y += str(random.sample(x, 1)[0])
    print(y)
    return y
  def colorama(self, specific_colour_code = None, sleeptime=2):
    try:specific_colour_code = eval(specific_colour_code)
    except:pass
    if specific_colour_code == "on_clipboard":
      for idx, i in enumerate(pyperclip.paste().split("\n")):
        with open(self.theme_path, "w") as f:
          f.write(self.blank.replace("__blank__", i))
          os.system("say '%s'"%idx)
        time.sleep(int(sleeptime))
      return
    while True:
      with open(self.theme_path, "w") as f:
        if specific_colour_code == None:
          f.write(self.blank.replace("__blank__", self.get_random_color_code()))
        else:
          f.write(self.blank.replace("__blank__", specific_colour_code))
          return
      time.sleep(int(sleeptime))
  def change_colours(self, color_code = None):
    print(json.dumps(self.discovered_colours, indent=4))
    with open(self.theme_path, "w") as f:
      f.write(self.blank.replace("__blank__", color_code))
  def change_comment_colours(self, color_code = None):
    with open(self.theme_path, "r") as f:
      x = f.read()
    with open(self.theme_path, "w") as f:
      f.write(x.replace("FF1700", color_code))
  def change_background_colour(self, color_code = None):
    with open(self.theme_path, "r") as f:
      x = f.read()
    with open(self.theme_path, "w") as f:
      f.write(x.replace("000000", color_code))
  def normal(self):
    SublimeText_Normal_text = ExecutableText().export("SublimeText_Normal_text")
    with open(self.theme_path, "w") as f:
      f.write(SublimeText_Normal_text)
  def argh_text(self, hex="ffffff"):
    hex=(self.get_random_color_code())if(None==hex)else(hex)
    self.hexes[-1].argh_text = hex
    R = homepath("~/Library/Application Support/Sublime Text 3/Packages/Color Scheme - Default/Monokai.sublime-color-scheme")
    F = re.sub(r'"text": "#.*', '"text": "#%s",' % (hex), open(R,"r").read())
    open(R, "w").write(F)
  def argh2_comments(self, hex="ffffff"):
    hex=(self.get_random_color_code())if(None==hex)else(hex)
    self.hexes[-1].argh2_comments = hex
    R = homepath("~/Library/Application Support/Sublime Text 3/Packages/Color Scheme - Default/Monokai.sublime-color-scheme")
    F = re.sub(r'"comment": "#.*', '"comment": "#%s",' % (hex), open(R,"r").read())
    open(R, "w").write(F)
  def argh_background(self, hex="000000"):
    hex=(self.get_random_color_code())if(None==hex)else(hex)
    self.hexes[-1].argh_background = hex
    R = homepath("~/Library/Application Support/Sublime Text 3/Packages/Color Scheme - Default/Monokai.sublime-color-scheme")
    F = re.sub(r'"background": "#.*', '"background": "#%s",' % (hex), open(R,"r").read())
    open(R, "w").write(F)
  def argh_colorama(self, text = True, comments = True, background = False, direction = None):
    if direction is not None:
      if direction == "left":
        self.current_idx = self.current_idx - 1 if (self.current_idx - 1) >= 0 else self.current_idx
        if text: self.argh_text(self.hexes[self.current_idx].argh_text)
        if comments: self.argh2_comments(self.hexes[self.current_idx].argh2_comments)
        if background: self.argh_background(self.hexes[self.current_idx].argh_background)
      elif direction == "right":
        self.current_idx = self.current_idx + 1 if (self.current_idx + 1) < len(self.hexes) else self.current_idx
        if text: self.argh_text(self.hexes[self.current_idx].argh_text)
        if comments: self.argh2_comments(self.hexes[self.current_idx].argh2_comments)
        if background: self.argh_background(self.hexes[self.current_idx].argh_background)
      return
    self.hexes.append(AttrDict())
    self.current_idx = len(self.hexes) - 1
    if text == True:
      self.argh_text(hex = None)
    elif text != False:
      self.argh_text(hex = text)

    if comments == True:
      self.argh2_comments(hex = None)
    elif comments != False:
      self.argh2_comments(hex = comments)

    if background == True:
      self.argh_background(hex = None)
    elif background != False:
      self.argh_background(hex = background)
      
  def argh_norm(self):
    R = homepath("~/Library/Application Support/Sublime Text 3/Packages/Color Scheme - Default/Monokai.sublime-color-scheme")
    open(R, "w").write(self.Monokai_color_scheme)
class Tesseract:
  def __init__(self):
    import pytesseract
    import textract
    import pyocr
    from PIL import Image
    globals().update({k:v for k,v in locals().items() if "self" != k})
  def pytesseract(self, x):
    x = Images().download(x) if not os.path.exists(x) else x
    if(None==x):return(None)#@Added Because It Could Be Images.Download Hits 404 Returns None,
    [setitem(globals(), "img", Image.open(x)), setitem(globals(), "img", globals()["img"].convert("L")), globals()["img"].save(x)]
    x = pytesseract.image_to_string(Image.open(x)).strip()
    redprint("[result\n][%s]"%x)
    return x
  def textract(self, x):
    x = Images().download(x) if not os.path.exists(x) else x
    if(None==x):return(None)#@Added Because It Could Be Images.Download Hits 404 Returns None,
    [setitem(globals(), "img", Image.open(x)), setitem(globals(), "img", globals()["img"].convert("L")), globals()["img"].save(x)]
    x = textract.process(x, encoding='ascii', method='tesseract').decode().strip()
    redprint("[result\n][%s]"%x)
    return x
  def pyocr(self, x):
    x = Images().download(x) if not os.path.exists(x) else x
    if(None==x):return(None)#@Added Because It Could Be Images.Download Hits 404 Returns None,
    [setitem(globals(), "img", Image.open(x)), setitem(globals(), "img", globals()["img"].convert("L")), globals()["img"].save(x)]
    x = pyocr.get_available_tools()[0].image_to_string(Image.open(x), builder=pyocr.builders.TextBuilder()).strip()
    redprint("[result\n][%s]"%x)
    return x
class TestClass(int):
  def __new__(cls, *args, **kwargs):
    return super(TestClass, cls).__new__(cls, 5)
    """
    print(TestClass())
    """
class Time(object):
  def __init__(self, _str=None):
    if or_list(_str,[],None) == None: _str = datetime.now()
    self.timestr = (self.parse_date(_str).strftime("%Y-%m-%d %H:%M:%S"))if(type(_str)==str)else(_str.strftime("%Y-%m-%d %H:%M:%S"))
    self.timeobj = (self.parse_date(_str))if(type(_str)==str)else(_str)
  def parse_date(self,w,remove_tzinfo=True,localize_timezone=False):
    import dateutil.parser
    x = dateutil.parser.parse(w)
    y = x.astimezone()if(localize_timezone==True)else(x)
    z = y.replace(tzinfo=None)if(remove_tzinfo==True)else(y)
  def strftime(self, srftime_string):
    return self.timeobj.strftime(srftime_string)
  def __repr__(self):
    return self.timestr
  def __sub__(self, _str):
    if type(_str) == int:
      return Time(self.timeobj - timedelta(_str))
    else:
      x = (self.timeobj - _str.timeobj)
      class Timedelta(object):
        def __init__(self, x):
          self.timedelta = x
          self.days = self.timedelta.days#
          self.microseconds = self.timedelta.microseconds#
          self.seconds = self.timedelta.seconds#
        def hours(self):#
          return int(self.total_seconds()  /  3600)
        def minutes(self):#
          return int(self.total_seconds()  /  60)
        def total_seconds(self):#
          return self.timedelta.total_seconds()
        def total_minutes(self):
          return int(self.total_seconds()  /  60) + (round( ((self.total_seconds() % 60)/60),2))
      return Timedelta(x)
  def __add__(self, _str):
    if type(_str) == int:
      return Time(self.timeobj + timedelta(_str))
  def __lt__(self, _str):
    return self.timeobj < _str.timeobj
  def __gt__(self, _str):
    return self.timeobj > _str.timeobj
  def __eq__(self, _str):
    return self.timeobj == _str.timeobj
  def __call__(self):
    return self.timeobj
  def date(self):
    return self.timeobj
  def str(self):
    return self.timestr
class TrueFalseStatements:
  def __init__(self):
    pyperclip.copy(

    """
    In [292]: '''1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1'''
    Out[292]: '1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1'

    In [293]: def true():return [print('true'),1][1]

    In [294]: def false():return [print('false'),0][1]

    In [295]: def truth():return [print('true'),1][1]

    In [296]: [print('t'),1][1] and ([print('f'),0][1] or [print('t'),1][1])
    t
    f
    t
    Out[296]: 1

    In [297]: true() and (false() or false() or false() or true()) and (false() or true()) and true() and true() and true() and true() and true() and (false(
         ...: ) or true()) and (false() or false() or true())
    true
    false
    false
    false
    true
    false
    true
    true
    true
    true
    true
    true
    false
    true
    false
    false
    true
    Out[297]: 1

    In [298]: '1 and (false or false or false or truth) and (false or truth) and tru and tru and tru and tru and tru and (fls or tru) and (f f t)'
    Out[298]: '1 and (false or false or false or truth) and (false or truth) and tru and tru and tru and tru and tru and (fls or tru) and (f f t)'

    """  .  replace('\n      ',''))



""" Internet-Utils """
def BeautifulSoup(x, y="lxml"):
  from bs4 import BeautifulSoup as BeautifulSoup
  return BeautifulSoup(x, "lxml")
def SOUP(x, y="lxml"):
  from bs4 import BeautifulSoup as SOUP
  return SOUP(x, "lxml")
def SOUPY(soup,x=None,y=None,z=None):
  import bs4
  if type(soup) != bs4.BeautifulSoup: soup = BeautifulSoup(str(soup))
  if x==None: return soup
  return(soup.findAll(x)if(None==y==z)else(soup.findAll(x,attrs={y:z})))
def addressurl(url, part = 0):
  return ("%s%s.png" % (Replacements(address_normalize(url), "/", " "), (":%s:"%(part))if(part!=0)else("") ))
  """
  ss = Browser()("sele")
  ss.get("google.com")
  assert addressurl(ss.current_url, part = 0) == "https:  www.google.com.png"
  assert addressurl(ss.current_url, part = 1) == "https:  www.google.com:1:.png"
  """
def bitly_url(url):
  return json.loads(requests.get("https://api-ssl.bitly.com/v3/shorten?access_token={}&longUrl={}".format(Muta()().bitly_access_token, url)).text)["data"]["url"]
  """
  bitly_url("https://google.com")
  """
def blocktext_to_session_headers(x):
  x=x.replace("\r","").strip().split("\n")
  x=lmap(lambda i:i.strip(),x)
  x={i.split(": ",1)[0] if not i.split(": ",1)[0].startswith(":") else(i.split(": ",1)[0][1:]):i.split(": ")[1] for i in x }
  return x
def check_gmail_account_exists(x):
  ss = Browser()("ph")
  ss.get("https://accounts.google.com/signin/v2/identifier")
  blueprint("got page")
  ss.ffs("input","type","email").send_keys(x).sp(2)
  blueprint("entered in email")

  ss.jtns("span","click",{"text":"Next"}).sp(5)
  blueprint("clicked next button")
  exists = None
  if "/pwd" in ss.current_url:
    blueprint(ss.current_url)
    exists = True # exists
  else:
    exists = False
  ss.quit()
  return exists
  """
  blueprint(check_gmail_account_exists("test"))
  blueprint(check_gmail_account_exists("asjdgasjgepawokgepak"))
  """
def cookies_to_database(username,website_name,cookies=None,reverse=True):
  # return Binarydata().update_or_create([pickle.dump(cookies,open("%s|%s|Cookies.ini"%(username,website_name),"wb")),"%s|%s|Cookies.ini"%(username,website_name)][1])if(reverse==False)else([Binarydata().export("%s|%s|Cookies.ini"%(username,website_name)),pickle.load(open("%s|%s|Cookies.ini"%(username,website_name),"rb")),rm("%s|%s|Cookies.ini"%(username,website_name)) ][1])
  return Binarydata().update_or_create([pickle.dump(cookies,open("%s|%s|Cookies.ini"%(username,website_name),"wb")),"%s|%s|Cookies.ini"%(username,website_name)][1])if(reverse==False)else([Binarydata().export("%s|%s|Cookies.ini"%(username,website_name)),pickle.load(open("%s|%s|Cookies.ini"%(username,website_name),"rb")), ][1])
def cookies_to_session(cookies, session):
  for cookie in cookies:
    session.cookies.set(cookie['name'], cookie['value'])
  return session
def firefox65_do(executable_string):
  os.system("pip install selenium==3.14.1 && sleep 2 && cd /Users/$USER/tavern/tavern && /Users/$USER/tavern/bin/python3.5 -c 'from soda.can import *; %s' ; sleep 10 && pip install selenium==2.53.1 && killall python3.5 ; killall python ; echo complete ; sleep 10" % (executable_string))
def get_ali_url(x):
  return Get(Product,shop=Muta()().store_abbre,handle=x).ali_url
def get_all_chrome_urls():
  return subprocess.getoutput("""osascript -e'set text item delimiters to linefeed' -e'tell app "Google Chrome 70" to url of tabs of window 1 as text'""").split("\n")
def get_one(_, *args, **kwargs):
  __ = _

  _ = _.objects.filter(**{a:v for a,v in kwargs.items() if "__range" not in a and not [i for i in __._meta.fields if i.name == a.split("__")[0] and type(i) == JSONField]})
  if {a:v for a,v in kwargs.items() if "__range" not in a and [i for i in __._meta.fields if i.name == a.split("__")[0] and type(i) == JSONField]}:
    _ = filter(_,**{a:v for a,v in kwargs.items() if "__range" not in a and [i for i in __._meta.fields if i.name == a.split("__")[0] and type(i) == JSONField]})
  if args and not [i[0] for i in sum(key("children",args),[]) if [j for j in __._meta.fields if j.name == i[0] and type(j) == JSONField]]:
    _ = _.filter(*args)
  if args and [i[0] for i in sum(key("children",args),[]) if [j for j in __._meta.fields if j.name == i[0] and type(j) == JSONField]]:
    _ = filter(_,*args)
  for a,v in kwargs.items():
    if "__range" in a:
      field = a.split("__",1)[0]
      for i in _:
        setattr(i, field, Date(getattr(i, field)).dateobj  )

      class myList(list):
        1
      _ = myList([i for i in _ if   Date(v[0]).dateobj<= getattr(i,field)  <= Date(v[1]).dateobj ])

  if type(_) == list:
    class myList(list):
      1
    _ = myList(_)

  n = lambda self, x: list(self)[x]
  ( bind3(_,len), bind3(_,n) )

  _ = _[0]
  return _
def get_us_ip_list():
  try:
    soup = BeautifulSoup(requests.get("https://free-proxy-list.net/").text)
    soup.findAll("td")
    x = key("text", soup.findAll("td"))
    y = [i for i in x if i.count(".") == 3 or tryprocess(int, i) == 1]
    proxy_list = ["%s:%s"%(i,j) for i,j in zip(y[0::2], y[1::2])]
    if len(proxy_list) == 0:
      q = redinput("redo/Error in My_Requests().set_proxies() | proxy_list == []   | check requests.get('http://www.free-proxy-list.net')    ")
      if q == "redo": return get_us_ip_list()
    if random.randrange(1,3) == 1:  proxy_list = list(tcer(proxy_list))
    else:                           random.shuffle(proxy_list)
    return proxy_list
  except :
    soup = BeautifulSoup(requests.get("http://www.idcloak.com/proxylist/free-us-proxy-list.html").text)
    x = key("text", soup.findAll("td"))
    y = []
    for i in x:
      try:
        if i.count(".") == 3:
          int(i.replace(".",""))
          y.append(i)
        else:
          int(i)
          y.append(i)
      except:
        pass
    y = list(tcer(y))
    proxy_list = []
    for i,j in zip(y[0::2], y[1::2]):
      proxy_list.append("%s:%s"%(i,j))
    proxy_list = proxy_list
    if random.randrange(1,3) == 1:
      proxy_list = list(tcer(proxy_list))
    else:
      random.shuffle(proxy_list)
    if len(proxy_list) == 0:
      return get_us_ip_list()
    return proxy_list
def killall_phantomjs():
  os.system("killall .phantomjs phantomjs &>/dev/null")
def login_gmail(ss, username, password):
  logout_gmail(ss)
  ss.get("https://accounts.google.com/ServiceLogin/identifier?service=mail&passive=true&rm=false&continue=https%3A%2F%2Fmail.google.com%2Fmail%2F&ss=1&scc=1&ltmpl=default&ltmplcache=2&emr=1&osid=1&flowName=GlifWebSignIn&flowEntry=AddSession")
  flexed = False
  quas = ss.ffss("div", "aria-label", "Switch account")
  if([] != quas):
    flexed = True
  if flexed == True:
    trykeycall("click", quas); sp(10)
    trykeycall("click", ss.ffsts("div", "Use another account")); sp(7)
  1
  trykeycall("send_keys", ss.fns("identifier"), username); sp(7)
  trykeycall("click", ss.ffsts("span", "Next")); sp(4)
  while("/pwd" not in ss.current_url):
    time.sleep(1)
  trykeycall("send_keys", ss.fns("password"), password); sp(7)
  current_url = ss.current_url
  trykeycall("click", ss.ffsts("span", "Next")); sp(7)
  while(current_url == (lambda: ss.current_url)()):
    time.sleep(1)
  time.sleep(10)
  if("/challenge" in ss.current_url):
    OSA.display_dialog("Please fill in the six digit verification code. Then click OK in this prompt.", text_prompt = False)
  trykeycall("click", ss.ffsts("span", "Next")); sp(6)
def logout_gmail(ss):
  ss.get("https://accounts.google.com/Logout")
def query_google(q, pages):
  urls = ["https://www.google.com/search?q={}&oq={}&start={}".format(q,q, i*10) for i in range(pages)]
  print(urls)
  x=[]
  for idx, url in enumerate(urls):
    print("getting page %s.." % idx)
    try:soup = BeautifulSoup(requests.get(url).text)
    except Exception as e: redprint("[query_google][%s]"%e); continue
    results = re.findall(r'<a href="/url\?q=(.*?)"', str(soup))
    for i in results:
      if i not in x:
        x.append(i)
    time.sleep(2)
    print("%s results so far" % len(x))
  x1 = []
  for url in x:
    x1.append(url.split("&amp")[0])
  return x1
def query_google_images(searches="", limit=20):
  for i in searches.split(","):
    rm(homepath("~/Documents/downloads"))
    rm(homepath("~/Documents/photos/%s"%(i)))
    os.chdir(homepath("~/Documents"))
    os.system('googleimagesdownload --chromedriver ~/tavern/tavern/soda/.chromedriver -k """%s""" -l %s'%(i.strip(), limit))
    os.system("mkdir ~/Documents/photos &>/dev/null")
    os.system("""mv ./downloads/* /Users/$USER/Documents/photos/ && mv ./downloads/*/* "/Users/$USER/Documents/photos/%s/" """%(i))
    os.system("echo 'printing image folders in ~/Documents/photos..'")
    os.system("ls -l ~/Documents/photos | grep -v 'jpg\|png\|jpeg\|psd'")
    rm("./downloads")
  return flatten([lmap(lambda x: homepath("~/Documents/photos/%s/%s"%(i,x)),os.listdir(homepath("~/Documents/photos/%s"%(i)))) for i in searches.split(",")],1)
def r_image_search(io,webbrowser_open=False):
  import webbrowser

  if type(io) != list:
    io = [io]
  def x(address):
    multipart = {"encoded_image": open(address, "rb"), "image_content": ""}
    response = requests.post("http://www.google.com/searchbyimage/upload", files=multipart, allow_redirects=False)
    fetchUrl = response.headers["Location"]
    url = fetchUrl + "&q=site%3Aaliexpress.com"
    return url
  l=pool(x,io,nodes=2).result()

  if webbrowser_open == True:
    if OSA.log("Are you sure you want to open the urls?",tp=False,buttons=["Yes","No"]) == "Yes":
      lmap(webbrowser.open,l)
  return l
def read_html(url, to_dict=True):
  import pandas as pd
  dataframes = pd.read_html(url, header=0)
  dataframes=[dataframe_to_dictlist(dataframe) for dataframe in dataframes]if(1==to_dict)else(dataframes)
  return dataframes
def reverse_image_search(io,search=None):
  try:
    # for segmentation fault
    if not os.path.exists(io):
      io = Images().download(io)
    # filePath = '/mnt/Images/test.png'
    searchUrl = 'http://www.google.com/searchbyimage/upload'
    multipart = {'encoded_image': (io, open(io, 'rb')), 'image_content': ''}
    response = requests.post(searchUrl, files=multipart, allow_redirects=False)
    url = response.headers['Location']
    if search:
      url = url + "&q=%s&oq=%s"%(search,search)
    return url
  except Exception as e:
    OSA.notify("reverse image search error: %s" % str(e))
    return reverse_image_search(io=io,search=search)
def run_pinterest_board_image_getter():
  # 'https://api.pinterest.com/oauth/?scope=read_public,write_public&client_id=5066656475317842279&state=768uyFys&response_type=code&redirect_uri=https://localhost/auth/pinterest/callback\nhttps://localhost/auth/pinterest/callback?state=768uyFys&code=de928c1c929e5c05\n\n\ndata={"grant_type":"authorization_code",\n"client_id":5066656475317842279,\n"client_secret":"84a1b5a0d3c5fc58fdbf7238902330d042ff2dfcf997c3ee2013c0408b03bb8e",\n"code":"d2021af082c74329",}\nx=requests.post("https://api.pinterest.com/v1/oauth/token",data=data)\n#y=\'{"access_token": "An0Xs7HN42Vf6UlX72a-KVcHjQahFdfH1Ef4bCxGUGE4UkCxZwhtQDAAAsw9RlBjTAqAq3MAAAAA", "token_type": "bearer", "scope": ["read_public", "write_public", "read_private", "write_private", "read_write_all"]}\'\ndata = json.loads(x.text)\naccess_token = data["access_token"]\n\nhttps://api.pinterest.com/v1/boards/396035429671343708/pins/?access_token=An8K8wKh3MUU2SX8uNNQh4I42w_1FcKm1yR6NIlGJA_4Q6Ckiwj7gDAAAqv1RiQTFyGAsh0AAAAA&fields=id%2Clink%2Cnote%2Curl%2Cattribution%2Cboard\n\n\n\nparams = {"access_token":access_token,"fields":["image","note"]}\nr = requests.get("https://api.pinterest.com/v1/boards/whitetiger62/steampunk-girl/pins/",params=params)\nall_data = []\ndata = json.loads(r.text)\nall_data.extend(data["data"])\nwhile "next" in data.get("page",{}):\n  r = requests.get(data["page"]["next"])\n  data = json.loads(r.text)\n  all_data.extend(data["data"])\n  print(data)\n  time.sleep(1)\n\n\nrequests.get("https://api.pinterest.com/v1/me/pins/?access_token=%s&fields=id,note&limit=1"%(access_token))\n\nrequests.get("https://api.pinterest.com/v1/boards/anapinskywalker/wanderlust/pins/?access_token=%s&limit=2&fields=id,link,counts,note"%(access_token))\n'
  process(lambda:OSA.log("x=document.getElementsByTagName('img');y=x.length;l=[];for (i=0;i<y;i++) {l=l.concat(x[i].src);};console.log(l.length);copy(l.join());"))
  datas = []
  while True:
    if pyperclip.paste() not in datas:
      datas.append(pyperclip.paste())
    if pyperclip.paste() == "end":
      break
  datas = listminus(datas,None)
  datas = oset(flatten(lmap(lambda i:i.split(","),sudby(lambda i:i.endswith("jpg"),datas)),1))
  datas = datas[1:]
  datas = lmap(lambda i:re.sub("(https://i.pinimg.com/)\d+x(.*)","\\g<1>1200x\\g<2>",i),datas)
  datas = [i for i in datas if re.findall("https://i.pinimg.com/\d+x\d+_RS",i) == []]
  # file_links = pool(lambda i: Images().download(i),datas,nodes=24)

  return datas
def site_speed_test(shop):
  """
  In [4]: @timeit
     ...: def timed():
     ...:     requests.get("https://%s"%Shop()(shop).Domain_Name)
     ...:     
     ...:     

  In [5]: timed()
  timeit: 2.1305429935455322, timed

  In [6]: timed()
  timeit: 0.7816150188446045, timed
  """
  @timeit
  def timed():
    requests.get("https://%s"%Shop()(shop).Domain_Name)
  timed()
  return
def socket_connect_send(host_and_port=("data.pr4e.org", 80),url="http://data.pr4e.org/romeo.txt"):
  import socket
  mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
  mysock.connect(host_and_port)
  cmd = ("GET %s HTTP/1.0\r\n\r\n"%(url)).encode()
  mysock.send(cmd)
  while True:
    data = mysock.recv(512)
    if (len(data) < 1):
      break
    print(data.decode())
  mysock.close()
def urllib_video_download(x):
  import urllib
  y = get_random_address(homepath("~/tavern/tavern/soda/dls")).mp4()
  urllib.request.urlretrieve(x, y)
  return y
def video_download(x):
  print("Downloading Video")
  timer = multiprocessing_process(lambda: [[OSA.notify(str(i)),time.sleep(1)] for i in range(WHILE_TRUE)])
  y = get_random_address(homepath("~/tavern/tavern/soda/dls")).mp4()
  timedretry(lambda: os.system("wget -O '%s' '%s'"%(y,x)),80)
  tryprocess(lambda: timer.terminate())
  return y
def youtube_downloader(y="asdf",z=20):
  os.makedirs(homepath("~/Documents/%s"%(y)),exist_ok=True)
  os.chdir(homepath("~/Documents/%s"%(y)))
  x=getoutput("youtube-dl --get-title --get-url ytsearch%s:%s"%(z,y)).split("\n")
  titles = x[0::3]
  urls = x[2::3]

  titles = lmap(lambda i: i.title(), titles)

  x = []
  for title, url in zip(titles, urls):
    if ner_tagger(title):
      pass
    else:
      cmd = "youtube-dl '%s' --output '%s.mp4' &"%(url,title)
      print(cmd)
      x.append(lambda: os.system("youtube-dl '%s' --output '%s.mp4' &"%(url,title)))
  pool(lambda i: i.__call__(), x, nodes=5).result()
def change_mac_address():
  mac_address = subprocess.getoutput("openssl rand -hex 6 | sed 's/\(..\)/\\1:/g; s/.$//'")
  os.system("sudo ifconfig en0 ether %s"%(mac_address))
class Bowser(object):
  def __call__(self, profile="sele", invis=False, window_index=None):
    distinct_print("initializing profile %s" % profile)
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.firefox.firefox_profile import FirefoxProfile
    from selenium.webdriver.firefox.firefox_binary import FirefoxBinary
    from selenium.webdriver.common.keys import Keys, Keys as SHADOW
    from selenium.webdriver.common.by import By
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver import ActionChains
    from selenium import webdriver
    from pyvirtualdisplay import Display
    from selenium.webdriver.common.alert import Alert
    from sys import platform
    import selenium.webdriver.support.expected_conditions as EC
    globals().update({a:v for a,v in Keys.__dict__.items() if not a.startswith("_")})
    globals().update(locals())

    wd = None
    if invis == True:
      display = Display(visible=0, size=(1024, 768)).start()
    if profile == 'ph':
      #@service_log_path somewhere else [2018.11.23 05:07 PM]
      wd = webdriver.PhantomJS(os.path.expanduser('~/tavern/tavern/soda/.phantomjs'),service_log_path=homepath("~/tavern/tavern/soda/.ghostdriver.log"))
      (wd.set_window_position(*GLOBAL_BROWSER_WINDOW_POSITION), wd.set_window_size(*GLOBAL_BROWSER_WINDOW_SIZE))
      wd.profile = "sele" # false but slips
      wd.driver_type = "phantomjs"
    if 'ch' in profile:
      # os.system("rm -rf '~/Library/Application Support/Google/Chrome/Profile 1000'")
      os.system("killall Google\ Chrome\ 70&>/dev/null&")
      options = webdriver.ChromeOptions()
      options.add_argument("--no-sandbox")
      options.add_argument("--user-data-dir=~/Library/Application Support/Google/Chrome/Profile 1000")
      options.add_argument("disable-infobars")
      options.add_argument('--disable-infobars')
      options.add_argument("--disable-infobars")
      os.system("rm -rf ~/Library/Application\ Support/Google/Chrome/Profile\ 1000/Cookies")
      OSA().notify("initiating webdriver")


      options.binary_location = '/Applications/Google Chrome 70.app/Contents/MacOS/Google Chrome'
      options.add_argument("--disable-dev-shm-usage");

      # killall "Google Chrome 70"

      # options.add_argument('window-size=1200x600')

      chromedriver = os.path.expanduser('~/tavern/tavern/soda/.chromedriver')
      if '+' in profile:
        rm(homepath("~/Library/Application Support/Google/Chrome/Profile 1000"))
        options.add_argument('--headless')
      if '/' in profile:
        rm(homepath("~/Library/Application Support/Google/Chrome/Profile 1000"))
      wd = webdriver.Chrome(executable_path=chromedriver, chrome_options=options)
      (wd.set_window_position(*GLOBAL_BROWSER_WINDOW_POSITION), wd.set_window_size(*GLOBAL_BROWSER_WINDOW_SIZE))
      wd.profile = profile
      wd.driver_type = "chrome"
    elif profile != 'ph':
      try:
        if platform == 'darwin':
          profile_path = os.path.expanduser("~/Library/Application Support/Firefox/Profiles")
        else:
          profile_path = os.path.expanduser('~/.mozilla/firefox')
        
        #options = Options()

        #options.add_argument("--headless")
        #options.set_headless(headless=True)

        # 3.14.1, 65/61, 24
        # 2.53.1, 46, 19? (24*)
        # 46 ruled as screenshot savely and zoomable
        executable_path = os.path.expanduser("~/tavern/tavern/soda/.geckodriver")
        #firefox_profile = FirefoxProfile(os.path.expanduser("~/Library/Application Support/Firefox/Profiles") + "/" + [i for i in os.listdir(os.path.expanduser("~/Library/Application Support/Firefox/Profiles"))][0])
        firefox_profile = FirefoxProfile(homepath("~/Library/Application Support/Firefox/Profiles/%s" % (( [i for i in os.listdir(os.path.expanduser("~/Library/Application Support/Firefox/Profiles")) if profile == "".join(i.split(".")[1:]) ][0] )) ))
        #firefox_profile.set_preference('browser.download.dir', '/tmp')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'text/csv; charset=utf-8')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'text/json; charset=utf-8')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'text/plain; charset=utf-8')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'text/html; charset=utf-8')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'text/csv')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'text/json')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'text/plain')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'text/html')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'attachment/json')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'attachment/json; charset=utf-8')
        firefox_profile.set_preference('browser.helperApps.neverAsk.saveToDisk', 'attachment/json;charset=utf-8')
        firefox_binary = FirefoxBinary("/Applications/Firefox 46.app/Contents/MacOS/firefox-bin") # Make sure selenium is 3.8.0
        # firefox_binary = FirefoxBinary("/Applications/Firefox 46.app/Contents/MacOS/firefox-bin") # Make sure selenium is 2.53.1
        wd = webdriver.Firefox(executable_path=executable_path, firefox_profile=firefox_profile, firefox_binary=firefox_binary)if(invis!=66)else(webdriver.Firefox(executable_path=executable_path,firefox_profile=firefox_profile,firefox_binary=FirefoxBinary("/Applications/Firefox 46.app/Contents/MacOS/firefox-bin".replace("46","66")), log_path="/dev/null"))#,capabilities=capabilities)
        (wd.set_window_position(*GLOBAL_BROWSER_WINDOW_POSITION), wd.set_window_size(*GLOBAL_BROWSER_WINDOW_SIZE))

        wd.driver_type = "firefox"
        # HERE IS THE PAYLOAD
        #if invis: OSA().setforemostwindowarrangement("Firefox",0,0,0,0)


        from selenium.webdriver.common.keys import Keys
        wd.keys = Keys
      except Exception as e:
        print(e)
    o = lambda self: [blueprint("imko_checker on"), setattr(self, "imko_checker", True), self][2]
    k = lambda self: [blueprint("imko_checker off"), setattr(self, "imko_checker", False), self][2]
    
    def imko(self, *args, part = 0):
      return self
      # [ Depreciatied]
      if len(args) > 1: part = args[-1]
      self.zoom_level()
      if part == "on":
        self.imko_checker = True
        return self
      elif part == "off":
        self.imko_checker = False
        return self


      if args: return [[greenprint("Image compare test passed.")]if(True==[self.save_screenshot("%s/%s%s.png"%(homepath("~/tavern/tavern/soda/imqo"),addressurl(args[0],part=part),"_:compare:_")), ImageComp()("%s/%s"%(homepath("~/tavern/tavern/soda/imqo"), addressurl(args[0],part=part)), "%s/%s%s.png"%(homepath("~/tavern/tavern/soda/imqo"),addressurl(args[0],part=part),"_:compare:_"))][1] )else([greenprint("Image compare test failed."), OSA.display_dialog("This page with url:\n%s\n failed the image compare test. It may have been changed.\nThis test was taken with a similarity metric of %s.\n\nContinue? (may result in program crash)"  % (self.current_url, GLOBAL_IMAGE_COMPARISON_TEST_SCORE), text_prompt = False)]), self][1]

      address_current = addressurl(self.current_url, part = part)
      address_imqo = homepath("~/tavern/tavern/soda/imqo")
      destination_locale = "%s/%s" % (address_imqo, address_current)
      assert os.path.exists(destination_locale)
      compare_locale = "%s%s.png" % (destination_locale, "_:compare:_") # gen new
      self.save_screenshot(compare_locale) # save
      image_compare_test_result = ImageComp()(destination_locale, compare_locale)
      os.remove(compare_locale)
      # :image_compare_test:
      if True == image_compare_test_result:
        greenprint("Image compare test passed.")
      else:
        greenprint("Image compare test failed.")
        OSA.display_dialog("This page with url:\n%s\n failed the image compare test. It may have been changed.\nThis test was taken with a similarity metric of %s.\n\nContinue? (may result in program crash)"  % (self.current_url, GLOBAL_IMAGE_COMPARISON_TEST_SCORE), text_prompt = False)
      return self
    def silver_port(self, executable_string):
      os.system("pip install selenium==3.14.1 && cd ~/tavern/tavern && ~/tavern/bin/python3.5 -c 'from soda.can import *; %s' ; pip install selenium==2.53.1" % (executable_string))
      return self
    def set_window(self, x,y,l,w):
      self.set_window_position(y, x)
      self.set_window_size(l, w)
      return self
    def set_window_index(self, row, col, num_rows=4, num_cols=4):
      self.get('http://google.com')
      if self.profile == 'ch':
        self.execute_script("document.body.style.zoom='25%'")
      else:
        self.zoom_out()
      row_size = 4000/num_rows
      col_size = 6400/num_cols
      if self.profile == 'ch':
        row_size = (row_size / 4) *1.2
      if self.profile == 'ch':
        col_size = (col_size / 4) *1.2
      x_position = row_size * row
      y_position = col_size * col
      x_size = row_size
      y_size = col_size
      print(x_position, y_position, x_size, y_size)
      self.set_window(x_position, y_position, y_size, x_size)
      return self
    def click_by_offset(self, element, x, y):
      ActionChains(self).move_to_element_with_offset(element, x, y).click().perform()
      return self
    def cget(self,url):
      self.execute_script("window.open('%s', 'new_window')"%url)
      self.switchlast()
      return self
    def switchlast(self):
      self.switch_to_window(self.window_handles[-1])
      return self
    def closelast(self):
      self.switchlast()
      self.close()
      self.switchlast()
      return self
    def nexturlwait(self):
      self.nexturlwait_current = self.current_url
      return self
    def nexturlwaitjoin(self, _time = GLOBAL_BROWSER_URLWAIT_WAIT_TIME):
      start_time = datetime.now()
      while self.current_url == self.nexturlwait_current:
        if ((datetime.now()-start_time).seconds) > _time: assert(False)
        time.sleep(0.5)
      self.zoom_level(level = self.zoom_level_idx)
      self.sp(GLOBAL_BROWSER_STEP_SLEEPTIME)
      return self
    def urlwait(self, x, _time = GLOBAL_BROWSER_URLWAIT_WAIT_TIME):
      start_time = datetime.now()
      while(x not in self.current_url):
        if ((datetime.now()-start_time).seconds) > _time: assert(False)
        time.sleep(0.5)
      self.zoom_level(level = self.zoom_level_idx)
      self.sp(GLOBAL_BROWSER_STEP_SLEEPTIME)
      return self
    def assert_connection_speed(self, minimum_speed = "25MB"):
      minimum_speed_integer = decimal_re(minimum_speed)
      download_speed_readable = Psutil().SpeedTest(download = True, upload = False, verbose = False)
      download_speed_integer = decimal_re(download_speed_readable)
      while download_speed_integer < minimum_speed_integer:
        download_speed_readable = Psutil().SpeedTest(download = True, upload = False, verbose = False)
        download_speed_integer = decimal_re(download_speed_readable)
        OSA.display_dialog("Browser is not working because download speed is not over the minimum speed which is %s.\nPressing Okay will re-attempt this download speed test." % (minimum_speed))
      greenprint("Download Speed, %s Is Over %s. Connection Speed Is Good" % (download_speed_readable, minimum_speed))
      return True
    if GLOBAL_BROWSER_REQUIRE_SPEEDTEST == True:
      speedtest = pool(type("", (AttrDict,), dict(assert_connection_speed = assert_connection_speed))().assert_connection_speed, minimum_speed = "200MB")
    def iframe_find(self, command, *args, **kwargs):
      iframes = self.ftns("iframe")
      for i in iframes:
        try:
          time.sleep(3)
          self.switch_to_frame(i)
          time.sleep(3)
        except Exception as e:
          redprint("could not switch to a frame, switching to default content and continuing.")
          time.sleep(3)
          self.switch_to_default_content()
          time.sleep(3)
          continue
          pass
        R = tryreturn(command, *args, **kwargs)
        if R == 0:
          print("could not execute the command with the args and kwargs, switching to default content and continuing.")          
          time.sleep(3)
          self.switch_to_default_content()
          time.sleep(3)
          continue
        elif R != 0:
          time.sleep(3)
          self.switch_to_default_content()
          time.sleep(3)
          return j
      time.sleep(3)
      self.switch_to_default_content()
      time.sleep(3)
    def wait_for(self, _type,_name,_time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME):
      try: return WebDriverWait(self,_time).until(EC.presence_of_element_located((getattr(By, _type), _name))); zz(2)
      except: print('[Disregardable] %s Not Found'%_name); return 'fail'
    def wait_fors(self, _type,_name,_time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME):
      try: return WebDriverWait(self,_time).until(EC.presence_of_all_elements_located((getattr(By, _type), _name))); zz(2)
      except: print('[Disregardable] %s Not Found'%_name); return []
    def wait_for_element(self, method, *args):
      while True:
        try:
          x = method(*list(args))
          if x != "fail":
            return x
        except Exception as e:
          print(method, *args, "not found", "sleeping 1")
          time.sleep(1)
      # ie self.ss.fcn, "s-company-title"
    # send_keys/click should be classed to return self
    def bind_more(elem, webdriver = None):
      if type(elem)==str: return "fail"
      elem.find_element_by_class_name1 = elem.find_element_by_class_name
      find_element_by_class_name = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.find_element_by_class_name1(x), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_element_by_css_selector1 = elem.find_element_by_css_selector
      find_element_by_css_selector = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.find_element_by_css_selector1(x), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_element_by_id1 = elem.find_element_by_id
      find_element_by_id = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.find_element_by_id1(x), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_element_by_link_text1 = elem.find_element_by_link_text
      find_element_by_link_text = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.find_element_by_link_text1(x), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_element_by_name1 = elem.find_element_by_name
      find_element_by_name = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.find_element_by_name1(x), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_element_by_partial_link_text1 = elem.find_element_by_partial_link_text
      find_element_by_partial_link_text = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.find_element_by_partial_link_text1(x), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_element_by_tag_name1 = elem.find_element_by_tag_name
      find_element_by_tag_name = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.find_element_by_tag_name1(x), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_element_by_xpath1 = elem.find_element_by_xpath
      find_element_by_xpath = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.find_element_by_xpath1(x), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_elements_by_class_name1 = elem.find_elements_by_class_name
      find_elements_by_class_name = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.find_elements_by_class_name1(x))(webdriver = webdriver)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_elements_by_css_selector1 = elem.find_elements_by_css_selector
      find_elements_by_css_selector = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.find_elements_by_css_selector1(x))(webdriver = webdriver)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_elements_by_id1 = elem.find_elements_by_id
      find_elements_by_id = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.find_elements_by_id1(x))(webdriver = webdriver)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_elements_by_link_text1 = elem.find_elements_by_link_text
      find_elements_by_link_text = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.find_elements_by_link_text1(x))(webdriver = webdriver)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_elements_by_name1 = elem.find_elements_by_name
      find_elements_by_name = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.find_elements_by_name1(x))(webdriver = webdriver)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_elements_by_partial_link_text1 = elem.find_elements_by_partial_link_text
      find_elements_by_partial_link_text = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.find_elements_by_partial_link_text1(x))(webdriver = webdriver)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_elements_by_tag_name1 = elem.find_elements_by_tag_name
      find_elements_by_tag_name = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.find_elements_by_tag_name1(x))(webdriver = webdriver)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.find_elements_by_xpath1 = elem.find_elements_by_xpath
      find_elements_by_xpath = lambda self, x, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.find_elements_by_xpath1(x))(webdriver = webdriver)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
      elem.click1 = elem.click
      click = lambda self, sleeptime = GLOBAL_BROWSER_STEP_SLEEPTIME: [elem.click1(), webdriver.sp(sleeptime), webdriver][2]
      elem.send_keys1 = elem.send_keys
      send_keys = lambda self, keys, sleeptime = GLOBAL_BROWSER_STEP_SLEEPTIME: [tryprocess(elem.clear), webdriver.sp(sleeptime), elem.send_keys1(keys), webdriver.sp(sleeptime), self][4]
      elem.clear1 = elem.clear
      s_keys = lambda self,x,r1=0.2,r2=0.8,sleeptime=GLOBAL_BROWSER_STEP_SLEEPTIME: [[tryprocess(elem.clear), time.sleep(sleeptime), time.sleep(1), [[elem.send_keys1(i), time.sleep(random.uniform(r1,r2))] for i in x]], self.sp(sleeptime), self][2]
      """
      ss = Browser()("sele")
      ss.get("google.com")
      ss.fcss(".gLFyf").s_keys("RR")
      """
      clear = lambda self: [elem.clear1(), self][1]
      for k,v in locals().items():
        try:    bind(elem, k, v)
        except: pass
      for i in dir(webdriver):
        if not i.startswith("_"):
          if not i.startswith("find"):
            if not i == "s_keys":
              tryprocess(setattr, elem, i, tryreturn(getattr, webdriver, i))
      # [don't do this, it sets the find_elements, wait, that uses ftn, etc, so none other collide]
      return elem
      """
      ss = Bowser()("ch")
      ss.get("google.com")
      a = ss.ftn("body")
      assert ss == a.click()
      """
    """
    ss = Browser()("sele")
    ss.get("google.com").bat()
    ss.ftns("input").ftns("input")
    ss.bat("A", "B")
    ss.batterypack
    """
    actionitem = lambda self: self
    bat = lambda self, *args, batterysleep_time = GLOBAL_BROWSER_STEP_SLEEPTIME: [setattr(self, "batterypack", []), setattr(self, "batterysleep", batterysleep_time), self][2] if len(args) == 0 else [[[self.batterypack[idx].click() if i=="Click" else self.nexturlwait() if i == "Nexturlwait" else self.nexturlwaitjoin() if i == "Nexturlwaitjoin" else () if i == Null else self.batterypack[idx].send_keys(i), self.sp(self.batterysleep)] for idx, i in enum(args)], self][1]
    atomicdialog = lambda self, x, method: [OSA.display_dialog(x, text_prompt = False) if True == method() else 1, self][1]
    binded_list = type("", (list,), dict(__call__ = lambda self, webdriver: [setattr(self, "ss", webdriver),self.ora(),(self)if(self!=["f","a","i","l"])else("fail")][2], click = lambda self, sleeptime = GLOBAL_BROWSER_STEP_SLEEPTIME: [binded_list(trykeycall("click", self))(webdriver = self.ss), self.sp(sleeptime)][0], send_keys = lambda self, keys, sleeptime = GLOBAL_BROWSER_STEP_SLEEPTIME: [trykeycall("clear", self), self.sp(sleeptime), binded_list(trykeycall("send_keys", self, keys))(webdriver = self.ss), self.sp(sleeptime)][2], s_keys = lambda self, keys, r1 = 0.2, r2 = 0.7, sleeptime = GLOBAL_BROWSER_STEP_SLEEPTIME: [[trykeycall("clear", self), self.sp(sleeptime), binded_list([[[tryprocess(elem.send_keys, i), time.sleep(random.uniform(r1, r2))][0] for i in keys] for elem in self])(webdriver = self)][2], self.sp(sleeptime)][0], clear = lambda self, sleeptime = GLOBAL_BROWSER_STEP_SLEEPTIME: [binded_list(trykeycall("clear", self))(webdriver = self.ss), self.sp(sleeptime)][0], ora = lambda self: [tryprocess(setattr, self, i, tryreturn(getattr, self.ss, i)) for i in dir(self.ss) if not i.startswith("_") and i != "s_keys"])) # could be just and i != "s_keys" # or... and i not in dir(self) # less risk
    fcn = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.wait_for('CLASS_NAME', Elem, _time=_time), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fcss = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.wait_for('CSS_SELECTOR', Elem, _time=_time), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fid = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.wait_for('ID', Elem, _time=_time), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    flt = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.wait_for('LINK_TEXT', Elem, _time=_time), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fn = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.wait_for('NAME', Elem, _time=_time), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fplt = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.wait_for('PARTIAL_LINK_TEXT', Elem, _time=_time), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    ftn = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.wait_for('TAG_NAME', Elem, _time=_time), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fx = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", bind_more(self.wait_for('XPATH', Elem, _time=_time), webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fcns = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.wait_fors('CLASS_NAME', Elem, _time=_time))(webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fcsss = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.wait_fors('CSS_SELECTOR', Elem, _time=_time))(webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fids = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.wait_fors('ID', Elem, _time=_time))(webdriver = self)),  self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    flts = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.wait_fors('LINK_TEXT', Elem, _time=_time))(webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fns = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.wait_fors('NAME', Elem, _time=_time))(webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fplts = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.wait_fors('PARTIAL_LINK_TEXT', Elem, _time=_time))(webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    ftns = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.wait_fors('TAG_NAME', Elem, _time=_time))(webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    fxs = lambda self, Elem, _time=GLOBAL_BROWSER_ELEMENT_WAIT_TIME, **kwargs: [setitem(kwargs, "hotspot", binded_list(self.wait_fors('XPATH', Elem, _time=_time))(webdriver = self)), self.batterypack.append(kwargs["hotspot"]), kwargs["hotspot"]][2]
    up = lambda self, x=1: binded_list([self.key(Keys.UP) for i in range(x)])(webdriver = self)
    down = lambda self, x=1: binded_list([self.key(Keys.DOWN) for i in range(x)])(webdriver = self)
    left = lambda self, x=1: binded_list([self.key(Keys.LEFT) for i in range(x)])(webdriver = self)
    right = lambda self, x=1: binded_list([self.key(Keys.RIGHT) for i in range(x)])(webdriver = self)
    enter = lambda self, x=1: binded_list([self.key(Keys.ENTER) for i in range(x)])(webdriver = self)
    zoom_out = lambda self, x=10: binded_list([self.execute_script, [(self.ctrlkey('-'), self.cmdkey('-')) for i in range(x)]])(webdriver = self)
    def zoom_level(self, level = GLOBAL_BROWSER_PAGEGOT_ZOOM_LEVEL):
      chrome_levels  = [33, 50, 67, 80, 90, 100, 110, 125, 133, 150, 175, 200, 250, 300, 400, 500, 25] # edited
      firefox_levels = [30, 50, 67, 80, 90, 100, 110, 120, 133, 150, 170, 200, 240, 300]
      if self.driver_type == "firefox":
        self.zoom_out(len(firefox_levels))
        self.zoom_in(level)
      elif self.driver_type == "chrome":
        chrome_level = chrome_levels[level]
        self.execute_script("document.body.style.zoom='{}%'".format(chrome_level))
      elif self.driver_type == "phantomjs":
        pass
      time.sleep(1)
      time.sleep(1)
      return self
    set_zoom_level = lambda self, x: [setattr(self, "zoom_level_idx", x), self.zoom_level(self.zoom_level_idx), self][2]
    zoom_in = lambda self, x=1: binded_list([(self.ctrlkey('='), self.cmdkey('='), time.sleep(0.5)) for i in range(x)])(webdriver = self)
    tab = lambda self, x=1, s=1: binded_list([[self.key(Keys.TAB), zz(s)] for i in range(x)])(webdriver = self)
    key = lambda self, keys: [ActionChains(self).send_keys(keys).perform(), self][1]
    ctrlkey = lambda self, keys: [ActionChains(self).key_down(Keys.CONTROL).send_keys(keys).key_up(Keys.CONTROL).perform(), self][1]
    cmdkey = lambda self, keys: [ActionChains(self).key_down(Keys.COMMAND).send_keys(keys).key_up(Keys.COMMAND).perform(), self][1]
    pagestop_timeout = lambda self: [self.ftn("body").send_keys(Keys.ESCAPE), self][1]
    handle_alert = lambda self, x=True: [tryprocess(Alert(self).accept) if x == True else tryprocess(Alert(self).dismiss), self][1]
    clear_cookies = lambda self, profile: [os.system("rm -rf ~/Library/Application\ Support/Firefox/Profiles/{}/cookies*".format([i for i in os.listdir(GLOBAL_FIREFOX_PROFILE_PATH) if i.split(".")[-1] == profile][0]))if("ch"!=profile)else([os.system("killall Google\ Chrome &>/dev/null"), time.sleep(1), os.system("rm -rf '~/Library/Application Support/Google/Chrome/Profile 1000'"), time.sleep(1), os.system("/Applications/Google\ Chrome\ 70.app/Contents/MacOS/Google\ Chrome --args --profile-directory=Profile\ 1000 &>/dev/null &"), time.sleep(1), os.system("/usr/bin/killall Google\ Chrome &>/dev/null &"), process(lambda: [time.sleep(1), os.system("/usr/bin/killall Google\ Chrome &>/dev/null &")])]), self][1]
    whippin = lambda self: self
    def space(self):
      self.key(self.Keys.SPACE)
      return self
    def ffs(self,tag,attr,value, _time = GLOBAL_BROWSER_ELEMENT_WAIT_TIME, GLOBAL_VARIABLE = None):
      start_time = datetime.now()
      if (None==GLOBAL_VARIABLE):
        GLOBAL_VARIABLE = generate_one_random_number(20)
        globals()[GLOBAL_VARIABLE] = start_time
      tags = self.find_elements_by_tag_name(tag)
      for e in tags:
        try:  
          if e.get_attribute(attr) == value:
            R = bind_more(e, webdriver = self)
            self.batterypack.append(R)
            return R
        except: pass
      if (datetime.now() - globals()[GLOBAL_VARIABLE]).seconds < _time:
        return self.ffs(tag = tag, attr = attr, value = value, _time = _time, GLOBAL_VARIABLE = GLOBAL_VARIABLE)
      assert False
    def ffss(self,tag,attr,value, _time = GLOBAL_BROWSER_ELEMENT_WAIT_TIME, GLOBAL_VARIABLE = None):
      start_time = datetime.now()
      if (None==GLOBAL_VARIABLE):
        GLOBAL_VARIABLE = generate_one_random_number(20)
        globals()[GLOBAL_VARIABLE] = start_time
      tags = self.find_elements_by_tag_name(tag)
      element_list = []
      for i in tags:
        if i.get_attribute(attr) == value:
          element_list.append(i)
      if (datetime.now() - globals()[GLOBAL_VARIABLE]).seconds < _time and element_list == []:
        self.ffss(tag = tag, attr = attr, value = value, _time = _time, GLOBAL_VARIABLE = GLOBAL_VARIABLE)
      R = binded_list(element_list)(webdriver = self)
      self.batterypack.append(R)
      return R
    def ffst(self, tag, text, _time = GLOBAL_BROWSER_ELEMENT_WAIT_TIME, GLOBAL_VARIABLE = None):
      start_time = datetime.now()
      if (None==GLOBAL_VARIABLE):
        GLOBAL_VARIABLE = generate_one_random_number(20)
        globals()[GLOBAL_VARIABLE] = start_time
      tags = self.find_elements_by_tag_name(tag) # !!
      for i in tags:
        if (datetime.now() - start_time).seconds > 100:
          print("over 100 refresh_every_x_seconds")
          if input("continue? (y/n): ") == "n":
            return
        if i.text == text:
          R = bind_more(i, webdriver = self)
          redprint("APPEND")
          self.batterypack.append(R)
          return R
      
      redprint("ffst return nothing so it should raise an Error/")

      if (datetime.now() - globals()[GLOBAL_VARIABLE]).seconds < _time:
        return self.ffst(tag = tag, text = text, _time = _time, GLOBAL_VARIABLE = GLOBAL_VARIABLE)
      assert False
    def ffsts(self, tag, text, _time = GLOBAL_BROWSER_ELEMENT_WAIT_TIME, GLOBAL_VARIABLE = None):
      start_time = datetime.now()
      if (None==GLOBAL_VARIABLE):
        GLOBAL_VARIABLE = generate_one_random_number(20)
        globals()[GLOBAL_VARIABLE] = start_time
      tags = self.find_elements_by_tag_name(tag)
      element_list = []
      for i in tags:
        if (datetime.now() - start_time).seconds > 100:
          print("over 100 refresh_every_x_seconds")
          if input("continue? (y/n): ") == "n":
            return
        if i.text == text:
          element_list.append(i)
      if (datetime.now() - globals()[GLOBAL_VARIABLE]).seconds < _time and element_list == []:
        return self.ffsts(tag = tag, text = text, _time = _time, GLOBAL_VARIABLE = GLOBAL_VARIABLE)
      R = binded_list(element_list)(webdriver = self)
      self.batterypack.append(R)
      return R
      assert False
    def bacpac(self, start = False, end = False, url = None):
      (setattr(self,"bacpac_urls",[]))if(None==getattr(self, "bacpac_urls", None))else()
      if start == True:
        self.bacpac_urls.append(self.current_url) if self.current_url not in self.bacpac_urls else ()
      if end == True:
        while True:
          if self.current_url not in self.bacpac_urls:
            self.bacpac_urls.append(self.current_url)
            print("break")
            break
          else:
            ()
        if url not in self.bacpac_urls:
          assert_dialog(lambda: url == self.bacpac_urls.__getitem__(-1), "current url: %s\nrequired url: %s\nsomething has changed"%(self.current_url, url))
        elif url in self.bacpac_urls:
          print("verified)")
          ()
      return self
    def pagedowndo(self, x, _time = GLOBAL_BROWSER_ELEMENT_WAIT_TIME):
      start_time = datetime.now()
      for i in range(WHILE_TRUE):
        if (datetime.now() - start_time).seconds > GLOBAL_BROWSER_ELEMENT_WAIT_TIME:
          assert False
        if(True==x()):
          self.key(self.Keys.PAGE_DOWN)
        else:
          self.key(self.Keys.HOME)
          time.sleep(GLOBAL_BROWSER_STEP_SLEEPTIME)
          return self
    def arrowdowndo(self, x, _time = GLOBAL_BROWSER_ELEMENT_WAIT_TIME):
      start_time = datetime.now()
      for i in range(WHILE_TRUE):
        if (datetime.now() - start_time).seconds > GLOBAL_BROWSER_ELEMENT_WAIT_TIME:
          assert False
        if(True==x()):
          self.key(self.Keys.ARROW_DOWN)
        else:
          self.key(self.Keys.HOME)
          time.sleep(GLOBAL_BROWSER_STEP_SLEEPTIME)
          return self
    def s_keys(self, elem, x, r1 = 0.2, r2 = 0.8):
      elem.clear()
      time.sleep(GLOBAL_BROWSER_STEP_SLEEPTIME)
      time.sleep(1)
      for i in x:
        elem.send_keys(i)
        Q = random.uniform(r1, r2)
        time.sleep(Q)
      return self
    def workable_from(self, element_list, command, *args, **kwargs):
      x = lambda *args, **kwargs: command(*args, **kwargs)
      attempt = trylmap(x, element_list)
      return binded_list([element_list[i] for i in attempt if i == 0])(webdriver = self)
    def html_test(self):
      pyperclip.copy("")
      open(homepath("~/tavern/tavern/test.html"),"w").write(self.page_source)
      if "/Applications/Firefox\ 46.app" not in subprocess.getoutput("ps -ef | grep firefox | grep -v grep"):
        os.system("/Applications/Firefox\ 46.app/Contents/MacOS/firefox-bin ~/tavern/tavern/test.html -foreground &")
        time.sleep(4)
      OSA("Firefox 46", ["cmd_l", "return", "delay 1"])
      return self
    def fxsxs(self, x):
      g()["ELEMENT_LIST"] = []
      GET_XPATHS = lambda R: R.find_elements_by_xpath("*")
      def GET_MORE(x):
        List = GET_XPATHS(x)
        if List == []: return
        for i in List:
          g()["ELEMENT_LIST"].extend(List)
          GET_MORE(i)
        return g()["ELEMENT_LIST"]
      GET_MORE(x)
      R = binded_list(g()["ELEMENT_LIST"])
      self.batterypack.append(R)
      return R
    def jcns(self, x, m, kws, _time = GLOBAL_BROWSER_ELEMENT_WAIT_TIME, tc=False):
      S = datetime.now()
      """
      x = "ui-button"
      m = "click"
      kws = {"text":"Close store"}
      """
      # kws = dict(zip(args[0::2], args[1::2]))
      t = self.execute_script("return document.getElementsByClassName('%s')"%(x))
      l = []
      for idx in list(range(len(t))):
        for a,b in kws.items():
          v = None
          if a == "text": v = Strip(self.execute_script("return document.getElementsByClassName('%s')[%s].%s"%(x,idx,"textContent"if("text"==a)else("textContent"))))
          else: v = self.execute_script("return document.getElementsByClassName('%s')[%s].getAttribute('%s')"%(x,idx,a))
          if v!=b:
            l.append(idx)
      r = len(t)
      y = sorted(set(range(r)) - set(l)) #
      E = (_time-((datetime.now()-S).total_seconds()))
      redprint(E)
      if ((y==[])and(E>0)): return [redprint("again,%s"%E),self.jcns(x, m, kws, _time = E)][1]
      elif ((y==[])and(E<=0)): return [] #
      if(m==0): return [self.execute_script("return document.getElementsByClassName('%s')[%s]"%(x,idx)) for idx in y]
      for idx in y:
        if m == "click": self.execute_script("document.getElementsByClassName('%s')[%s].click()"%(x,idx))
        else: self.execute_script("document.getElementsByClassName('%s')[%s].value = '%s'"%(x,idx,m))if(tc==False)else(self.execute_script("document.getElementsByClassName('%s')[%s].textContent = '%s'"%(x,idx,m)))
      time.sleep(GLOBAL_BROWSER_STEP_SLEEPTIME)
      return self

      """
      x = "ui-button"
      m = "click"
      kws = {"text":"Close store"}
      idx = [5]
      ss.fcns(x)[5].click() # does not work @ top of page
      self.execute_script("document.getElementsByClassName('%s')[%s].click()"%(x,idx)) # works @ top of page
      
      """
      """
      ss.get("{}/settings/account".format(self.Administrative_Url))
      kws = {"text":"Close store","name":"button","data-bind-event-click":"passwordConfirmationModal.show()"}
      x = "ui-button"
      m = "click"
      # getElementsByTagName
      """
    def jtns(self, x, m, kws, _time = GLOBAL_BROWSER_ELEMENT_WAIT_TIME, tc=False):
      # added strip to text
      S = datetime.now()
      # kws = dict(zip(args[0::2], args[1::2]))
      redprint("_time: %s, S: %s" % (_time, S))
      t = self.execute_script("return document.getElementsByTagName('%s')"%(x))
      l = []
      for idx in list(range(len(t))):
        for a,b in kws.items():
          v = None
          if a == "text": v = Strip(self.execute_script("return document.getElementsByTagName('%s')[%s].%s"%(x,idx,"textContent"if("text"==a)else("textContent"))))
          else: v = self.execute_script("return document.getElementsByTagName('%s')[%s].getAttribute('%s')"%(x,idx,a))
          if v!=b:
            l.append(idx)
      r = len(t)
      y = sorted(set(range(r)) - set(l)) #
      E = (_time-((datetime.now()-S).total_seconds()))
      redprint(E)
      if ((y==[])and(E>0)): return [redprint("again,%s"%E),self.jtns(x, m, kws, _time = E)][1]
      elif ((y==[])and(E<=0)): return [] #
      if(m==0): return [self.execute_script("return document.getElementsByTagName('%s')[%s]"%(x,idx)) for idx in y]
      for idx in y:
        if m == "click": self.execute_script("document.getElementsByTagName('%s')[%s].click()"%(x,idx))
        else: self.execute_script("document.getElementsByTagName('%s')[%s].value = '%s'"%(x,idx,m))if(tc==False)else(self.execute_script("document.getElementsByTagName('%s')[%s].textContent = '%s'"%(x,idx,m)))
      time.sleep(GLOBAL_BROWSER_STEP_SLEEPTIME)
      return self
    def jns(self, x, m, kws, _time = GLOBAL_BROWSER_ELEMENT_WAIT_TIME, tc=False):
      S = datetime.now()
      # kws = dict(zip(args[0::2], args[1::2]))
      t = self.execute_script("return document.getElementsByName('%s')"%(x))
      l = []
      for idx in list(range(len(t))):
        for a,b in kws.items():
          v = None
          if a == "text": v = Strip(self.execute_script("return document.getElementsByName('%s')[%s].%s"%(x,idx,"textContent"if("text"==a)else("textContent"))))
          else: v = self.execute_script("return document.getElementsByName('%s')[%s].getAttribute('%s')"%(x,idx,a))
          if v!=b:
            l.append(idx)
      r = len(t)
      y = sorted(set(range(r)) - set(l)) #
      E = (_time-((datetime.now()-S).total_seconds()))
      redprint(E)
      if ((y==[])and(E>0)): return [redprint("again,%s"%E),self.jns(x, m, kws, _time = E)][1]
      elif ((y==[])and(E<=0)): return [] #
      if(m==0): return [self.execute_script("return document.getElementsByName('%s')[%s]"%(x,idx)) for idx in y]
      for idx in y:
        if m == "click": self.execute_script("document.getElementsByName('%s')[%s].click()"%(x,idx))
        else: self.execute_script("document.getElementsByName('%s')[%s].value = '%s'"%(x,idx,m))if(tc==False)else(self.execute_script("document.getElementsByName('%s')[%s].value = '%s'"%(x,idx,m)))
      time.sleep(GLOBAL_BROWSER_STEP_SLEEPTIME)
      return self
    def captcha_check(self):

      lol = [i for i in self.ftns("iframe") if True == tryreturn(lambda: "https://www.google.com/recaptcha/api2" in i.get_attribute("src") )]
      F = False
      for i in lol:
        self.frame(i)
        try:
          if "fail"==self.fcn("recaptcha-checkbox-checkmark",_time=2):
            0/0
          F= True
          blueprint("F TRUE")
        except:
          self.dc()
          continue
        self.dc()
      #if tryreturn(lambda: self.fcns("g-recaptcha",_time=4)) == 0:
      if F:
        OSA.display_dialog("There is a Google ReCaptcha on this page. Please complete the captcha and after the captcha is completed, click OK in this prompt. The captcha is complete when the check appears.\n\nIf there is no captcha, please ignore this message.",text_prompt=False)
      return self
    #bind = lambda obj,name,method: setattr(obj, name, MethodType(method,obj))
    def tp(self, func, *args, **kwargs):
      import multiprocessing
      t = multiprocessing.Process(target=func, args=args, kwargs=kwargs)
      #t = multiprocessing.Process(target=func)#, args=args, kwargs=kwargs)
      try:
        t.run()
        return self
      except Exception as e:
        #OSA.notify("%s, %s, %s" %  (str(func), str(args), str(kwargs)))
        #OSA.notify("tryprocess: " + str(e))
        #pyperclip.copy(str(e))
        return self

    def sp(self, x):
      time.sleep(x)
      return self

    for k,v in locals().items():
      try:    bind(wd, k, v)
      except: pass
    [wd.set_window_index(window_index[0],window_index[1],window_index[2],window_index[3]),setattr(wd,"zoom_level_idx",GLOBAL_BROWSER_PAGEGOT_ZOOM_LEVEL)]if(window_index!=None and type(window_index)is(list))else(setattr(wd,"zoom_level_idx",window_index))if(window_index!=None and type(window_index)is(int))else(setattr(wd,"zoom_level_idx",GLOBAL_BROWSER_PAGEGOT_ZOOM_LEVEL))
    # :tmp bricks:
    #if window_index and type(window_index) is list:
    #  wd.set_window_index(window_index[0],window_index[1],window_index[2],window_index[3])
    #  wd.zoom_level_idx = GLOBAL_BROWSER_PAGEGOT_ZOOM_LEVEL
    #elif window_index and type(window_index) is int:
    #  wd.zoom_level_idx = window_index
    #else:
    #  wd.zoom_level_idx = GLOBAL_BROWSER_PAGEGOT_ZOOM_LEVEL
    def p(self,*args,**kwargs):
      distinct_print(*args,**kwargs)
      return self
    bind3(wd,p)
    def get_element_attributes(self, element):
      attrs = self.execute_script('var items = {}; for (index = 0; index < arguments[0].attributes.length; ++index) { items[arguments[0].attributes[index].name] = arguments[0].attributes[index].value }; return items;', element)
      return binded_list(attrs)(webdriver = self)
    bind3(wd, get_element_attributes)
    wd.execute_script1 = wd.execute_script
    # :tmp bricks:
    # def execute_script(self, script):
    #   return [self.execute_script1(script), self][1]
    # bind3(self, execute_script) # you can return a string with this. so, don't bind
    wd.es = wd.execute_script
    wd.refresh1 = wd.refresh
    def refresh(self):
      try:
        self.refresh1()
        self.zoom_level(level=self.zoom_level_idx)
      except Exception as e:
        e
        # timeout
        self.ftn("body").send_keys(Keys.ESCAPE)
      return self
    bind3(wd, refresh)
    wd.get1 = wd.get
    wd
    wd.delete_all_cookies1 = wd.delete_all_cookies
    delete_all_cookies = lambda self: [self.delete_all_cookies1(), self][1]
    bind3(wd, delete_all_cookies)
    def dc(self):
      self.switch_to_default_content()
      return self
    bind3(wd, dc)
    def frame(self, x):
      self.switch_to_frame(x)
      return self
    bind3(wd, frame)
    wd.switch_to_frame1 = wd.switch_to_frame
    def switch_to_frame(self, x):
      self.switch_to_frame1(x)
      return self
    wd.batterypack = []
    wd.imko_on = False
    wd.SHADOW = SHADOW
    for i in wd.Keys.__dict__:
      if not i.startswith("_"):
        setattr(wd, i, eval("""lambda element: element.send_keys("%s")""" %(Keys.__dict__[i])) )
    def get(self, url, timeout = GLOBAL_BROWSER_GET_PAGE_WAIT_TIME, **kwargs):
      """
      if self.current_url == url:
        tryprocess(lambda: self.ftn("body").send_keys(Keys.ESCAPE))
        self.refresh()
        return self
      """
      # Proc return so not load page twice
      if(0==url.startswith("http")): url="https://%s"%url
      try:
        self.set_page_load_timeout(timeout)
        # [may not require] self.set_page_load_timeout(timeout) # so also have to deset it or else every get 
        start_time = datetime.now()
        get_url_process = multiprocessing_process(lambda: self.get1(url))
        # A. Get the url, do not wait.
        # B. Start a sleep checker that terminates and ends.
        # C. 
        # timeout_checker = multiprocessing_process(lambda: [time.sleep(timeout), get_url_process.terminate(), self.ftn("body").send_keys(self.Keys.ESCAPE)])
        while True:
          print("running while true anyways")
          if get_url_process.is_alive() == True and ((datetime.now()-start_time).seconds < timeout):
            time.sleep(0.25)
            None
            print(":A", (datetime.now()-start_time).seconds)
          elif get_url_process.is_alive() == True and ((datetime.now()-start_time).seconds >= timeout):
            time.sleep(0.25)
            redprint("Terminating")
            get_url_process.terminate()
            redprint("get url process status: %s" % get_url_process.is_alive())
            redprint("sending keys")
            self.ftn("body").send_keys(Keys.ESCAPE)
            redprint("sent keys")
            print(":B", (datetime.now()-start_time).seconds)
          elif get_url_process.is_alive() == False and ((datetime.now()-start_time).seconds < timeout):
            time.sleep(0.25)
            None
            break
            print(":C", (datetime.now()-start_time).seconds)
          elif get_url_process.is_alive() == False and ((datetime.now()-start_time).seconds >= timeout):
            time.sleep(0.25)
            None
            break
            print(":D", (datetime.now()-start_time).seconds)
      except Exception as e:
        #redprint("[page_stop timeout][%s]"%e)
        redprint("pageload escape")
        while True:
          if 0 == tryprocess(lambda: self.ftn("body").send_keys(Keys.ESCAPE)):
            self.pagestop_timeout()
            return self.get(url, timeout=timeout, **kwargs)

      time.sleep(GLOBAL_BROWSER_PAGEGOT_WAIT_TIME)
      self.zoom_level(level = self.zoom_level_idx)

      # add image_compare_image here just to ensure pagegot rules
      # if self.imko_checker == True:
      #  self.imko(part = kwargs.get("imko_part", 0))
      
      return self
    globalise(wd,"ss_v")
    bind3(wd, get)
    if "ch" in profile:
      wd.delete_all_cookies()
    if GLOBAL_BROWSER_REQUIRE_SPEEDTEST == True:
      speedtest.result()
    return wd
class Browser(Bowser):
  ""
class Emailer(object):
  def get_credentials(self):
    #os.makedirs(credential_path, exist_ok=True)
    q = "." + "|".join([self.user, "Client_Secret_2", "GSuite"]) + ".json"
    qq = "." + "|".join([self.user, "Client_Secret", "GSuite"]) + ".json"
    store = oauth2client.file.Storage(homepath("~/tavern/tavern/soda/%s"%q))
    print("store: %s" % store)
    if q in key("filename", All(Binarydata)):
      Binarydata().export(q, homepath("~/tavern/tavern/soda/%s"%q))
    try:
      credentials = store.get()
      print("credentials: %s"%credentials)
    except Exception as e:
      print(e)
    if 'credentials' not in locals().keys():
      # the credentials here must be downloaded
      Binarydata().export(qq, homepath("~/tavern/tavern/soda/%s"%(qq)))
      flow = client.flow_from_clientsecrets(homepath("~/tavern/tavern/soda/%s"%(qq)), 'https://mail.google.com/')
      flow.user_agent = 'Gmail API Python Send Email'
      OSA.display_dialog("Your browser will be opened to authenticate credentials for gmail api. Please click OK here, your browser will open a new window. Please sign in, you will see a window that says \"%s wants to access your Google Account\". Please click Allow.\n\nNote: The same process will occur again to authenticate credentials to the google drive api." % (self.user), text_prompt = False, buttons = ["OK"])
      credentials = tools.run_flow(flow, store)
      print('Storing credentials to %s'%homepath("~/tavern/tavern/soda"))
    if not credentials or credentials.invalid:
      # the credentials here must be downloaded
      Binarydata().export(qq, homepath("~/tavern/tavern/soda/%s"%(qq)))
      flow = client.flow_from_clientsecrets(homepath("~/tavern/tavern/soda/%s"%(qq)), 'https://mail.google.com/')
      flow.user_agent = 'Gmail API Python Send Email'
      OSA.display_dialog("Your browser will be opened to authenticate credentials for gmail api. Please click OK here, your browser will open a new window. Please sign in, you will see a window that says \"%s wants to access your Google Account\". Please click Allow." % (self.user), text_prompt = False, buttons = ["OK"])
      credentials = tools.run_flow(flow, store)
      print('Storing credentials to %s'%homepath("~/tavern/tavern/soda"))
    if q not in key("filename", All(Binarydata)):
      os.chdir(homepath("~/tavern/tavern/soda/"))
      Binarydata().update_or_create(q)
    self.credentials = credentials
  def set_service(self):
    http = self.credentials.authorize(httplib2.Http())
    service = discovery.build('gmail', 'v1', http=http)
    self.service = service
  def init(self, user):
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    from oauth2client.file import Storage
    from oauth2client import client, tools
    from apiclient import discovery
    import oauth2client
    import mimetypes
    import httplib2
    globals().update(locals())


    self.user = user
    #self.credential_path = '%s/%s.json' % (credential_path, user.split('.com')[0])
    #print(self.credential_path)
    try:
      self.__dict__.update(locals())
      self.get_credentials()
      self.set_service()
      self.m = self.service.users().messages()
      self.a = self.service.users().messages().attachments()
      self.t = self.service.users().threads()
      print(self.m,self.a,self.t)
    except:
      if GLOBAL_EMAILER_INITIALIZE_ERROR_MESSAGE:
        OSA.log("Unable to initiate Emailer.",tp=False)
      else:
        return
  def initiate_2(self,user):
    user = "support@steampunkstop.com"
    file = ".%s|Gmail_Client_Secret.pickle"%(user)

    # below commented out
    # from __future__ import print_function
    import pickle
    import os.path
    from googleapiclient.discovery import build
    from google_auth_oauthlib.flow import InstalledAppFlow
    from google.auth.transport.requests import Request
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    from oauth2client.file import Storage
    from oauth2client import client, tools
    from apiclient import discovery
    import oauth2client
    import mimetypes
    import httplib2
    import base64
    # If modifying these scopes, delete the file token.pickle.
    SCOPES = ['https://mail.google.com/']

    def main():
        """Shows basic usage of the Gmail API.
        Lists the user's Gmail labels.
        """
        creds = None
        # The file token.pickle stores the user's access and refresh tokens, and is
        # created automatically when the authorization flow completes for the first
        # time.
        # Try To Export The File
        tp(lambda:Binarydata().export(file))
        """ Here, use file as the file address """
        if os.path.exists(file):
            """ Here, use file as the file address """
            with open(file, 'rb') as token:
                creds = pickle.load(token)
        # If there are no (valid) credentials available, let the user log in.
        # if not creds or not creds.valid:
        if not creds:
            """ Here, make sure you have the credentials file. ~/tavern/tavern/credentials.json """
            OSA().log("Here, make sure you have the credentials file. ~/tavern/tavern/credentials.json.")
            shop = OSA().log("Which shop is this for? Enter the shop abbreviation")
            Shop()(shop).GET_GOOGLE_API_PROJECT(user) # saves the credentials.json first and then calls Emailer which will use the credentials.json and save the authenticated pickle file.
            return Emailer().initiate_2(user)
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                flow = InstalledAppFlow.from_client_secrets_file(
                    'credentials.json', SCOPES)
                creds = flow.run_local_server(port=0)
            # Save the credentials for the next run
            """ Here, use file as the file address """
            with open(file, 'wb') as token:
                pickle.dump(creds, token)
            """ Here, use file as the file address """
            Binarydata().update_or_create(file)

        service = build('gmail', 'v1', credentials=creds)

        # Call the Gmail API
        results = service.users().labels().list(userId='me').execute()
        labels = results.get('labels', [])

        if not labels:
            print('No labels found.')
        else:
            print('Labels:')
            for label in labels:
                print(label['name'])

        return service
    return main()
  def set_services_initiate_2(self,user):
    service = self.initiate_2(user)
    self.service = service
    self.m = self.service.users().messages()
    self.a = self.service.users().messages().attachments()
    self.t = self.service.users().threads()
    print(self.m,self.a,self.t)
    return self
  def remove_labels(self, id, labels=['UNREAD']):
    return self.m.modify(userId='me', id=id, body={'removeLabelIds':labels}).execute()
  def delete_message(self, id):
    x = self.t.delete(userId='me', id=id).execute()
    blueprint("deleted: %s" % x)
    return x
  def set_messages(self, count = 50):
    messages = []
    original_messages = []
    data = []
    nextpagetoken = None
    idx = 0
    msg_datas = None
    try:
      while True:
        print(nextpagetoken)
        if nextpagetoken is not None:
          msg_datas = self.m.list(userId='me', pageToken=nextpagetoken).execute()
        elif nextpagetoken is None:
          msg_datas = self.m.list(userId='me').execute()
          if msg_datas == {'resultSizeEstimate': 0}:
            self.messages = []
            OSA.notify("No messages")
            return
        print(msg_datas['messages'])
        print("getting more messages... idx: %s" % idx)
        data.extend(msg_datas.pop('messages', []))
        if 'nextPageToken' not in msg_datas.keys():
          break
        else:
          nextpagetoken = msg_datas['nextPageToken']
        idx += 1
        break # works better w/ this ? 
    except Exception as e:
      print("error: %s" % (e))
    print("len data: %s" % len(data))
    

    """ ::: Ticket is removed as of now ::: """
    #existing_threads = [i.id for i in Ticket.objects.all()]
    #data = [i for i in data if i['id'] not in existing_threads]
    print("len new data: %s" % len(data))

    print("len data: %s"% len(data))
    errors = 0
    """
                      count=100
                      """
    data = data[:count]
    true_ids = set()
    messages_in_without = []
    messages_in_without2 = []
    for idx, msg in enumerate(data):
      #@risky to pool api calls.
      try:
        # try:
        #   x = Emit.objects.get(true_id=msg['id'])
        #   redprint("[Emit.objects.get(true_id=msg['id'])]   [Exists] -- ending set more messages  [%s]"%msg['id'])
        #   #return
        # except Exception as e:
        #   redprint("[current message id][%s][not found in Emit.objects.all()][so saving this message as a new Emit], %s"%(msg["id"],e))



        print("getting message %s out of %s" % (idx+1, len(data)))
        initial_data = self.m.get(userId='me',id=msg['id']).execute()
        original_messages.append(initial_data)
        self.original_messages = original_messages
        header_data = initial_data['payload']['headers']
        msg_data   = {}
        msg_data['id'] = initial_data['id']


        msg_data['labelIds'] = initial_data['labelIds']
        # skip any drafts.
        if "DRAFT" in msg_data["labelIds"]:
          redprint("Skipping Draft")
          continue


        if "SENT" in msg_data["labelIds"]:
          msg_data["direction"] = 1
        elif "SENT" not in msg_data["labelIds"]:
          msg_data["direction"] = 0
        try:
          try:
            msg_data['sender'] = keyequals('name', 'Return-Path', header_data)[0]['value']
          except:
            msg_data['sender'] = keyequals('name', 'From', header_data)[0]['value']
          try:
            msg_data['sender'] = re.findall(r'<(.*)>', msg_data['sender'])[0]
          except:
            pass
          try:
            msg_data['sender'] = keyequals('name', 'Reply-To', header_data)[0]['value']
            msg_data['sender'] = re.findall('<(.*?@.*?>)',msg_data['sender'])[0]
            print("found a reply to")
          except:
            pass
          msg_data['receiver'] = keyequals('name', 'To', header_data)[0]['value']
          try:
            msg_data['receiver'] = re.findall(r'<(.*)>', msg_data['receiver'])[0]
          except:
            pass
        except:
          try:
            msg_data['receiver'] = keyequals('name', 'To', header_data)[0]['value']
          except:
            pass

        emailer_name = or_list(lambda:findall(keyequals("name","From",header_data)[0]["value"],"(.*?) <.*?@.*?>")[0],lambda:findall(keyequals("name","From",header_data)[0]["value"],"^.*$")[0])
        msg_data["emailer_name"] = emailer_name

        try:
          msg_data['subject'] = keyequals('name', 'Subject', header_data)[0]['value']
        except:
          print("header data")
          print(header_data)
          msg_data["subject"] = "No subject"
        msg_data['date'] = or_list(lambda:keyequals('name', 'Received', header_data)[-1]['value'].split(';')[-1].strip(),lambda:keyequals("name","Date",header_data)[0]["value"])
        if re.findall(r" \(.*?<.*?@.*?\.com.*?>.*?\)",msg_data["date"]):
          msg_data["date"] = msg_data["date"].replace(re.findall(r" \(.*?<.*?@.*?\.com.*?>.*?\)",msg_data["date"])[0],"")
        if re.findall(r"^from.*?HTTP.*?id .*? ",msg_data["date"]):
          msg_data["date"] = msg_data["date"].replace(re.findall(r"^from.*?HTTP.*?id .*? ",msg_data["date"])[0],"")
        msg_data["date"] = Date().parse_date(msg_data["date"],remove_tzinfo=True,localize_timezone=True)

        try: msg_data['parts'] = initial_data['payload']['parts']
        except: pass
        
        pay = self.m.get(userId='me',id=msg['id'], format='raw').execute()
        pay_2 = self.m.get(userId='me',id=msg['id'], format='full').execute()
        import base64
        message = base64.urlsafe_b64decode(pay['raw'].encode('ASCII')).decode("utf-8", "ignore")
        message_2 = base64.urlsafe_b64decode(pay['raw'].encode('ASCII'))
        message = message

        msg_data["hidden_message"] = message
        msg_data["hidden_message_2"] = message_2
        msg_data["hidden_message_pay_raw"] = pay["raw"]
        try:
          msg_data["hidden_message_3"] = base64.urlsafe_b64decode(pay_2["payload"]["parts"][-1]["body"]["data"])
          msg_data["hidden_message_3"] = (findall(  msg_data["hidden_message_3"].encode(errors="ignore"),r"(?s)<.*>")[0]).encode() if msg_data["hidden_message_3"].encode(errors="ignore").startswith("<") else msg_data["hidden_message_3"]
        except:
          try:
            msg_data["hidden_message_3"] = base64.urlsafe_b64decode(pay_2["payload"]["body"]["data"])
            msg_data["hidden_message_3"] = (findall(  msg_data["hidden_message_3"].encode(errors="ignore"),r"(?s)<.*>")[0]).encode() if msg_data["hidden_message_3"].encode(errors="ignore").startswith("<") else msg_data["hidden_message_3"]
          except:
            try:
              msg_data["hidden_message_3"] = base64.urlsafe_b64decode(pay_2["payload"]["parts"][-1]["parts"][-1]["body"]["data"])
              msg_data["hidden_message_3"] = (findall(  msg_data["hidden_message_3"].encode(errors="ignore"),r"(?s)<.*>")[0]).encode() if msg_data["hidden_message_3"].encode(errors="ignore").startswith("<") else msg_data["hidden_message_3"]
            except:
              try:
                rf=lmap(lambda i:base64.urlsafe_b64decode(i),findall(json.dumps(pay_2,indent=4),r'"data": ".*?"'))
                rf=lmap(lambda i:i.decode(errors="ignore"), rf)
                s=findall(  ("\n\n\n".join(rf)).strip()  ,  "(?s)<.*>" ) [ 0] if(tryprocess(lambda:findall(  ("\n\n\n".join(rf)).strip()  ,  "(?s)<.*>" ) [ 0])==1)else(("\n\n\n".join(rf)).strip())
                s = s.encode()
                #hidden_message_3 = SOUP(s).text
                msg_data["hidden_message_3"] = s
              except:
                0/0

        #if "Content-Type: text/plain" not in message:
        #  assert False
        if "Content-Type: text/plain" in message:

          content_types = re.findall(r"Content-Type:.*;", message)
          scan_1 = re.findall(r"(?s)Content-Type: text/plain.*", message)[0]

          content_types = re.findall(r"Content-Type:.*;", message)
          scan_2 = None
          if len(content_types) > 1:
            try:scan_2 = re.findall(r"(?s)(Content-Type: text/plain.*)Content-Type", scan_1)[0]
            except: scan_2 = scan_1
          elif len(content_types) == 1:
            scan_2 = scan_1

          print("[tentative] re.sub urls. -- ")
          scan_3 = re.sub(r"(?s)http.*? ","<url>", scan_2)

          print("[morecleans] -- ")
          scan_4 = re.sub(r"[\n]+", "\n", scan_3)

          scan_5 = re.sub(r"(?s)Content-Type.*?\n","",scan_4)
          scan_6 = re.sub(r"(?s)Content-Transfer-Encoding.*?\n","",scan_5)
          scan_7 = re.sub(r"(?s)Mime-Version.*?\n","",scan_6)
          scan_8 = re.sub(r"(?s)Date.*?\n","",scan_7)
          scan_9 = re.sub(r"(?s)\n--.*","",scan_8)
          scan_10 = scan_9.replace("\r", "\n")

          #print(scan_4)
          msg_str = ("Subject: %s\n"%msg_data["subject"]) + scan_10
          #msg_str = msg_str.replace("=", "")
          #msg_str = BeautifulSoup(msg_str, 'lxml').text
          #msg_str = msg_str[msg_str.find('From: '):]
          #for i in range(25):
          #  msg_str = msg_str.replace('\n\n','\n').replace('\r','').replace('\t','').replace(' ',' ').replace(' \n','').replace('\n ','\n')
          msg_data['message'] = msg_str
        def save_message_as_emit(l):
          locals().update(l)

          an_emit = Emit()
          if len(Emit.objects.filter(true_id=msg_data["id"])) == 1:
            emit = Emit.objects.get(true_id=msg_data["id"])
            print("found emit with true id of %s existing.." % msg_data["id"])
          an_emit.direction = msg_data["direction"]
          point_a = None
          point_b = None
          print(json.dumps(msg_data, indent=4))
          if an_emit.direction == 0:
            point_a = msg_data["receiver"]
            point_b = msg_data["sender"]
          elif an_emit.direction == 1:
            #print("direction is 1, receiver is point_b")
            point_a = msg_data["sender"]
            point_b = msg_data["receiver"]
          moment = None
          try: moment = Date().myDatetimenow(        datetime.strptime( re.findall(r"(.*) [+-]", msg_data["date"])[0].split(".")[0], "%a, %d %b %Y %H:%M:%S" )  , round_count = 6) #  """ Out[6]: datetime.datetime(2018, 7, 30, 0, 38, 55)->18210.027025|datetime.datetime(2018, 7, 30, 0, 38, 56)->18210.027037 """
          except Exception as e: redprint("error in setting moment for Emit... %s"%e)  ;   print(msg_data['date'])
          print("moment: %s," % moment)
          true_id = msg_data["id"]
          payload = msg_data["message"]
          print("saving an emit\n")
          #print(json.dumps(an_emit.__dict__, indent=4))
          an_emit.__dict__.update(locals())
          true_ids.add(an_emit.true_id)
          try:
            print("saving an emit..")
            an_emit.save()
          except Exception as e:
            an_emit = Emit.objects.get(true_id=an_emit.true_id)
            None
        #save_message_as_emit(l=locals())

        msg_data.pop('parts', None)
        messages.append(msg_data)
        self.sent_messages = [i for i in messages if i.get("receiver",None)!=None and "SENT" in i["labelIds"]]
        self.messages = [i for i in messages if i.get("receiver",None)!=None and "SENT" not in i["labelIds"]]
        # receiver will default to None if emailer sends email to emailer.(self).{test}
        for i in self.messages:
          i = AttrDict(i)

        #except Exception as e:                                                        # ._. - " (?) "
        #  print(e)                                                                    # /> - > . <
        #  print("\n\n\n\n\nWHY IS THERE AN ERROR?")
        #  print(json.dumps(msg_data, indent=4))
        #  input("take this out when checked. why there is an errors . unknown errors here in Emailer.")
        #  errors += 1
      except Exception as e:
        redprint(e)
        messages_in_without.append(msg_data)
        self.messages_in_without = messages_in_without
        messages_in_without2.append(msg)
        self.messages_in_without2 = messages_in_without2

    if tryprocess(lambda: self.messages) == 0:
      self.messages = []
    redprint(messages_in_without)
    self.errors = messages_in_without
    self.messages = [AttrDict(i) for i in self.messages]
    #distinct_print(ordered_json_dumps(messages_in_without))
    redprint("\n\n")
    redprint(messages_in_without)
    #distinct_print(ordered_json_dumps(messages_in_without))
    print("%s errors" % errors)
    print("%s true ids" % len(true_ids))
    blueprint("%s messages, (%s+%s), errors:(%s)"%(len(data),(len(self.messages)),len(self.sent_messages),len(self.errors)))
    redprint("This now updates to latest existing msg['id']")
    return self.messages
  def create_tickets_from_message(self, i):
    i['date'] = i['date'].replace(' +', ' -')
    i['date'] = i['date'].split(' -')[0]
    i['date'] = i['date'].split('.')[0]
    try:
      i['datetime'] = datetime.strptime(i['date'], "%a, %d %b %Y %H:%M:%S")
    except:
      i['datetime'] = datetime.strptime(i['date'], "%d %b %Y %H:%M:%S")

    i['text'] = i['message']
    try:
      email_accounts_in_message = [i['receiver'], i['sender']]
      i['email'] = [j for j in email_accounts_in_message if 'support@' not in j][0]
    except:
      return
    print("creating... \n%s"%i)

  def set_attachments(self, subject=''):
    filtered_messages = keyequals('subject', subject, self.messages)
    filtered_messages = [i for i in filtered_messages if 'UNREAD' in i['labelIds']]
    for msg_data in filtered_messages:
      msg_data['attachments'] = []
      for part in msg_data['parts']:
        if '.csv' in part['filename'] or '.txt' in part['filename']:
          attachmentId = part['body']['attachmentId']
          attachment = self.a.get(userId='me', messageId=msg_data['id'], id=attachmentId).execute()
          msg_data['attachments'].append({'filename': part['filename'],
                          'data': attachment['data']})
      self.remove_labels(id=msg_data['id'], labels=['UNREAD'])
  def dump_attachments(self, outdir='./'):
    for msg_data in self.messages:
      if 'attachments' in msg_data:
        for attachment in msg_data['attachments']:
          print('writing... %s' % outdir+attachment['filename'])
          with open(outdir+attachment['filename'], 'wb') as f:
            import base64
            f.write(base64.urlsafe_b64decode(attachment['data'].encode('UTF-8')))
    try: return outdir+attachment['filename']
    except: return None
  def reply_to_message(self, thread_id, msg):
    ss = Browser()("sele")
    ss.get("https://gmail.com")
    ss.fcns('gbii')[-1].click()
    print("discovering the slot")
    BASE_EMAIL_STRING = "https://mail.google.com/mail/u/0/#inbox"
    if ss.fcns("gb_Cb")[-1].text != self.user:
      slot = None
      users = ss.fcns("gb_Zb") 
      for idx, user_slot in enumerate(users):
        print(user_slot.text.strip().replace(" (default)", ""))
        if self.user == user_slot.text.strip().replace(" (default)", ""):
          slot = user_slot
          self.slot_idx = idx
          BASE_EMAIL_STRING = "https://mail.google.com/mail/u/%s/#inbox" % self.slot_idx
    thread_url = BASE_EMAIL_STRING + '/' + thread_id
    print("getting %s" % thread_url)
    ss.get(thread_url)
    print("clicking open the last response box")
    ss.fcns('bkH')[-1].click()
    print("typing msg in boxbox..")
    ss.ffs("div","contenteditable","true").send_keys(msg)
    print("sending message...")
    ss.fcns("L3")[-2].click()
    print("sleeping .")
    time.sleep(7)
    ss.quit()
  def get_major_thread_from_one_thread(self, thread_id):
    threads = self.get_all_threads()
    for thread in threads:
      tdata = self.service.users().threads().get(userId="me", id=thread['id']).execute()
      for i in tdata['messages']:
        if i['id'] == thread_id:
          print('match', thread['id'] == thread_id, "if matched True, then the mini thread Id you replied to was the Major one. ^-^")
          print("but this requires extensive in depth testing. would recommend doing 1 by 1.")
  def get_all_threads(self):
    idx = 0
    data = []
    nextpagetoken = None
    while True:
      if nextpagetoken is not None:
        threads = self.service.users().threads().list(userId='me', pageToken=nextpagetoken).execute()
      elif nextpagetoken is None:
        threads = self.service.users().threads().list(userId='me').execute()
      print("getting more messages... idx: %s" % idx)
      data.extend(threads.pop('threads', []))
      if 'nextPageToken' not in threads.keys():
        break
      else:
        nextpagetoken = threads['nextPageToken']
      idx += 1
    return data
  def send_reply(self, msgHtml, threadId, ):
    payload = self.m.get(userId='me',id=threadId).execute().get("payload")
    headers = payload.get("headers")
    headers_dict = dict(zip(key("name", headers), key("value", headers)))

    msgHtml = msgHtml.replace("\n", "<br>")

    
    references = []
    for i in headers:
      if i["name"] in ["In-Reply-To", "References", "Message-ID"]:
        references.extend(i["value"].split(" "))
    redprint(references)
    references = " ".join(references)
    redprint(references)

    subject = headers_dict["Subject"]
    print(headers_dict["From"])
    to = re.findall("[a-z0-9]*@.*?\.[a-z0-9]*", headers_dict["From"])[0]
    from_ = self.user
    threadId = threadId

    print("references: %s" % references)
    print("subject: %s" % subject)
    print("to: %s" % to)
    print("from_: %s" % from_)
    print("threadId: %s" % threadId)


    msg = MIMEMultipart('alternative')
    msg['Subject'] = subject
    msg["To"] = to
    msg['From'] = from_
    msg['threadId'] = threadId


    msg.attach(MIMEText('msgPlain', 'plain'))
    msg.attach(MIMEText(msgHtml, 'html'))
    import base64
    raw = base64.urlsafe_b64encode(msg.as_bytes())
    raw = raw.decode()
    message = {'raw': raw}
    sent_message = self.m.send(userId="me", body=message).execute()
    print("sent message id: %s" % sent_message.get('id', "error"))
    self.modify_as_read(id = threadId)
  def modify_as_read(self, id, star=True):
    if(True==star):
      self.m.modify(userId="me",id=id,body={"addLabelIds":["STARRED"],"removeLabelIds":["UNREAD"]}).execute()
    elif(False==star):
      self.m.modify(userId="me",id=id,body={"removeLabelIds":["UNREAD"]}).execute()
  def send_message(self, subject, to, msgHtml, threadId=None):
    from email.mime.multipart import MIMEMultipart
    msg = MIMEMultipart('alternative')
    msg['Subject'] = subject
    msg['To'] = to
    msg['From'] = self.user



    msg.attach(MIMEText('msgPlain', 'plain'))
    msg.attach(MIMEText(msgHtml, 'html'))
    import base64
    raw = base64.urlsafe_b64encode(msg.as_bytes())
    raw = raw.decode()
    message = {'raw': raw}
    try:
      sent_message = self.m.send(userId="me", body=message).execute()
      print(sent_message['id'])
      return sent_message
    except Exception as e:
      print(e)
      return str(e)
  def send_message_with_attachment(self, subject, to, message_text='', file=''):
    """ ::: the fat frog 2 ::: """
    from email.mime.base import MIMEBase
    from email.mime.image import MIMEImage
    from email.mime.audio import MIMEAudio
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    import mimetypes
    message = MIMEMultipart()
    message['to'] = to
    # message['from'] = self.user
    message['subject'] = subject
    msg = MIMEText(message_text)
    message.attach(msg)
    content_type, encoding = mimetypes.guess_type(file)
    #if content_type.split("/")[0] == 'text':
    #  redprint("text")
    #  fp = open(file, 'rb')
    #  msg = MIMEText(fp.read(), _subtype=content_type.split("/")[1]) # [AttributeError: 'bytes' object has no attribute 'encode']
    #  fp.close()
    #  filename = os.path.basename(file)
    #  msg.add_header('Content-Disposition', 'attachment', filename=filename)
    #  message.attach(msg)
    if content_type is None or encoding is not None:
      content_type = 'application/octet-stream'
      main_type, sub_type = content_type.split('/', 1)
    if content_type == "application/pdf":
      main_type, sub_type = content_type.split("/")
      fp = open(file, 'rb')
      msg = MIMEBase(main_type, sub_type)
      msg.set_payload(fp.read())
      fp.close()
      filename = os.path.basename(file)
      import email.encoders
      msg.add_header('Content-Disposition', 'attachment', filename=filename)
      email.encoders.encode_base64(msg)
      message.attach(msg)
    elif content_type.split("/")[0] == 'image':
      redprint("image")
      fp = open(file, 'rb')
      msg = MIMEImage(fp.read(), _subtype=content_type.split("/")[1])
      fp.close()
      filename = os.path.basename(file)
      msg.add_header('Content-Disposition', 'attachment', filename=filename)
      message.attach(msg)
    elif content_type.split("/")[0] == 'audio':
      redprint("audio")
      fp = open(file, 'rb')
      msg = MIMEAudio(fp.read(), _subtype=content_type.split("/")[1])
      fp.close()
      filename = os.path.basename(file)
      msg.add_header('Content-Disposition', 'attachment', filename=filename)
      message.attach(msg)
    else:
      redprint("elsed")
      fp = open(file, 'rb')
      msg = MIMEBase(content_type.split("/")[0], content_type.split("/")[1])
      msg.set_payload(fp.read())
      fp.close()
      filename = os.path.basename(file)
      msg.add_header('Content-Disposition', 'attachment', filename=filename)
      message.attach(msg)
    import base64
    created_message = {'raw': base64.urlsafe_b64encode(message.as_bytes()).decode()}
    sent_message = self.m.send(userId='me', body=created_message).execute()
    print(sent_message)
    return sent_message
  def failsafe_gmail_api_quickstart():
      # below commented out
      # from __future__ import print_function
      import pickle
      import os.path
      from googleapiclient.discovery import build
      from google_auth_oauthlib.flow import InstalledAppFlow
      from google.auth.transport.requests import Request

      # If modifying these scopes, delete the file token.pickle.
      SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']

      def main():
          """Shows basic usage of the Gmail API.
          Lists the user's Gmail labels.
          """
          creds = None
          # The file token.pickle stores the user's access and refresh tokens, and is
          # created automatically when the authorization flow completes for the first
          # time.
          if os.path.exists('token.pickle'):
              with open('token.pickle', 'rb') as token:
                  creds = pickle.load(token)
          # If there are no (valid) credentials available, let the user log in.
          if not creds or not creds.valid:
              if creds and creds.expired and creds.refresh_token:
                  creds.refresh(Request())
              else:
                  flow = InstalledAppFlow.from_client_secrets_file(
                      'credentials.json', SCOPES)
                  creds = flow.run_local_server(port=0)
              # Save the credentials for the next run
              with open('token.pickle', 'wb') as token:
                  pickle.dump(creds, token)

          service = build('gmail', 'v1', credentials=creds)

          # Call the Gmail API
          results = service.users().labels().list(userId='me').execute()
          labels = results.get('labels', [])

          if not labels:
              print('No labels found.')
          else:
              print('Labels:')
              for label in labels:
                  print(label['name'])

      if __name__ == '__main__':
          main()
class Explain_It(object):
  def explain_it(self):
    simplest_reason = input("simplest reason")
    most_complicated_reason = input("most complicated reason")
    reasons = [simplest_reason,most_complicated_reason]
    while True:
      reasons.insert(1,input("reasons going from simplest to most complicated"))
      print(reasons)
class Firefox_Porter:
  def __init__(self, io = None):
    if Exists(io):
      rm(GLOBAL_FIREFOX_PROFILE_PATH)
      os.makedirs(GLOBAL_FIREFOX_PROFILE_PATH, exist_ok = False)
      lmap(lambda i: os.system("/Applications/Firefox\ 46.app/Contents/MacOS/firefox-bin -CreateProfile %s" % i), lmap(lambda i: i.split(".")[-1], os.listdir(io)))
      lmap(lambda i: os.system("rm -rf %s"%(Join("/",address_backslash(GLOBAL_FIREFOX_PROFILE_PATH),i,"*"))), os.listdir(GLOBAL_FIREFOX_PROFILE_PATH))
      lmap(lambda i: os.system("cp -r %s %s" % (Join("/", io, i, "*"),Join("/",address_backslash(GLOBAL_FIREFOX_PROFILE_PATH),[j for j in os.listdir(GLOBAL_FIREFOX_PROFILE_PATH) if j.split(".")[-1]==i.split(".")[-1]][0],""))), os.listdir(io))
    else:
      io = (lmap(lambda i: i.split(".")[-1], os.listdir(GLOBAL_FIREFOX_PROFILE_PATH)))if(io==None)else(io)
      io = lmap(lambda i: [j for j in os.listdir(GLOBAL_FIREFOX_PROFILE_PATH) if j.split(".")[-1]==i][0], io)
      os.makedirs("Firefox_Port", exist_ok = False)
      lmap(lambda i: os.system("cp -r '%s' '%s'" % (Join("/",GLOBAL_FIREFOX_PROFILE_PATH,i),Join("/","Firefox_Port",i))), io)
      zipUtil("Firefox_Port")
    """
    Firefox_Porter(io = None) # Port Out
    redprint("\n".join(os.listdir("Firefox_Port")))
    Firefox_Porter("Firefox_Port") # Port In

    Firefox_Porter(io = ["sele2", "main_panels", "emails", "default"]) # Port One
    redprint("\n".join(os.listdir("Firefox_Port")))
    Firefox_Porter("Firefox_Port") # Port In
    """
class Firefox_Profile:
  def __init__(self, profile):
    [rm(Join("/", GLOBAL_FIREFOX_PROFILE_PATH, i)) for i in os.listdir(GLOBAL_FIREFOX_PROFILE_PATH) if i.split(".")[-1] == profile]
    os.system("/Applications/Firefox\ 46.app/Contents/MacOS/firefox-bin -CreateProfile %s" % (profile))
    R = [i for i in os.listdir(GLOBAL_FIREFOX_PROFILE_PATH) if i.split(".")[-1] == profile][0]
    # open(Join("/", GLOBAL_FIREFOX_PROFILE_PATH, R, "prefs.js"), "w").write('// Mozilla User Preferences\n\n// DO NOT EDIT THIS FILE.\n//\n// If you make changes to this file while the application is running,\n// the changes will be overwritten when the application exits.\n//\n// To change a preference value, you can either:\n// - modify it via the UI (e.g. via about:config in the browser); or\n// - set it within a user.js file in your profile.\n\nuser_pref("app.normandy.first_run", false);\nuser_pref("app.normandy.user_id", "06ce59be-456c-b540-9a47-0941c6043180");\nuser_pref("app.update.auto", false);\nuser_pref("app.update.enabled", false);\nuser_pref("app.update.lastUpdateTime.addon-background-update-timer", 0);\nuser_pref("app.update.lastUpdateTime.background-update-timer", 1550635354);\nuser_pref("app.update.lastUpdateTime.blocklist-background-update-timer", 0);\nuser_pref("app.update.lastUpdateTime.browser-cleanup-thumbnails", 1550633597);\nuser_pref("app.update.lastUpdateTime.recipe-client-addon-run", 0);\nuser_pref("app.update.lastUpdateTime.search-engine-update-timer", 1550635039);\nuser_pref("app.update.lastUpdateTime.services-settings-poll-changes", 1550635420);\nuser_pref("app.update.lastUpdateTime.telemetry_modules_ping", 0);\nuser_pref("app.update.lastUpdateTime.xpi-signature-verification", 0);\nuser_pref("browser.bookmarks.restore_default_bookmarks", false);\nuser_pref("browser.cache.disk.capacity", 1048576);\nuser_pref("browser.cache.disk.filesystem_reported", 1);\nuser_pref("browser.cache.disk.smart_size.first_run", false);\nuser_pref("browser.cache.disk.smart_size.use_old_max", false);\nuser_pref("browser.cache.frecency_experiment", 1);\nuser_pref("browser.contentblocking.category", "standard");\nuser_pref("browser.download.importedFromSqlite", true);\nuser_pref("browser.laterrun.bookkeeping.profileCreationTime", 1550633567);\nuser_pref("browser.laterrun.bookkeeping.sessionCount", 12);\nuser_pref("browser.laterrun.enabled", true);\nuser_pref("browser.migrated-sync-button", true);\nuser_pref("browser.migration.version", 77);\nuser_pref("browser.newtabpage.activity-stream.feeds.section.highlights", false);\nuser_pref("browser.newtabpage.activity-stream.feeds.section.topstories", false);\nuser_pref("browser.newtabpage.activity-stream.feeds.section.topstories.rec.impressions", "{"34054":1550633569243,"34079":1550633569243,"34084":1550633569243}");\nuser_pref("browser.newtabpage.activity-stream.feeds.section.topstories.spoc.impressions", "{"787":[1550634723461,1550634727923,1550634732355],"1099":[1550635011420]}");\nuser_pref("browser.newtabpage.activity-stream.feeds.snippets", false);\nuser_pref("browser.newtabpage.activity-stream.feeds.topsites", false);\nuser_pref("browser.newtabpage.activity-stream.impressionId", "{c85341b3-f663-9243-bac9-83b8e7427423}");\nuser_pref("browser.newtabpage.activity-stream.migrationLastShownDate", 1550552400);\nuser_pref("browser.newtabpage.activity-stream.migrationRemainingDays", 3);\nuser_pref("browser.newtabpage.activity-stream.prerender", false);\nuser_pref("browser.newtabpage.activity-stream.section.highlights.includeBookmarks", false);\nuser_pref("browser.newtabpage.activity-stream.section.highlights.includeDownloads", false);\nuser_pref("browser.newtabpage.activity-stream.section.highlights.includePocket", false);\nuser_pref("browser.newtabpage.activity-stream.section.highlights.includeVisited", false);\nuser_pref("browser.newtabpage.activity-stream.showSearch", false);\nuser_pref("browser.newtabpage.activity-stream.showSponsored", false);\nuser_pref("browser.newtabpage.enhanced", true);\nuser_pref("browser.newtabpage.storageVersion", 1);\nuser_pref("browser.pageActions.persistedActions", "{"version":1,"ids":["bookmark","bookmarkSeparator","copyURL","emailLink","addSearchEngine","sendToDevice","shareURL","pocket","screenshots_mozilla_org"],"idsInUrlbar":["pocket","bookmark"]}");\nuser_pref("browser.pagethumbnails.storage_version", 3);\nuser_pref("browser.places.smartBookmarksVersion", 7);\nuser_pref("browser.preferences.advanced.selectedTabIndex", 0);\nuser_pref("browser.rights.3.shown", true);\nuser_pref("browser.safebrowsing.provider.google4.lastupdatetime", "1550635400587");\nuser_pref("browser.safebrowsing.provider.google4.nextupdatetime", "1550637198587");\nuser_pref("browser.safebrowsing.provider.mozilla.lastupdatetime", "1550633571752");\nuser_pref("browser.safebrowsing.provider.mozilla.nextupdatetime", "1550637171752");\nuser_pref("browser.search.cohort", "nov17-2");\nuser_pref("browser.search.countryCode", "US");\nuser_pref("browser.search.region", "US");\nuser_pref("browser.sessionstore.upgradeBackup.latestBuildID", "20190211233335");\nuser_pref("browser.shell.checkDefaultBrowser", false);\nuser_pref("browser.shell.didSkipDefaultBrowserCheckOnFirstRun", true);\nuser_pref("browser.slowStartup.averageTime", 855);\nuser_pref("browser.slowStartup.samples", 1);\nuser_pref("browser.startup.homepage_override.buildID", "20190211233335");\nuser_pref("browser.startup.homepage_override.mstone", "65.0.1");\nuser_pref("browser.uiCustomization.state", "{"placements":{"widget-overflow-fixed-list":[],"nav-bar":["back-button","forward-button","stop-reload-button","home-button","customizableui-special-spring1","urlbar-container","customizableui-special-spring2","downloads-button","library-button","sidebar-button","loop-button"],"TabsToolbar":["tabbrowser-tabs","new-tab-button","alltabs-button"],"PersonalToolbar":["personal-bookmarks"]},"seen":["developer-button","loop-button","pocket-button","feed-button"],"dirtyAreaCache":["nav-bar","TabsToolbar","PersonalToolbar"],"currentVersion":15,"newElementCount":2}");\nuser_pref("browser.urlbar.placeholderName", "Google");\nuser_pref("browser.urlbar.timesBeforeHidingSuggestionsHint", 2);\nuser_pref("datareporting.healthreport.uploadEnabled", false);\nuser_pref("datareporting.policy.dataSubmissionPolicyAcceptedVersion", 2);\nuser_pref("datareporting.policy.dataSubmissionPolicyNotifiedTime", "1550633570624");\nuser_pref("datareporting.sessions.current.activeTicks", 7);\nuser_pref("datareporting.sessions.current.clean", true);\nuser_pref("datareporting.sessions.current.firstPaint", 664);\nuser_pref("datareporting.sessions.current.main", 73);\nuser_pref("datareporting.sessions.current.sessionRestored", 2511);\nuser_pref("datareporting.sessions.current.startTime", "1550633939369");\nuser_pref("datareporting.sessions.current.totalTime", 37);\nuser_pref("devtools.onboarding.telemetry.logged", true);\nuser_pref("distribution.iniFile.exists.appversion", "65.0.1");\nuser_pref("distribution.iniFile.exists.value", false);\nuser_pref("dom.apps.reset-permissions", true);\nuser_pref("dom.forms.autocomplete.formautofill", true);\nuser_pref("dom.mozApps.used", true);\nuser_pref("e10s.rollout.cohort", "unsupportedChannel");\nuser_pref("experiments.activeExperiment", false);\nuser_pref("extensions.blocklist.pingCountVersion", -1);\nuser_pref("extensions.bootstrappedAddons", "{"firefox@getpocket.com":{"version":"1.0","type":"extension","descriptor":"/Applications/Firefox.app/Contents/Resources/browser/features/firefox@getpocket.com.xpi","multiprocessCompatible":false,"runInSafeMode":true},"loop@mozilla.org":{"version":"1.2.6","type":"extension","descriptor":"/Applications/Firefox.app/Contents/Resources/browser/features/loop@mozilla.org.xpi","multiprocessCompatible":false,"runInSafeMode":true},"e10srollout@mozilla.org":{"version":"1.0","type":"extension","descriptor":"/Applications/Firefox.app/Contents/Resources/browser/features/e10srollout@mozilla.org.xpi","multiprocessCompatible":false,"runInSafeMode":true}}");\nuser_pref("extensions.databaseSchema", 28);\nuser_pref("extensions.e10sBlockedByAddons", false);\nuser_pref("extensions.enabledAddons", "%7B972ce4c6-7e08-4474-a285-3208198ce6fd%7D:46.0");\nuser_pref("extensions.getAddons.cache.lastUpdate", 1550633941);\nuser_pref("extensions.getAddons.databaseSchema", 5);\nuser_pref("extensions.lastAppBuildId", "20190211233335");\nuser_pref("extensions.lastAppVersion", "65.0.1");\nuser_pref("extensions.lastPlatformVersion", "65.0.1");\nuser_pref("extensions.pendingOperations", false);\nuser_pref("extensions.systemAddonSet", "{"schema":1,"addons":{}}");\nuser_pref("extensions.webcompat.perform_injections", true);\nuser_pref("extensions.webcompat.perform_ua_overrides", true);\nuser_pref("extensions.webextensions.uuids", "{"formautofill@mozilla.org":"2b4f0ede-b4d9-6545-9ac0-e1660f03296f","screenshots@mozilla.org":"a1a637bf-7c5f-f446-908f-d12e4f77d811","webcompat-reporter@mozilla.org":"9bf34646-9ad4-954f-9c4e-1063d8c70d25","webcompat@mozilla.org":"b79d04e0-3f7f-3b44-a76a-3cdbecb89a81"}");\nuser_pref("extensions.xpiState", "{"app-system-defaults":{"firefox@getpocket.com":{"d":"/Applications/Firefox.app/Contents/Resources/browser/features/firefox@getpocket.com.xpi","e":true,"v":"1.0","st":1540071218000},"loop@mozilla.org":{"d":"/Applications/Firefox.app/Contents/Resources/browser/features/loop@mozilla.org.xpi","e":true,"v":"1.2.6","st":1540071218000},"e10srollout@mozilla.org":{"d":"/Applications/Firefox.app/Contents/Resources/browser/features/e10srollout@mozilla.org.xpi","e":true,"v":"1.0","st":1540071218000}},"app-global":{"{972ce4c6-7e08-4474-a285-3208198ce6fd}":{"d":"/Applications/Firefox.app/Contents/Resources/browser/extensions/{972ce4c6-7e08-4474-a285-3208198ce6fd}.xpi","e":true,"v":"46.0","st":1540071218000}}}");\nuser_pref("font.internaluseonly.changed", true);\nuser_pref("gecko.buildID", "20160421124000");\nuser_pref("gecko.mstone", "46.0");\nuser_pref("lightweightThemes.persisted.headerURL", false);\nuser_pref("lightweightThemes.usedThemes", "[]");\nuser_pref("media.gmp.storage.version.observed", 1);\nuser_pref("network.cookie.prefsMigrated", true);\nuser_pref("network.predictor.cleaned-up", true);\nuser_pref("pdfjs.enabledCache.state", false);\nuser_pref("pdfjs.migrationVersion", 2);\nuser_pref("pdfjs.previousHandler.alwaysAskBeforeHandling", true);\nuser_pref("pdfjs.previousHandler.preferredAction", 4);\nuser_pref("places.history.expiration.transient_current_max_pages", 112348);\nuser_pref("plugin.disable_full_page_plugin_for_types", "application/pdf");\nuser_pref("privacy.cpd.offlineApps", true);\nuser_pref("privacy.cpd.siteSettings", true);\nuser_pref("privacy.sanitize.migrateClearSavedPwdsOnExit", true);\nuser_pref("privacy.sanitize.pending", "[{"id":"newtab-container","itemsToClear":[],"options":{}}]");\nuser_pref("privacy.sanitize.timeSpan", 0);\nuser_pref("security.sandbox.content.tempDirSuffix", "d0b0a17d-ddae-9c44-bb41-7cfca103ccd5");\nuser_pref("security.sandbox.plugin.tempDirSuffix", "9ad5aae9-5dc2-ac4f-9263-0195647a6ab7");\nuser_pref("services.blocklist.addons.checked", 1550635565);\nuser_pref("services.blocklist.onecrl.checked", 1550635565);\nuser_pref("services.blocklist.plugins.checked", 1550635565);\nuser_pref("services.settings.clock_skew_seconds", -145);\nuser_pref("services.settings.last_update_seconds", 1550635565);\nuser_pref("services.settings.main.language-dictionaries.last_check", 1550635565);\nuser_pref("services.settings.main.onboarding.last_check", 1550635565);\nuser_pref("services.settings.main.sites-classification.last_check", 1550635565);\nuser_pref("services.sync.clients.lastSync", "0");\nuser_pref("services.sync.clients.lastSyncLocal", "0");\nuser_pref("services.sync.declinedEngines", "");\nuser_pref("services.sync.engine.addresses.available", true);\nuser_pref("services.sync.globalScore", 0);\nuser_pref("services.sync.migrated", true);\nuser_pref("services.sync.nextSync", 0);\nuser_pref("services.sync.tabs.lastSync", "0");\nuser_pref("services.sync.tabs.lastSyncLocal", "0");\nuser_pref("signon.importedFromSqlite", true);\nuser_pref("toolkit.startup.last_success", 1550635390);\nuser_pref("toolkit.telemetry.cachedClientID", "c0ffeec0-ffee-c0ff-eec0-ffeec0ffeec0");\nuser_pref("toolkit.telemetry.previousBuildID", "20190211233335");\nuser_pref("toolkit.telemetry.reportingpolicy.firstRun", false);\n')
    open(Join("/", GLOBAL_FIREFOX_PROFILE_PATH, R, "prefs.js"), "w").write('// Mozilla User Preferences\n\n// DO NOT EDIT THIS FILE.\n//\n// If you make changes to this file while the application is running,\n// the changes will be overwritten when the application exits.\n//\n// To change a preference value, you can either:\n// - modify it via the UI (e.g. via about:config in the browser); or\n// - set it within a user.js file in your profile.\n\nuser_pref("app.normandy.first_run", false);\nuser_pref("app.normandy.user_id", "06ce59be-456c-b540-9a47-0941c6043180");\nuser_pref("app.update.auto", false);\nuser_pref("app.update.elevate.version", "66.0.3");\nuser_pref("app.update.enabled", false);\nuser_pref("app.update.lastUpdateTime.addon-background-update-timer", 1553728744);\nuser_pref("app.update.lastUpdateTime.background-update-timer", 1550635354);\nuser_pref("app.update.lastUpdateTime.blocklist-background-update-timer", 1553728915);\nuser_pref("app.update.lastUpdateTime.browser-cleanup-thumbnails", 1550633597);\nuser_pref("app.update.lastUpdateTime.recipe-client-addon-run", 0);\nuser_pref("app.update.lastUpdateTime.search-engine-update-timer", 1550635039);\nuser_pref("app.update.lastUpdateTime.services-settings-poll-changes", 1550635420);\nuser_pref("app.update.lastUpdateTime.telemetry_modules_ping", 0);\nuser_pref("app.update.lastUpdateTime.xpi-signature-verification", 1553729321);\nuser_pref("app.update.silent", true);\nuser_pref("app.update.url", "xxxhttps://xxxaus5.mozilla.org/update/6/%PRODUCT%/%VERSION%/%BUILD_ID%/%BUILD_TARGET%/%LOCALE%/%CHANNEL%/%OS_VERSION%/%SYSTEM_CAPABILITIES%/%DISTRIBUTION%/%DISTRIBUTION_VERSION%/update.xml");\nuser_pref("browser.bookmarks.restore_default_bookmarks", false);\nuser_pref("browser.cache.disk.capacity", 1048576);\nuser_pref("browser.cache.disk.filesystem_reported", 1);\nuser_pref("browser.cache.disk.smart_size.first_run", false);\nuser_pref("browser.cache.disk.smart_size.use_old_max", false);\nuser_pref("browser.cache.frecency_experiment", 1);\nuser_pref("browser.contentblocking.category", "standard");\nuser_pref("browser.ctrlTab.recentlyUsedOrder", false);\nuser_pref("browser.download.importedFromSqlite", true);\nuser_pref("browser.laterrun.bookkeeping.profileCreationTime", 1550633567);\nuser_pref("browser.laterrun.bookkeeping.sessionCount", 13);\nuser_pref("browser.migrated-sync-button", true);\nuser_pref("browser.migration.version", 77);\nuser_pref("browser.newtabpage.activity-stream.asrouter.userprefs.cfr", false);\nuser_pref("browser.newtabpage.activity-stream.feeds.section.highlights", false);\nuser_pref("browser.newtabpage.activity-stream.feeds.section.topstories", false);\nuser_pref("browser.newtabpage.activity-stream.feeds.snippets", false);\nuser_pref("browser.newtabpage.activity-stream.feeds.topsites", false);\nuser_pref("browser.newtabpage.activity-stream.impressionId", "{c85341b3-f663-9243-bac9-83b8e7427423}");\nuser_pref("browser.newtabpage.activity-stream.migrationExpired", true);\nuser_pref("browser.newtabpage.activity-stream.migrationLastShownDate", 1553659200);\nuser_pref("browser.newtabpage.activity-stream.migrationRemainingDays", 2);\nuser_pref("browser.newtabpage.activity-stream.prerender", false);\nuser_pref("browser.newtabpage.activity-stream.section.highlights.includeBookmarks", false);\nuser_pref("browser.newtabpage.activity-stream.section.highlights.includeDownloads", false);\nuser_pref("browser.newtabpage.activity-stream.section.highlights.includePocket", false);\nuser_pref("browser.newtabpage.activity-stream.section.highlights.includeVisited", false);\nuser_pref("browser.newtabpage.activity-stream.showSearch", false);\nuser_pref("browser.newtabpage.activity-stream.showSponsored", false);\nuser_pref("browser.newtabpage.enabled", false);\nuser_pref("browser.newtabpage.enhanced", true);\nuser_pref("browser.newtabpage.storageVersion", 1);\nuser_pref("browser.pageActions.persistedActions", "{"version":1,"ids":["bookmark","bookmarkSeparator","copyURL","emailLink","addSearchEngine","sendToDevice","shareURL","pocket"],"idsInUrlbar":["pocket","bookmark"]}");\nuser_pref("browser.pagethumbnails.storage_version", 3);\nuser_pref("browser.places.smartBookmarksVersion", 7);\nuser_pref("browser.preferences.advanced.selectedTabIndex", 0);\nuser_pref("browser.preferences.defaultPerformanceSettings.enabled", false);\nuser_pref("browser.rights.3.shown", true);\nuser_pref("browser.safebrowsing.provider.google4.lastupdatetime", "1557288602301");\nuser_pref("browser.safebrowsing.provider.google4.nextupdatetime", "1557290413301");\nuser_pref("browser.safebrowsing.provider.mozilla.lastupdatetime", "1557288602720");\nuser_pref("browser.safebrowsing.provider.mozilla.nextupdatetime", "1557292202720");\nuser_pref("browser.search.cohort", "nov17-2");\nuser_pref("browser.search.countryCode", "US");\nuser_pref("browser.search.hiddenOneOffs", "Google,Bing,Amazon.com,DuckDuckGo,eBay,Twitter,Wikipedia (en)");\nuser_pref("browser.search.region", "US");\nuser_pref("browser.search.suggest.enabled", false);\nuser_pref("browser.sessionstore.upgradeBackup.latestBuildID", "20190211233335");\nuser_pref("browser.shell.checkDefaultBrowser", false);\nuser_pref("browser.shell.didSkipDefaultBrowserCheckOnFirstRun", true);\nuser_pref("browser.slowStartup.averageTime", 975);\nuser_pref("browser.slowStartup.samples", 1);\nuser_pref("browser.startup.homepage", "about:blank");\nuser_pref("browser.startup.homepage_override.buildID", "20190124174741");\nuser_pref("browser.startup.homepage_override.mstone", "65.0");\nuser_pref("browser.uiCustomization.state", "{"placements":{"widget-overflow-fixed-list":[],"nav-bar":["back-button","forward-button","stop-reload-button","home-button","customizableui-special-spring1","urlbar-container","customizableui-special-spring2","downloads-button","library-button","sidebar-button"],"TabsToolbar":["tabbrowser-tabs","new-tab-button","alltabs-button"],"PersonalToolbar":["personal-bookmarks"]},"seen":["developer-button"],"dirtyAreaCache":["nav-bar"],"currentVersion":15,"newElementCount":2}");\nuser_pref("browser.urlbar.placeholderName", "Google");\nuser_pref("browser.urlbar.searchSuggestionsChoice", false);\nuser_pref("browser.urlbar.suggest.bookmark", false);\nuser_pref("browser.urlbar.suggest.openpage", false);\nuser_pref("browser.urlbar.suggest.searches", false);\nuser_pref("browser.urlbar.timesBeforeHidingSuggestionsHint", 1);\nuser_pref("datareporting.healthreport.uploadEnabled", false);\nuser_pref("datareporting.policy.dataSubmissionPolicyAcceptedVersion", 2);\nuser_pref("datareporting.policy.dataSubmissionPolicyNotifiedTime", "1550633570624");\nuser_pref("datareporting.sessions.current.activeTicks", 7);\nuser_pref("datareporting.sessions.current.clean", true);\nuser_pref("datareporting.sessions.current.firstPaint", 664);\nuser_pref("datareporting.sessions.current.main", 73);\nuser_pref("datareporting.sessions.current.sessionRestored", 2511);\nuser_pref("datareporting.sessions.current.startTime", "1550633939369");\nuser_pref("datareporting.sessions.current.totalTime", 37);\nuser_pref("devtools.onboarding.telemetry.logged", true);\nuser_pref("distribution.iniFile.exists.appversion", "65.0");\nuser_pref("distribution.iniFile.exists.value", false);\nuser_pref("dom.apps.reset-permissions", true);\nuser_pref("dom.forms.autocomplete.formautofill", true);\nuser_pref("dom.mozApps.used", true);\nuser_pref("e10s.rollout.cohort", "unsupportedChannel");\nuser_pref("experiments.activeExperiment", false);\nuser_pref("extensions.blocklist.lastModified", "Tue, 26 Mar 2019 17:13:55 GMT");\nuser_pref("extensions.blocklist.pingCountVersion", -1);\nuser_pref("extensions.databaseSchema", 28);\nuser_pref("extensions.e10sBlockedByAddons", false);\nuser_pref("extensions.enabledAddons", "%7B972ce4c6-7e08-4474-a285-3208198ce6fd%7D:46.0");\nuser_pref("extensions.getAddons.cache.lastUpdate", 1553728744);\nuser_pref("extensions.getAddons.databaseSchema", 5);\nuser_pref("extensions.lastAppBuildId", "20190124174741");\nuser_pref("extensions.lastAppVersion", "65.0");\nuser_pref("extensions.lastPlatformVersion", "65.0");\nuser_pref("extensions.pendingOperations", false);\nuser_pref("extensions.webcompat.perform_injections", true);\nuser_pref("extensions.webcompat.perform_ua_overrides", true);\nuser_pref("extensions.webextensions.uuids", "{"formautofill@mozilla.org":"fd82627d-7029-df44-854c-65997238f507","screenshots@mozilla.org":"1b26d190-485a-3a41-991d-cbdbedab016b","webcompat-reporter@mozilla.org":"cdb30fdf-9916-544d-9ae5-be2506ea93c1","webcompat@mozilla.org":"f3f59ad4-5a24-054e-9a2d-8807fc628a8e"}");\nuser_pref("font.internaluseonly.changed", false);\nuser_pref("gecko.buildID", "20160421124000");\nuser_pref("gecko.mstone", "46.0");\nuser_pref("layers.acceleration.disabled", true);\nuser_pref("lightweightThemes.persisted.headerURL", false);\nuser_pref("lightweightThemes.usedThemes", "[]");\nuser_pref("media.gmp.storage.version.observed", 1);\nuser_pref("network.cookie.prefsMigrated", true);\nuser_pref("network.predictor.cleaned-up", true);\nuser_pref("pdfjs.enabledCache.state", false);\nuser_pref("pdfjs.migrationVersion", 2);\nuser_pref("pdfjs.previousHandler.alwaysAskBeforeHandling", true);\nuser_pref("pdfjs.previousHandler.preferredAction", 4);\nuser_pref("places.history.expiration.transient_current_max_pages", 112348);\nuser_pref("plugin.disable_full_page_plugin_for_types", "application/pdf");\nuser_pref("privacy.cpd.offlineApps", true);\nuser_pref("privacy.cpd.siteSettings", true);\nuser_pref("privacy.sanitize.migrateClearSavedPwdsOnExit", true);\nuser_pref("privacy.sanitize.pending", "[]");\nuser_pref("privacy.sanitize.timeSpan", 0);\nuser_pref("security.sandbox.content.tempDirSuffix", "d0b0a17d-ddae-9c44-bb41-7cfca103ccd5");\nuser_pref("security.sandbox.plugin.tempDirSuffix", "9ad5aae9-5dc2-ac4f-9263-0195647a6ab7");\nuser_pref("services.blocklist.addons.checked", 1550635565);\nuser_pref("services.blocklist.onecrl.checked", 1550635565);\nuser_pref("services.blocklist.plugins.checked", 1550635565);\nuser_pref("services.settings.clock_skew_seconds", -145);\nuser_pref("services.settings.last_update_seconds", 1550635565);\nuser_pref("services.settings.main.language-dictionaries.last_check", 1550635565);\nuser_pref("services.settings.main.onboarding.last_check", 1550635565);\nuser_pref("services.settings.main.sites-classification.last_check", 1550635565);\nuser_pref("services.sync.clients.lastSync", "0");\nuser_pref("services.sync.clients.lastSyncLocal", "0");\nuser_pref("services.sync.declinedEngines", "");\nuser_pref("services.sync.engine.addresses.available", true);\nuser_pref("services.sync.globalScore", 0);\nuser_pref("services.sync.migrated", true);\nuser_pref("services.sync.nextSync", 0);\nuser_pref("services.sync.tabs.lastSync", "0");\nuser_pref("services.sync.tabs.lastSyncLocal", "0");\nuser_pref("signon.importedFromSqlite", true);\nuser_pref("signon.rememberSignons", false);\nuser_pref("toolkit.startup.last_success", 1557288598);\nuser_pref("toolkit.telemetry.cachedClientID", "c0ffeec0-ffee-c0ff-eec0-ffeec0ffeec0");\nuser_pref("toolkit.telemetry.previousBuildID", "20190124174741");\nuser_pref("toolkit.telemetry.reportingpolicy.firstRun", false);\n')
    Binarydata().export("places.sqlite", Join("/", GLOBAL_FIREFOX_PROFILE_PATH, R, "places.sqlite"))
class GitHub:
  def get(self,url):
    print("git clone %s" % url)
    os.system("git clone %s" % url)
  def pull(self,url):
    os.system("git pull %s" % (url))
  def push(self,username,repository):
    os.system("git remote set-url origin 'https://%s@github.com/%s/%s.git'; git add *; git commit -m \"initial commit\"; git push origin master"%(username,username,repository))
class Google_Drive:
  def __init__(self, Email_Address):
    #https://developers.google.com/drive/api/v3/quickstart/python
    # FIRST, EXPORT THE CREDS NO.1.
    # YEAH, THEN IT JAX THAT TO NOW GET TOKEN.PICKLE!!!!
    import os
    ADDY = "." + "|".join([Email_Address, "Client_Secret", "GSuite"]) + ".json"
    Binarydata().export(ADDY)
    GDRIVE_PICKLE_ADDRESS = "." + "|".join([Email_Address, "Client_Secret_3", "GSuite"]) + ".pickle"
    if GDRIVE_PICKLE_ADDRESS not in os.listdir():
      if GDRIVE_PICKLE_ADDRESS in key("filename", All(Binarydata)):
        Binarydata().export(GDRIVE_PICKLE_ADDRESS)
      else:
        1

    import pickle
    import os.path
    from googleapiclient.discovery import build
    from google_auth_oauthlib.flow import InstalledAppFlow
    from google.auth.transport.requests import Request

    # If modifying these scopes, delete the file GDRIVE_PICKLE_ADDRESS.
    SCOPES = ['https://www.googleapis.com/auth/drive']

    """Shows basic usage of the Drive v3 API.
    Prints the names and ids of the first 10 files the user has access to.
    """
    creds = None
    # The file GDRIVE_PICKLE_ADDRESS stores the user's access and refresh tokens, and is
    # created automatically when the authorization flow completes for the first
    # time.
    if os.path.exists(GDRIVE_PICKLE_ADDRESS):
      with open(GDRIVE_PICKLE_ADDRESS, 'rb') as token:
        creds = pickle.load(token)
    # If there are no (valid) credentials available, let the user log in.
    if not creds or not creds.valid:
      if creds and creds.expired and creds.refresh_token:
        creds.refresh(Request())
      else:
        OSA().display_dialog("A browser will open and you will be asked to log in and accept permissions to use the Google Drive API. Click OK to continue.",text_prompt=False)
        flow = InstalledAppFlow.from_client_secrets_file(
          ADDY, SCOPES)
        creds = flow.run_local_server()
      # Save the credentials for the next run
      with open(GDRIVE_PICKLE_ADDRESS, 'wb') as token:
        pickle.dump(creds, token)

    service = build('drive', 'v3', credentials=creds)
    self.service = service
    # Call the Drive v3 API
    results = service.files().list(
      pageSize=10, fields="nextPageToken, files(id, name)").execute()
    items = results.get('files', [])

    if not items:
      print('No files found.')
    else:
      print('Files:')
      for item in items:
        print(u'{0} ({1})'.format(item['name'], item['id']))

    Binarydata().update_or_create(GDRIVE_PICKLE_ADDRESS)
    Binarydata().export(GDRIVE_PICKLE_ADDRESS)
  def create(self, address, public = True):
    service = self.service
    ext_dict = {".doc": "application/msword",".dot": "application/msword",".docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",".dotx": "application/vnd.openxmlformats-officedocument.wordprocessingml.template",".docm": "application/vnd.ms-word.document.macroEnabled.12",".dotm": "application/vnd.ms-word.template.macroEnabled.12",".xls": "application/vnd.ms-excel",".xlt": "application/vnd.ms-excel",".xla": "application/vnd.ms-excel",".xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",".xltx": "application/vnd.openxmlformats-officedocument.spreadsheetml.template",".xlsm": "application/vnd.ms-excel.sheet.macroEnabled.12",".xltm": "application/vnd.ms-excel.template.macroEnabled.12",".xlam": "application/vnd.ms-excel.addin.macroEnabled.12",".xlsb": "application/vnd.ms-excel.sheet.binary.macroEnabled.12",".ppt": "application/vnd.ms-powerpoint",".pot": "application/vnd.ms-powerpoint",".pps": "application/vnd.ms-powerpoint",".ppa": "application/vnd.ms-powerpoint",".pptx": "application/vnd.openxmlformats-officedocument.presentationml.presentation",".potx": "application/vnd.openxmlformats-officedocument.presentationml.template",".ppsx": "application/vnd.openxmlformats-officedocument.presentationml.slideshow",".ppam": "application/vnd.ms-powerpoint.addin.macroEnabled.12",".pptm": "application/vnd.ms-powerpoint.presentation.macroEnabled.12",".potm": "application/vnd.ms-powerpoint.template.macroEnabled.12",".ppsm": "application/vnd.ms-powerpoint.slideshow.macroEnabled.12",".mdb": "application/vnd.ms-access"}
    ext = "." + address.split(".")[-1]
    if ext not in ext_dict:
      OSA.display_dialog("extension %s not in ext_dict.\n Please add it." % (ext), text_prompt = False)
    import googleapiclient
    media = googleapiclient.http.MediaFileUpload(address,
                            mimetype=ext_dict[ext],
                            resumable=False)
    file_metadata = {
        'name': address.replace("_", " "),
        'mimeType': ext_dict[ext],
    }
    file = service.files().create(body=file_metadata,
                                        media_body=media,
                                        fields='id').execute()
    print('File ID: %s' % file.get('id'))
    ID = file.get("id")
    if public == True:
      service.permissions().create(body={"role":"reader", "type":"anyone"}, fileId=ID).execute()
    URL = "https://drive.google.com/file/d/{}/view".format(ID)
    return URL
  @staticmethod
  def tests():
    Email_Address = a_shop().Business_Email_Address
    ADDY = "." + "|".join([Email_Address, "Client_Secret", "GSuite"]) + ".json"
    assert ADDY in key("filename", All(Binarydata))
    R = Google_Drive(Email_Address = Email_Address)
    Test_Address = "Test.docx"
    text_to_docx("Test", Test_Address)
    R.create(address = Test_Address, public = True)
    rm("Test.docx")
class Google_Places_Search:
  def google_places_search(x="40.7532616",y="-73.9839516",radius=3500,name="restaurant"):
    # from https://stackoverflow.com/questions/50573658/python-google-places-api
    # This covers from Houston Street to 79th St at these coordinates with radius 3500 meters
    import requests
    import json

    APIKEY = "AIzaSyBFx8hqftDOlrSWRTiOSowjwfeS1OQtBpw"

    def findPlaces(loc,radius, pagetoken = None):
      lat, lng = loc
      type = "restaurant"
      #url = "https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={lat},{lng}&radius={radius}&type={type}&key={APIKEY}{pagetoken}".format(lat = lat, lng = lng, radius = radius, type = type,APIKEY = APIKEY, pagetoken = "&pagetoken="+pagetoken if pagetoken else "")
      url = "https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={lat},{lng}&radius={radius}&name={name}&key={APIKEY}{pagetoken}".format(lat = lat, lng = lng, radius = radius, name = name,APIKEY = APIKEY, pagetoken = "&pagetoken="+pagetoken if pagetoken else "")
      print(url)
      response = requests.get(url)
      res = json.loads(response.text)
      # print(res)
      print("here results ---->>> ", len(res["results"]))

      for result in res["results"]:
        info = ";".join(map(str,[result["name"],result["geometry"]["location"]["lat"],result["geometry"]["location"]["lng"],result.get("rating",0),result["place_id"]]))
        print(info)
      pagetoken = res.get("next_page_token",None)

      print("here -->> ", pagetoken)

      return pagetoken, res["results"]

    # pagetoken = "CpQFhwIAADQWOcVI1wll-B869Z24El48rXw18gKoab_keD65V18zFEvPjKIfrS79Pc_vXJcZQtOuF0RObQG20ph-GE3ssP3k1fu8zsYbw5g3UPbSjAvQLdXkdD1qAWztXj7hc5Kxc4pYRyGM1_ljVOHg3Py_zSlYscnoNjCvRua2MDQgusCsEquNqGREFdvhjDkbeMhEFYxHucTnIn96OxIJEpamePTHsBooYyPBaa_ejGZ_C99QeDjpSkSKBgEe3aL1uWKlYhsGKh7biQUR5rKsKPodwccLIrW8Gr5tag3NH0sLPExHHvqzlpkj--KIuydTVjPH7u2zHxmPByServ2S5xjXYUBRr-ly3e1xPsVMhZZH9TxfttCIHLscBvpvCswIfaGYdl3bEzsrFISfpp0rpKtlp9gWGY7Tbk2n6s3etCHQEHn2qmM8bsJwkZV81pUWN0j9C9RX-ywOyIKY2yp1w_Iq1mRwOwY4mckbicOoooHiV6JER4xe7Kizw9hbXOnezn_NMk15TLwRoXlfL1s73uwogo-VWE8c-V1HqRpWQSyudRhLwhOEclrICXIdxICOgTgYO1z57xCEerw3QUL_7MPDrlbbh_AlX8I6Jfe8IhQ1Fkqu_njatm6aBTjkp2CSqlvZJpI_Lrv330VcyFEqBkGn7NJew3I9xofSrBaXFa8ABi6DXQm6-yC32OEyf7GHNXINjT1IB0yh6KR6c0qzaqiqOzKcuuai9XqEMQNNKyi6EuhzH5TP9YA56N3JhnXRFhs2aWHZhLlieVI6_uqzpZSgYjUem8aQrMTlmHw0kIYU8I-Ca041C4Zm2gMezwygRrhzsOoAmbmu96nft0KuIWTB3A_xGVKYQ2qjb2KRM7nsglnSEhDoNs8EhvuIm0FQs30YSCp5GhRO3b3Tn5rsLuwiWgu8hwEGhL0S1A"
    pagetoken = None

    results = []
    while True:
      pagetoken, results_ = findPlaces(loc=(x,y),radius=radius,pagetoken=pagetoken)
      results.extend(results_)
      import time
      # time.sleep(5)
      time.sleep(10)
      if not pagetoken:
        break
    return results
    """
    assert len(google_places_search(name="trader joes")) == 6
    assert len(google_places_search(name="park")) == 0
    assert len(google_places_search(name="central park")) == 3
    """
  def getinfo(placeid):
    APIKEY="AIzaSyBFx8hqftDOlrSWRTiOSowjwfeS1OQtBpw"
    fields=["formatted_address","formatted_phone_number","opening_hours","name","rating","website"]
    #url= "https://maps.googleapis.com/maps/api/place/details/json?key={}&placeid={}&fields={}".format(
    #      APIKEY,placeid,",".join(fields))
    url= "https://maps.googleapis.com/maps/api/place/details/json?placeid={}&key={}&fields={}".format(
          placeid,APIKEY,",".join(fields))
    r = requests.get(url)
    #return url
    data = json.loads(r.text)
    return data
class Images(object):
  def flexor_and_tenor(self, address, size, logo_scaling_dimension_size):
    import cv2, numpy as np

    pic = cv2.imread(address)
    t1, t2 = pic.shape[0]*(size[0]/logo_scaling_dimension_size[0]), pic.shape[1]*(size[1]/logo_scaling_dimension_size[1])
    t1, t2 = int(t1,), int(t2,)
    pic[0:t1,0:t2,0:,] = np.array([255,255,255])
    cv2.imwrite(address, pic)
    return address
    for i in os.listdir(homepath("~/Desktop")):
      os.system("mv '/Users/$USER/Desktop/%s' '/Users/$USER/tavern/tavern/soda/dls/'"%(i))
  def image_binary(self,address):
    import cv2
    img_grey = cv2.imread(r, cv2.IMREAD_GRAYSCALE)
    img_binary = cv2.threshold(img_grey, 128, 255, cv2.THRESH_BINARY)[1]
    return img_binary
  def image_base64(self, address):
    import base64
    return base64.b64encode(open(address,"rb").read())
  def vstack(self, images= ["hot.png"]*3, destination_address=None):
    imgs       =  pool(Image.open,images).result()
    widths = set(lmap(lambda i: Image.open(i).size[0],images))
    print(widths)
    
    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]

    x = list((np.asarray( i ) for i in imgs ))
    
    imgs_comb  = np.vstack( (np.asarray( i ) for i in x ) )
    import scipy.misc
    print(imgs_comb.shape)
    scipy.misc.imsave(input("destination address?: ") if destination_address == None else destination_address,imgs_comb)
    cv2.imwrite(destination_address,imgs_comb)
    return destination_address
    return imgs_comb
  def slow_vstack(self, images, destination_address=None):
    imgs =  pool(Image.open,images).result()
    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]
    arrays = pool(np.asarray,imgs).result()
    jaxpel = arrays[0]
    for idx,i in enum(arrays[:-1]):
      try:
        jaxpel = np.vstack([jaxpel, arrays[idx+1]])
        redprint(idx, jaxpel.shape)
      except Exception as e:
        redprint("some error.")
    imgs_comb  = Image.fromarray( jaxpel)
    imgs_comb.save(input("destination address?: ") if destination_address == None else destination_address )
    return destination_address
  def hstack(self, images):
    import numpy as np
    """
    imgs = []
    import numpy as np
    imgs.append(np.full((1000,100,3),255,dtype=np.uint8))
    imgs.append(np.full((1000,100,3),255,dtype=np.uint8))
    imgs.append(np.full((800,100,3),255,dtype=np.uint8))
    import cv2
    addresses = [get_random_address(homepath("~/tavern/tavern/soda/dls")).png() for i in range(3)]
    for address,i in zip(addresses,imgs):
      cv2.imwrite(address,i)
    images = addresses
    """
    imgs       =  pool(Image.open,images).result()
    
    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1][1]
    min_shape_2 = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1][0]
    max_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs],reverse=True)[0][1][1]
    for idx,i in enum(imgs):
      if i.size[1] != max_shape:
        x = cv2.imread(images[idx])
        import numpy as np
        new = np.full((max_shape,min_shape_2,3),0,dtype=np.uint8)
        new[0:i.size[1],0:min_shape_2,] = x
        cv2.imwrite(images[idx],new)
    imgs       =  pool(Image.open,images).result()

    imgs_comb  = np.hstack( (np.asarray( i ) for i in imgs ) )
    import scipy.misc
    print(imgs_comb.shape)
    destination_address = get_random_address(homepath("~/tavern/tavern/soda/dls")).png()
    scipy.misc.imsave(destination_address,imgs_comb)
    return destination_address
  def __init__(self):
    import urllib.request
    from PIL import Image
    from PIL import ImageEnhance, ImageFilter
    import cv2
    import numpy as np
    from moviepy.editor import VideoFileClip
    globals().update(locals())
  def download(self, url="http://www.gunnerkrigg.com//comics/00000001.jpg", save_path=None):
    if not save_path:
      save_folder    = os.path.expanduser("~/tavern/tavern/soda/dls")
      os.makedirs(save_folder, exist_ok=True)
      save_path = get_random_address(save_folder).jpg()
      print('Saving to.. %s'%save_path)
    try:
      import urllib
      urllib.request.urlretrieve(url, save_path)
      #open(save_path,"wb").write(requests.get(url).raw)
    except Exception as e:
      redprint("%s, url: %s"%(e, url))
      time.sleep(5)
      return Images().download(url,save_path)
    return save_path
  def resize_disregard_proportion(self, width, height, infile, outfile):
    from PIL import Image
    x = Image.open(infile)
    x = x.resize((width, height), Image.ANTIALIAS)
    x.save(outfile)
    return outfile
  @staticmethod
  @timeit
  def images_to_video(images, width, height, framerate, outfile):
    """[Annotation] if you edit this, it doesn't look like it makes sense, but that's usual for this stuff. [assume it works]"""
    from PIL import Image
    import cv2
    import os
    """[Hard-Add B] emitting"""
    print("initiating Images().images_to_video")
    print("[Emit] Verifying image_paths are Images --")
    """[Annotation] [Hard-Add A] (part of a compilation of hard-adds)"""
    images = sudby(lambda i: tp(lambda:Image.open(i)), images)
    """[Annotation] here, i had to change the names to .png and do some complicated thing with blips in it """
    olds, news = ["%s.png"%(".".join(i.split(".")[:-1])) for i in images], images
    [Image.open(old).save(new) for old,new in zip(olds,news) if old.endswith(".png") == False and old != new] #chx4if!=png\|undeeded
    images = ["%s.png"%(".".join(i.split(".")[:-1])) for i in images]
    """[Hard-Add B] emitting"""
    print("[Emit] Changed all image_paths to PNG format")
    print("[Emit] Resizing all images now -- ")
    """[Annotation] here, resize """    
    for IMAGE_FILENAME_TO_SIZE in images:
      print(IMAGE_FILENAME_TO_SIZE)
      x = Image.open(IMAGE_FILENAME_TO_SIZE)
      x = x.resize((width, height), Image.ANTIALIAS)
      x.save(IMAGE_FILENAME_TO_SIZE)
    """[Hard-Add B] emitting"""
    print("[Emit] Adding images to outfile %s -- "%outfile)
    """[Annotation] here, took this code from stackoverflow; basically it makes an `out` and adds images to it."""
    out = cv2.VideoWriter(outfile, cv2.VideoWriter_fourcc(*"mp4v"), framerate, (width, height))
    def add_images_to_out(out, images):
      for image in images:
        frame = cv2.imread(image)
        out.write(frame) # Write out frame to video
        cv2.imshow("video",frame)
        if (cv2.waitKey(1) & 0xFF) == ord("q"): # Hit `q` to exit
          break
      return out
    add_images_to_out(out, images).release()
    """[Hard-Add B] emitting"""
    print("[Emit] Video file successfully created. cv2 cleaning up --")
    """[Annotation] [No-annotation]"""
    cv2.destroyAllWindows()
    """[Annotation] [No-annotation]"""
    print("The output video is {}".format(outfile))
    """[Hard-Add B] emitting"""
    print("[Emit] End of images_to_video --*")
    return outfile
    """ [A Test] \"\"\"
    import os
    test_photos_path = os.path.expanduser("~/Documents/photos/test")
    if not os.path.exists(test_photos_path):
      print("you must create a photo directory with images at ~/Documents/photos/test")
      print("ending test..")
    os.chdir(test_photos_path)
    images_to_video(os.listdir(), 1920, 1080, 60, "out.mp4")  
    """
  def images_to_video2(self, images, frames_per_image = 60):
    framerate = 30
    # images = ["image1.jpg"]
    out_location = get_random_address(homepath("~/tavern/tavern/soda/dls")).mp4()
    images = sudby(lambda i: tp(lambda:Image.open(i)), images)
    width, height, layers = cv2.imread(images[0]).shape
    out = cv2.VideoWriter(out_location, cv2.VideoWriter_fourcc(*"mp4v"), framerate, (width, height))
    images = lmap(lambda i: cv2.imread(i), images)
    for i in images:
      for j in range(frames_per_image):
        out.write(i)
    out.release()
    r = VideoFileClip(out_location)
    print(r.duration)
    os.system("open %s"%(out_location))
    return out_location
  @staticmethod
  def image_show(images):
    # final = concatenate([VideoFileClip(clips[0]),
    #                      VideoFileClip(clips[1]).crossfadein(0.5),
    #                      VideoFileClip(clips[2]).crossfadein(0.5),
    #                      ],
    #              padding=-1, method="compose")
    frames_per_image = int(OSA.log("frames per image?"))
    crossfadein = 0.5
    extra_frames = int(30 * crossfadein)
    frames_per_image = frames_per_image + 30 + extra_frames
    # clips = [Images().images_to_video2([images[0]], frames_per_image - 30)] + lmap(lambda i: Images().images_to_video2([i], frames_per_image), images[1:])
    clips = [Images().images_to_video2([images[0]], frames_per_image - extra_frames)] + lmap(lambda i: Images().images_to_video2([i], frames_per_image), images[1:])
    # clips = lmap(lambda i: Images().images_to_video2([i], frames_per_image), images)
    from moviepy.editor import VideoFileClip
    from moviepy.editor import concatenate
    # 'final = VideoFileClip(clips[0])\nfor i in clips[1:]:\n  final = concatenate([final,\n                        VideoFileClip(i).crossfadein(0.5)],\n             padding=-1, method="compose")'
    final = concatenate([VideoFileClip(clips[0]),
                        *lmap(lambda i: VideoFileClip(i).crossfadein(crossfadein), clips[1:])],
                 padding=-1, method="compose")
    out_location = get_random_address(homepath("~/tavern/tavern/soda/dls")).mp4()
    final.write_videofile(out_location)
    os.system("open '{}'".format(out_location))
    return out_location
  def resize(self, fn, size=1200):
    if not size:
      return fn
    im = Image.open(fn)
    import numpy as np
    image_size = np.array(im.size)
    # ratio = max(image_size)/size
    ratio = image_size[0]/size
    new_size = image_size / ratio 
    new_size = [int(round(i)) for i in new_size]
    im = im.resize(new_size)
    im.save(fn)
    return fn
  def resize_via_width(self, address, desired_width=1200):
    # Always Resize The Bitch.
    im = Image.open(address)
    aspect_ratio = im.size[1]/im.size[0]
    im = im.resize((desired_width,Integer(desired_width*aspect_ratio) ))
    im.save(address)
    return address
  def resize_over_background(self, address, size):
    img = cv2.imread(address)
    size_ = size
    size = list(tcer(img.shape[:2]))
    larger_side = max(size)
    x = np.full((larger_side,larger_side,3),77,dtype=np.uint8)
    to_subtract = 0
    if size[0] > size[1]:
      diff = int(larger_side - size[1])
      if diff % 2 == 1: 
        to_subtract = 1
      diff = int(diff / 2)
      diff1 = diff
      x[diff:int(larger_side-diff)-to_subtract,0:larger_side] = img
    elif size[1] > size[0]:
      diff = int(larger_side - size[0])
      if diff % 2 == 1: 
        to_subtract = 1
      diff = int(diff / 2)
      diff1 = diff
      x[0:larger_side,diff:int(larger_side-diff1)-to_subtract] = img
    else:
      x[0:larger_side,0:larger_side] = img
    cv2.imwrite(address,x)
    address = Images().resize(address,size_)
    return address
  def get_image_size(self, address):
    return Image.open(address).size
  def image_size(x):
    import PIL
    if type(x) == PIL.JpegImagePlugin.JpegImageFile:
      return x.size
    else:
      return tuple(tcer(x.shape[:2]))
  def download_and_resize(self, url, size=1200, save_path = None):
    save_path = self.download(url, save_path=save_path)
    im = Image.open(save_path).convert("RGB")
    import numpy as np
    image_size = np.array(im.size)
    ratio = max(image_size)/size
    new_size =  image_size / ratio 
    new_size = [int(i) for i in new_size]
    im = im.resize(new_size)
    im.save(save_path)
    return save_path
  def black_and_white(self, address):
    from PIL import Image
    image_file = Image.open(address) # open colour image
    image_file = image_file.convert("L") # convert image to black and white
    image_file.save(address)
    return address
  def fb_image_upload(self, x, init_shop=None, hash=False):
    if init_shop == None:
      init_shop = All(Shop)[0].shop_abbreviation
    if not os.path.exists(x):
      x = Images().download(x)
    shop = Shop()( All(Shop)[0].shop_abbreviation)
    image = AdImage(parent_id='act_%s'%shop.Facebook_Business_Ad_Account_ID)
    image[AdImage.Field.filename] = x
    image.remote_create()
    time.sleep(1.2)
    return image['url'] if hash == False else image['hash']
  def bitly_url(self,url):
    return json.loads(requests.get("https://api-ssl.bitly.com/v3/shorten?access_token={}&longUrl={}".format(Muta()().bitly_access_token, url)).text)["data"]["url"]
    """
    bitly_url("https://google.com")
    """
  def sharpen(self,x):
    img = Image.open(x)
    img = img.convert("RGB")
    img_sharp = img.filter(ImageFilter.SHARPEN)
    #img_sharp.show()
    img_sharp.save(x)
    return x
  def contrast(self,x):
    im = Image.open(x)
    enhancer = ImageEnhance.Contrast(im)
    enhanced_im = enhancer.enhance(1.2)
    enhanced_im.save(x)
    return x
  def contrast_sharpen(self,x,sharpen=True,contrast=True):
    im = Image.open(x)
    img_contrast = ImageEnhance.Contrast(im)
    if contrast:
      im = img_contrast.enhance(1.05)
    if sharpen:
      im = im.convert("RGB")
      im = im.filter(ImageFilter.SHARPEN)
    im.save(x, optimize=True)
    return x
  def compress(self, fn):
    from PIL import Image
    if os.path.getsize(fn) > 153600:
      img = Image.open(fn)
      img = img.resize(img.size,Image.ANTIALIAS)
      img.save(fn,optimize=True,quality=80)
    return fn
class Selenium_Firefox_Matrix_Test:
  def some_test_results(self):
    if "geckodriver 18":
      ['quas.py', '3.4.3', '53']
      ['quas.py', '3.4.1', '57']
      ['quas.py', '3.4.3', '52']
      ['quas.py', '3.14.0', '52']
      ['quas.py', '3.6.0', '52']
      ['quas.py', '3.7.0', '52']
      ['quas.py', '3.4.1', '54']
      ['quas.py', '3.7.0', '53']
      ['quas.py', '3.6.0', '53']
      ['quas.py', '3.14.0', '53']
      ['quas.py', '3.14.0', '57']
      ['quas.py', '3.6.0', '57']
      ['quas.py', '3.7.0', '57']
      ['quas.py', '3.4.3', '54']
      ['quas.py', '3.14.0', '54']
      ['quas.py', '3.7.0', '54']
      ['quas.py', '3.6.0', '54']
      ['quas.py', '3.4.1', '53']
      ['quas.py', '3.4.1', '52']
      ['quas.py', '3.4.3', '57']
      ['quas.py', '3.13.0', '57']
      ['quas.py', '3.13.0', '54']
      ['quas.py', '3.12.0', '54']
      ['quas.py', '3.12.0', '52']
      ['quas.py', '3.13.0', '52']
      ['quas.py', '3.13.0', '53']
      ['quas.py', '3.12.0', '53']
      ['quas.py', '3.7.0', '60']
      ['quas.py', '3.6.0', '60']
      ['quas.py', '3.14.0', '60']
      ['quas.py', '3.10.0', '60']
      ['quas.py', '3.11.0', '60']
      ['quas.py', '3.9.0', '60']
      ['quas.py', '3.8.0', '60']
      ['quas.py', '3.4.0', '60']
      ['quas.py', '3.5.0', '60']
      ['quas.py', '3.14.1', '60']
      ['quas.py', '3.4.2', '60']
      ['quas.py', '3.12.0', '57']
    if "geckodriver 19":
      ['quas.py', '3.4.3', '62']
      ['quas.py', '3.11.0', '61']
      ['quas.py', '3.10.0', '61']
      ['quas.py', '3.9.0', '62']
      ['quas.py', '3.8.0', '62']
      ['quas.py', '3.10.0', '62']
      ['quas.py', '3.11.0', '62']
      ['quas.py', '3.8.0', '61']
      ['quas.py', '3.9.0', '61']
      ['quas.py', '3.5.0', '61']
      ['quas.py', '3.4.0', '61']
      ['quas.py', '3.4.0', '62']
      ['quas.py', '3.5.0', '62']
      ['quas.py', '3.4.2', '62']
      ['quas.py', '3.14.1', '61']
      ['quas.py', '3.4.2', '61']
      ['quas.py', '3.14.1', '62']

  def __init__(self):

    exec("from soda.can import *", globals())
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.firefox.firefox_profile import FirefoxProfile
    from selenium.webdriver.firefox.firefox_binary import FirefoxBinary
    from selenium.webdriver.common.keys import Keys
    from selenium.webdriver.common.by import By
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver import ActionChains
    from selenium import webdriver
    from pyvirtualdisplay import Display
    from selenium.webdriver.common.alert import Alert
    from sys import platform
    import selenium.webdriver.support.expected_conditions as EC

    a = ["3.0.0",
    "3.0.1",
    "3.0.2",
    "3.0.4",
    "3.3.0",
    "3.4.0",
    "3.4.1",
    "3.4.2",
    "3.4.3",
    "3.5.0",
    "3.6.0",
    "3.7.0",
    "3.8.0",
    "3.9.0",
    "3.10.0",
    "3.11.0",
    "3.12.0",
    "3.13.0",
    "3.13.1",
    "3.14.0",
    "3.14.1"]
    b = [
    "/Applications/Firefox 61.app/Contents/MacOS/firefox-bin",
    "/Applications/Firefox 62.app/Contents/MacOS/firefox-bin",
    "/Applications/Firefox 63.app/Contents/MacOS/firefox-bin",
    "/Applications/Firefox 64.app/Contents/MacOS/firefox-bin",
    "/Applications/Firefox 46.app/Contents/MacOS/firefox-bin",
    ]
    if __name__ == "__main__":
      import sys
      sys.argv[1]
      print(sys.argv)

      j = sys.argv[2]
      j = ["/Applications/Firefox %s.app/Contents/MacOS/firefox-bin"%j for i in os.listdir("/Applications") if tryreturn(decimal_re, i) == int(j)][0]
      print(j)
      profile = "sele"
      profile_path = os.path.expanduser("~/Library/Application Support/Firefox/Profiles")
      executable_path = os.path.expanduser("~/tavern/tavern/soda/geckodriver 24")
      firefox_profile = FirefoxProfile(homepath("~/Library/Application Support/Firefox/Profiles/%s" % (( [i for i in os.listdir(os.path.expanduser("~/Library/Application Support/Firefox/Profiles")) if profile == "".join(i.split(".")[1:]) ][0] ))))
      firefox_binary = FirefoxBinary(j) # Make sure selenium is 3.8.0
      wd = webdriver.Firefox(executable_path=executable_path, firefox_profile=firefox_profile, firefox_binary=firefox_binary)

    # TESTER 1 #
    for i in a:
      for j in b:
        F = subprocess.getoutput("pip install selenium==%s"%i)
        greenprint(F)
        if "Could not find a version that satisfies the requirement selenium" in F:
          print("continue-")
          continue
        R = subprocess.getoutput("~/tavern/bin/python3.5 quas.py %s %s"%(i, decimal_re(j)))
        redprint(R)
        with open("%s_%s.txt" % (i, decimal_re(j)) , "w") as f:
          f.write(R)
        os.system("killall firefox-bin")

    # TESTER 2 #
    R = os.listdir()
    for i in R:
      try:
        if "Traceback" not in open(i, "r").read():
          print(i)
          if "DEBUG" not in open(i).read():
            distinct_print(open(i).read())
      except Exception as e:
        # redprint(e)
        pass
class Slime(DecisionTree):
  def posit(you,x,lang="en"):
    return True
  def __init__(self):
    exec("from moviepy.editor import *")
    from moviepy.editor import VideoFileClip
    #from mutagen import MP3
    from pydub import AudioSegment
    from gtts import gTTS
    globals().update(locals())
    #print("hello")
    #print(" -- most often, youtube_video_download(7) will be used -- ")
    self.functions_sorted = [
                              "youtube_mp3_download",
                              "scdl",
                              "download", 
                              "halfavideo",
                              "resizevideo",
                              "youtube_channel_download", 
                              "youtube_playlist_download", 
                              "youtube_artist_download", 
                              "youtube_subtitle_download",

                              "youtube_proxy_download",


                              "splice", 
                              "youtube_search_download",
                              "mass_videos_to_subtitles", 
                              "download_a_song",
                              "download_en_masse",
                              "convert_current_directory_to_mp3", 
                              "youtube_video_download", 
                              "vaudioop", 
                              "mp3_compile", 
                              "mp3_to_mp4", 
                              "mp4_to_mp3", 
                              "mp3_to_wav",
                              "wav_to_mp3",
                              "wav_to_array",
                              
                              "speak",
                              "speak2",
                              "save",
                              "get_sound_volume_output",
                              ]
  def resizevideo(self,infile,outfile):
    os.system("ffmpeg -i '%s' -s 640x360 -c:a copy '%s' ;"%(infile,outfile))
  def wav_to_array(self, infile):
    from scipy.io.wavfile import read
    a = read(infile)
    return numpy.array(a[1],dtype=float)
  def wav_to_mp3(self, infile, outfile):
    os.system("ffmpeg -i '%s' -codec:a libmp3lame -qscale:a 2 '%s'"%(infile,outfile))
  def mp3_to_wav(self, infile, outfile):
    os.system("ffmpeg -i '%s' -acodec pcm_u8 -ar 22050 '%s'"%(infile,outfile))
  def download_en_masse(self, data):
    data = data.split(',')
    url = data.pop(0)
    outfile = data.pop(0)
    isotimes = data
    for isotime in isotimes:
      start_isotime, end_isotime = isotime.split('-')
      print("downloading %s %s-%s"%(url, start_isotime, end_isotime))
      self.download(url, outfile, 'mp4', start_isotime, end_isotime)
  def mass_videos_to_subtitles(self, word):
    import os, requests
    os.makedirs(word, exist_ok=True)
    os.chdir(word)
    many_urls = []
    for i in range(30):
      x = requests.get("https://www.youtube.com/results?search_query=%s&page=%s"%(word,i))
      urls = re.findall(r'(?s)href="(/watch.*?)"', x.text)
      urls = list(set(urls))
      urls = ["https://youtube.com%s"%i for i in urls]
      many_urls.extend(urls)
      many_urls = list(set(many_urls))
      print("found %s more urls, total of many_urls is %s" % (len(urls), len(many_urls)))
      #os.system("youtube-dl --sub-lang en --sub-format vtt --write-auto-sub --skip-download https://www.youtube.com/results?search_query=%s&page=15"%(word.replace(" ","+")))
      #os.system("youtube-dl --sub-lang en --sub-format vtt --write-auto-sub --skip-download https://www.youtube.com/results?q=%s&page=%s"%(word.replace(" ","+"), i))
      #os.system("youtube-dl --ignore-errors --all-subs -f 18 -cit https://www.youtube.com/results?q=%s&page=%s"%(word, i))
    for i in many_urls:
      os.system("youtube-dl --sub-lang en --sub-format vtt --write-auto-sub --skip-download %s"%i)
    def to_txt(fn):
      with open(fn, "r") as f:
        txt = f.read()
      # <>s
      pattern = r'(<.*?>)'
      txt = re.sub(pattern, "", txt)
      # timestamps
      pattern = r'(.*-->.*)'
      txt = re.sub(pattern, "", txt)
      txt = txt.split("\n")
      load = []
      for i in txt:
        i = i.strip()
        load.append(i)
      txt = "\n".join(load)
      for i in range(20):
        txt = txt.replace("\n\n", "\n")

      txt = txt.split("\n")
      load = []
      # Only append if line is not duplicate.
      for idx, i in enumerate(txt[:-1]):
        try:
          if txt[idx] != txt[idx+1]:
            load.append(i)
        except Exception as e:
          print(e)
      txt = "\n".join(load)
      return txt
    def lineskip(txt):
      lineskips = [" but", " um", " I'm", " I"]
      txt = txt.replace("\n", " ")
      for i in lineskips:
        txt = txt.replace(i, "\n%s"%i)
      return txt

    input("ready to change text on the downloaded srcs?")
    for i in os.listdir():
      if "vtt" not in i:
        continue
      print("working on file '%s'"%i)
      txt = to_txt(i)
      txt = lineskip(txt)
      with open(i, "w") as f:
        f.write(txt)

  def youtube_mp3_download(self, url):
    i = input("artist&track like this: '%s - %s' ||: ")
    self.download(url, outfile=i, format="mp3")
    
    artist_name, track_name = i.split(" - ")
    track_name = track_name + ".mp3"
    print('artist name: %s' % artist_name)
    print('track name: %s' % track_name)
    os.system('mv "%s.mp3" "%s"' % (i, track_name))
    os.system('id3v2 -a "%s" "%s"' % (artist_name,track_name))
    os.system('id3v2 -t "%s" "%s"' % (track_name,track_name))
    print('\n')
    os.system('id3v2 --list "%s"' % track_name)
    os.system('mv "%s" ~/Documents/' % track_name)
  def download_a_song(self, url, song, album, artist):
    #https://www.youtube.com/watch?v=MW1mnujV6eI
    song = song.replace("_", " ")
    album = album.replace("_", " ")
    artist = artist.replace("_", " ")
    system("youtube-dl --extract-audio --audio-format mp3 %s" % url)
    track_name = [i for i in os.listdir() if ".mp3" in i][0]
    system('mv "%s" "%s"'  % (track_name, "%s.mp3"%song))
    system('id3v2 -a "%s" "%s"' % (artist, track_name))
    system('id3v2 -A "%s" "%s"' % (album, track_name))
    system('id3v2 -t "%s" "%s"' % (song, track_name))
    system('mv *.mp3 ~/Documents/')

  def download(self, url, outfile, format, start_isotime=None, end_isotime=None):
    print("url, outfile, format='mp3', start_isotime=None, end_isotime=None");
    if format == 'mp3':
      system("youtube-dl --extract-audio --audio-format mp3 --output '{}.%(ext)s' {}".format(outfile.replace('.mp3',''), url))
      fn = '%s.mp3' % outfile
      while fn not in os.listdir('.'):
        time.sleep(1)
        print("Waiting...")

      if start_isotime:
        sliced_fn = ('%s-%s-%s'%(start_isotime, end_isotime, fn)).replace(':', '')
        sliced = self.splice(fn, start_isotime, end_isotime, 'mp3')
        sliced.export(sliced_fn)
        system('rm %s'%fn)
        return sliced_fn

      return fn

    elif format == 'mp4':
      system("youtube-dl -f 18 --output '{}.%(ext)s' {}".format(outfile.replace('.mp4',''), url))
      time.sleep(5)
      fn = '%s.mp4' % outfile
      while fn not in os.listdir('.'):
        time.sleep(1)
        print("Waiting...")

      if start_isotime:
        print("splicing...")
        sliced = self.splice(fn, start_isotime, end_isotime, format='mp4')
        system('rm %s'%fn)
  def splice(self, fn, start_isotime, end_isotime, format):
    if format == 'mp3':
      sound = AudioSegment.from_mp3(fn)
      start = self.isotime_to_milliseconds(start_isotime)
      end = self.isotime_to_milliseconds(end_isotime)
      spliced_sound = sound[start:end]
      spliced_sound.export("%s-%s_%s"%(start_isotime,end_isotime,fn.split('/')[-1]))
      return spliced_sound 
    elif format == 'mp4':
      video = VideoFileClip(fn)
      start = self.isotime_to_seconds(start_isotime)
      end = self.isotime_to_seconds(end_isotime)
      video = video.subclip(start, end)

      sliced_fn = ('%s-%s-%s'%(start_isotime, end_isotime, fn)).replace(':', '')
      print('sliced_fn: %s'%sliced_fn)
      video.write_videofile(sliced_fn, fps=24)
      return video
  def youtube_search_download(self, query):
    query = query.replace('_','+')
    system("youtube-dl --ignore-errors -f 18 -cit https://www.youtube.com/results?q=%s&page=1"%query)
  def youtube_channel_download(self, url, format, bestquality="False", proxy="False"):
    proxy = eval(proxy)
    bestquality = eval(bestquality)

    print("please specify a format, mp4/m4a, or mp3 || note in future will have need cvrt webm to m4a.. ")
    x = requests.get(url).text
    folder_name = or_list(lambda:SOUPY(x,"h2","class","epic-nav-item-heading")[0].text.strip(),SOUPY(x,"span","class","qualified-channel-title-text")[0].text)
    print("downloading to ~/Documents/%s" % folder_name)
    if format == "mp3":
      ###
      if proxy == False:
        system('mkdir "/Users/$USER/Documents/%s" && cd "/Users/$USER/Documents/%s" && youtube-dl --extract-audio --audio-format mp3 --ignore-errors %s &' % (folder_name,folder_name,url))
      ###
      ###
      elif proxy == True:
        proxy_list = get_us_ip_list() # stored in general-utils
        for idx, proxy in enumerate(proxy_list):
          print("#%s" % idx)
          #response = getoutput("youtube-dl --proxy %s %s" % (proxy, url))
          response = getoutput('mkdir "/Users/$USER/Documents/%s" && cd "/Users/$USER/Documents/%s" && youtube-dl --extract-audio --audio-format mp3 --ignore-errors --proxy %s "%s" & '%(folder_name,folder_name,proxy,url))
          print(response)
          if "[download] Destination:" in response:
            print("found it -- proxy 1")
      ###
    elif format == "m4a" or format == "mp4":
      if proxy == False:
        if bestquality == False:
          system('mkdir "/Users/$USER/Documents/%s" ; cd "/Users/$USER/Documents/%s" && youtube-dl --ignore-errors -f 18 "%s" '%(folder_name,folder_name,url))
        elif bestquality == True:
          bestqualitie = self.get_best_qualitie(url)
          print("bestqualitie: %s" % bestqualitie)
          system('mkdir "/Users/$USER/Documents/%s" ; cd "/Users/$USER/Documents/%s" && youtube-dl --ignore-errors -f %s "%s" '%(folder_name,folder_name, bestqualitie, url))
      elif proxy == True:

        proxy_list = get_us_ip_list() # stored in general-utils
        random.shuffle(proxy_list)
        for idx, proxy in enumerate(proxy_list):
          print("#%s" % idx)
          #response = getoutput("youtube-dl --proxy %s %s" % (proxy, url))
          response = getoutput('mkdir "/Users/$USER/Documents/%s" ; cd "/Users/$USER/Documents/%s" && youtube-dl --ignore-errors --proxy %s "%s" '%(folder_name,folder_name,proxy,url))
          print(response)
          if "[download] Destination:" in response:
            print("found it -- proxy 1")
    try:
      if format == "mp3":
        for i in os.listdir(homepath("~/Documents/%s" % folder_name)):
          system('id3v2 -a "%s" "/Users/$USER/Documents/%s/%s"' % (folder_name,folder_name,i))
          system('id3v2 -t "%s" "/Users/$USER/Documents/%s/%s"' % (i,folder_name,i))
    except:
      # untested
      pass
  def get_best_qualitie(self, url):
    q = getoutput("youtube-dl -F '%s'"% url)
    qualities = {}
    for i in q.split("\n"):
      if " mp4 " in i:
        note=re.findall(r" ([0-9]+p)", i)
        format_=re.findall(r"(^[0-9]+) ", i)
        if note != []:
          qualities[format_[0]] = int(note[0].replace("p",""))
    bestqualitie = -1
    for format_ in qualities:
      if qualities[format_] > bestqualitie:
        bestqualitie = qualities[format_]
    return bestqualitie

  def get_sound_volume_output(self, seconds=10):
    import sounddevice as sd
    import numpy as np
    def print_sound(indata,outdata,frames,time,status):
      volume_norm = np.linalg.norm(indata)*10
      print("|" * int(volume_norm))
    with sd.Stream(callback=print_sound):
      sd.sleep(seconds * 1000)

  def youtube_playlist_download(self, url, format="mp3", folder_name = None):
    print("please specify a format, mp4/m4a, or mp3 || note in future will have need cvrt webm to m4a.. ")
    folder_name = url.split("/")[-1] if folder_name == None else folder_name
    print("downloading to ~/Documents/%s" % folder_name)
    if format == "mp3":
      system("mkdir ~/Documents/%s ; cd ~/Documents/%s && youtube-dl --extract-audio --audio-format mp3 --ignore-errors %s &" % (folder_name,folder_name,url))
    elif format == "m4a" or format == "mp4":
      system('mkdir ~/Documents/%s ; cd ~/Documents/%s && youtube-dl --ignore-errors -f 18 "%s" &'%(folder_name,folder_name,url))


  def youtube_artist_download(self):
    artist = OSA.log("artist?:")
    playlist_urls = []
    while True:
      x = str(pyperclip.paste()).split("&playnext")[0]
      if "playlist" in x and x not in playlist_urls:
        playlist_urls.append(x)
      if x == "end":
        break
    os.makedirs(homepath("~/Documents/%s"%(artist)),exist_ok=True)
    for i in playlist_urls:
      title = SOUP(requests.get(i).text).findAll("h1",attrs={"class":"pl-header-title"})[0].text.strip()
      y = homepath("~/Documents/%s/%s"%(artist,title))
      os.makedirs(y,exist_ok=True)
      os.chdir(y)
      os.system("youtube-dl --extract-audio --audio-format mp3 --ignore-errors %s"%(i))
      os.system("id3v2 -a '%s' *"%(artist))
      os.system("id3v2 -A '%s' *"%(title))

  # def youtube_artist_download(self):
  #   artists = OSA.log("artists (delimited by ', ')?:")
  #   ss = Browser()("ch")
  #   for artist in artists:
  #     ss.get("https://www.youtube.com/results?search_query=%s"%(artist))
  #     ss.fcns("ytd-search-refinement-card-renderer")


  def convert_current_directory_to_mp3(self):
    for fn in os.listdir():
      if '.mp4' == fn[-4:]:
        self.mp4_to_mp3(fn, fn.replace('.mp4','.mp3'))
        os.remove(fn)
  def youtube_video_download(self, url):
    system('youtube-dl -f 18 -citw -v %s'%url)
  def isotime_to_milliseconds(self, isotime):
    minutes, seconds = isotime.split(':')
    milliseconds = 1000 * ((int(minutes)*60)+int(seconds))
    return milliseconds
  def isotime_to_seconds(self, isotime):
    minutes, seconds_ = isotime.split(':')
    seconds = ((int(minutes)*60)+int(seconds_))
    return seconds
  def milliseconds_to_isotime(self, milliseconds):
    seconds = int((milliseconds/1000)%60)
    minutes = int(((milliseconds/1000)-seconds)/60)
    return '%s:%s' % (minutes, seconds)
  def OverlayAudioToVideo(self,audio,video,out):
    aud = AudioFileClip(audio)
    vid = VideoFileClip(video)
    ed = clip.fx(vfx.loop,duration=aud.duration)
    final = ed.set_audio(audio)
    final.write_videofile(out,fps=clip.fps,audio_bitrate="2000k",bitrate="8000k")
  def mp3_compile(self, crossfade=2):
    print("this will compile the mp3 files in this directory... crossfade inputtable")
    out_fn = input("output mp3 filename?: ")
    payload = AudioSegment.from_mp3('silence')
    
    for idx, i in enumerate(os.listdir('.')):
      print('%s. %s'%(idx, i))
    numbers = input("Numbers delimited by ', '?: ") 
    numbers = list(map(int, numbers.split(', ')))
    tracktimes = []
    for i in numbers:
      filename = os.listdir('.')[i]
      payload += AudioSegment.from_mp3(filename)
      tracktimes.append("%s : %s" % (filename, self.milliseconds_to_isotime(len(payload))))
      payload += AudioSegment.from_mp3('silence') * crossfade
    print('\n'.join(tracktimes))
    payload.export(out_fn)
  @timeit
  def mp3_to_mp4(self, picture, mp3, out='final.mp4'):
    Images().resize(picture, 1920)
    system("ffmpeg -loop 1 -i %s -i %s -c:v libx264 -c:a aac -strict experimental -b:a 192k -shortest -preset ultrafast %s" % (picture,mp3,out))
  def mp4_to_mp3(self, fn, outfile):
    clip = VideoFileClip(fn) # .subclip(0,20)
    clip.audio.write_audiofile(outfile)
  def scdl(self, artist, link):
    from mutagen.mp3 import MP3
    os.makedirs(homepath("~/Documents/%s"%(artist)))
    os.chdir(homepath("~/Documents/%s"%(artist)))
    os.system("scdl --onlymp3 -c -t -l %s"%(link))
    os.system('id3v2 -a """%s""" *'%(artist))
    for i in os.listdir():
      audio = MP3(i)
      if audio.info.length < 45:
        print("%s less than 45 seconds in runtime, it is %s. deleting..." % (i, audio.info.length))
        os.remove(i)
  def halfavideo(self, count=8, fn="Test.mp4"):
    print("inputs are count, fn ")
    command = "ffmpeg -i %s -filter:a '%s' -vn %s_slower_%s" \
      % (fn, ("atempo=0.5 "*count).strip().replace(" ", ","), count, fn)

    print(command)
    print("%s Times Slower" % 0.5**count)
    import os
    os.system(command)
  def youtube_proxy_download(self, url):
    # ip_regex = r"\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b"


    proxy_list = get_us_ip_list() # stored in general-utils

    for idx, proxy in enumerate(proxy_list):
      print("#%s" % idx)
      #response = getoutput("youtube-dl --proxy %s %s" % (proxy, url))
      response = getoutput("youtube-dl --sub-lang en --sub-format vtt --write-auto-sub --proxy %s %s" % (proxy, url))
      print(response)

      if "[download] Destination:" in response:
        print("found it -- proxy 1")

        return response


  def youtube_subtitle_download(self, url):
    print("youtube subtitle downloading url: %s" % url)
    def dl(url):
      x = getoutput("youtube-dl --sub-lang en --sub-format vtt --write-auto-sub --skip-download %s" % url)
      x = x.split(": ")[-1]
      getoutput("mv '%s' '%s'" % (x, x.replace(" ", "_")))
      return x.replace(" ", "_")
    def to_txt(fn):
      with open(fn, "r") as f:
        txt = f.read()
      # <>s
      pattern = r'(<.*?>)'
      txt = re.sub(pattern, "", txt)
      # timestamps
      pattern = r'(.*-->.*)'
      txt = re.sub(pattern, "", txt)
      txt = txt.split("\n")
      load = []
      for i in txt:
        i = i.strip()
        load.append(i)
      txt = "\n".join(load)
      for i in range(20):
        txt = txt.replace("\n\n", "\n")

      txt = txt.split("\n")
      load = []
      # Only append if line is not duplicate.
      for idx, i in enumerate(txt[:-1]):
        try:
          if txt[idx] != txt[idx+1]:
            load.append(i)
        except Exception as e:
          print(e)
      txt = "\n".join(load)
      return txt
    def lineskip(txt):
      lineskips = [" but", " um", " I'm", " I"]
      txt = txt.replace("\n", " ")
      for i in lineskips:
        txt = txt.replace(i, "\n%s"%i)
      return txt
    def main(url):
      fn = dl(url)
      txt = to_txt(fn)
      txt = lineskip(txt)
      with open("%s.txt"%fn, "w") as f:
        f.write(txt)
    main(url)
    print("success")


  def speak(self, text = None, lang="en", slow=False):
    if text == None: text = multi_input("Input text to speak: ").replace("\n", ". ")
    tts = gTTS(text, lang=lang, slow=slow)
    tts.save("out.mp3")
    os.system("afplay out.mp3 && rm out.mp3 &")
  def speak2(self, text = None):
    if text == None: text = multi_input("Input text to speak: ").replace("\n", ". ")
    os.system('say """%s""" &' % text)
  def save(self, text, output, lang="en", slow=False):
    text = multi_input("Input text to speak: ").replace("\n", ". ") if text==None else text
    tts = gTTS(text, lang=lang, slow=slow)
    tts.save(output)
  def translate(self, to_translate, to_language="en", from_language="auto"):
    from mtranslate import translate
    return translate(to_translate, to_language, from_language)
  def mtranslate(self, to_translate, to_language="en", from_language="auto"):
    from mtranslate import translate
    return translate(to_translate, to_language, from_language)
  def verbalpolygon(you, inner, lacks=["en","en"]):
    from mtranslate import translate
    return translate(inner, lacks[1], lacks[0])
  def add_videos(self, files, destination):
    files = lmap(lambda i:("'%s'"%(i)), files)
    os.system("mencoder -forceidx -ovc copy -oac pcm -o '%s' %s"%(destination, Join(" ",files)))
    

  def get_albums_from_wikipedia(self,url="https://en.wikipedia.org/wiki/1969_in_music"):
    """ url = "https://en.wikipedia.org/wiki/1969_in_music" """
    a = read_html(url)
    a = [i for i in a if "Album" in str(i)]
    redprint(len(a))
    a = sum(a,[])
    redprint(len(a))
    return a


  def audio_record(self):
    # Other aliases: record_wav, record_sound, record_self, record_audio, mp3_record, wav_record
    address = greeninput("address?: ")
    (  [redprint("address in os.listdir()"),0/0]  )  if(0!=os.listdir().count(address))    else(  [redprint("address `%s` not in os.listdir()"%address)]  )
    OSA(None, ["cmd_arrow_right"]) # shift aside desktop windows.
    os.system("""/usr/local/bin/sox -d "%s" """ % (address))
  def tests(self):
    test_url = 'https://www.youtube.com/watch?v=PN7HJBodm8o'
    self.download(test_url, outfile='test_download', format='mp3')
    print('test done')
    self.download(test_url, outfile='test_download2', format='mp3', start_isotime='00:10', end_isotime='1:10')
    print('test done')
    self.download(test_url, outfile='test_download3', format='mp4')
    print('test done')
    self.download(test_url, outfile='test_download4', format='mp4', start_isotime='00:10', end_isotime='1:10')
    print('test done')
    self.mp4_to_mp3(input('mp4_to_mp3?:'), input("outfile?: "))
    self.mp3_compile()
def check_domain_name_via_shopify(domain):
  if(0!=len(re.findall(r"\d+",domain))):
    OSA.display_dialog("Numbers are not support in domain in this project. Please try again.", text_prompt = False, buttons=["OK"])
    return
  zo = "https://www.shopify.com/tools/domain-name-generator/search?utf8=%E2%9C%93&query={}&button=&tool=domain_name_generator"
  po = zo.format(domain)
  vo = requests.get(po).text
  zox = re.findall(r"""polling_exact_id.*?value="(.*)" """,vo)
  if len(zox) == 0:
    OSA.display_dialog("domain %s is not available.", text_prompt = False, buttons=["OK"])
  else:
    zox = zox[0]
  idv = 0
  bung = []
  while True:
    idv += 1
    kooks = ""
    def run():
      blech = "https://www.shopify.com/tools/domain-name-generator/poll?pollingID={}&page={}".format(zox, idv)
      kooks = requests.get(blech).text
      distinct_print(kooks)
      if kooks == '{"results":"-PENDING-"}':
        print("something as -pending-")
        return run()
      else:
        return kooks
    kooks = run()
    if """{"results":[]}""" == kooks:
      break
    else:
      bung.append(kooks)
  bang = pool(lambda x: json.loads(x)["results"], bung).result()
  try:beng = sum(bang, [])
  except:print(bang[0])
  nos = pool(lambda x: AttrDict(x), beng).result()
  keycall("__delitem__", nos, "shop_name")
  if not keyequals("domain_name", domain, nos):
    dialog = "domain %s is not available or already purchased.\nIf it is owned by you, please continue normally.\nHere are your other options:\n%s"%(domain, "\n".join(["%s is %s at $%s per year"%(i.domain_name, ("Available")if(True==i.available)else("not available"), i.price) for i in nos]))
  if False == keyequals("domain_name", domain, nos)[0].available:
    dialog = "domainc %s is not available or already purchased.\nIf it is owned by you, please continue normally.\nHere are your other options:\n%s"%(domain, "\n".join(["%s is %s at $%s per year"%(i.domain_name, ("Available")if(True==i.available)else("not available"), i.price) for i in nos]))
  if True == keyequals("domain_name", domain, nos)[0].available:
    dialog = "domain %s is available at $%s per year" % (domain, keyequals("domain_name", domain, nos)[0].price)
  OSA.display_dialog(dialog, text_prompt = False, buttons = ["OK"])

  class My_Requests:
    process_ = False
    help = lambda self: redprint("""  def request(self,process_count=4,timeout=10,notInUrl="ø",notInText="ø",proxy=True):  """)
    requesting = lambda self: process(lambda: [self.request(no_return=True),self.requesting()if(0!=len(Filter(Request,x=False)))else([-1,redprint("Empty")])])
    def request(self,process_count=10,timeout=10,notInUrl="ø",notInText="ø",proxy=True,url=None,helper_count = 500,no_return = False):
      #url = "https://google.com"
      #timeout=10
      #notInUrl="ø"
      #notInText="ø"


      not_requested = Filter_Get_Randoms(Request,x=False,count=helper_count)if(None==url)else( [setitem(globals(),"url_specified_request",Create(Request,w=url)),Filter(Request,id=globals()["url_specified_request"].id)][1] )
      not_requested = list(not_requested)

      __special_metric__ = len(not_requested) + 1
      for idx_z, i in enumerate(range(helper_count)):
        __special_metric__ = __special_metric__ - 1
        redprint("__special_metric__: %s, idx_z: %s" % (__special_metric__,idx_z))
        if __special_metric__ == 0:
          return "None"
        self.new = not_requested.pop(0)
        magentaprint("self.new: %s" % self.new)
        if self.new.notInText: notInText = self.new.notInText
        if self.new.notInUrl: notInUrl = self.new.notInUrl


        if not self.new.cookies_label:
          a = requests.get(self.new.w)
          distinct_print(a.status_code)
          """ ::: hnsr y ts in hr. tk out. amazon_add gv me EROR. ::: """ #   ({[({[[[\\Took\\it\\out\\and\\it\\was\\fine.]]]]]}})})
          """ ::: Upon inspection, the ABOVE THING, i said, well.       if amazon in url, and a's status_code was 503... LOL. ::: """
          if((self.new.w.find("amazon")>-1)and(503==a.status_code)): return self.request(process_count=process_count,timeout=timeout,notInUrl=notInUrl,notInText=notInText,proxy=proxy,url=None,helper_count=helper_count,no_return=no_return)
          if (0!=a) and (-1!=getattr(a,"status_code",-1)) and (notInUrl not in getattr(a,"url",notInUrl)) and (notInText not in getattr(a,"text",notInText)):
            if no_return == True:
              Update(self.new,y=a.text,x=True,time_added=datetime.now()).y
              continue
            else:
              """ ::: Not sure why I took this out. ::: """
              #1
              return Update(self.new,y=a.text,x=True,time_added=datetime.now()).y

        print("here")
        #magentaprint(self.new.y)
        """ """
        s = None
        if self.new.cookies_label:
          s = requests.Session()
          s.headers = session_headers
          cookies = None
          cookies = cookies_to_database(username=self.new.cookies_label.split("|")[0],website_name=self.new.cookies_label.split("|")[1],reverse=True)
          s = cookies_to_session(cookies, s)
          a = s.get(self.new.w)
          redprint("[%s][%s]"% (a.status_code, self.new.w))

          if (0!=a) and (-1!=getattr(a,"status_code",-1)) and (notInUrl not in getattr(a,"url",notInUrl)) and (notInText not in getattr(a,"text",notInText)):
            redprint("[ensuring] `%s` not in `a.text`: %s" % (notInText, notInText not in a.text))
            redprint("[ensuring] `%s` not in `a.url`: %s" % (notInUrl, notInUrl not in a.text))
            if no_return == True:
              Update(self.new,y=a.text,x=True,time_added=datetime.now()).y
              continue
            else:
              return Update(self.new,y=a.text,x=True,time_added=datetime.now()).y
          else:
            redprint("[ensuring] `%s` in `a.text`: %s" % (notInText, notInText in a.text))
            redprint("[ensuring] `%s` in `a.url`: %s" % (notInUrl, notInUrl in a.text))




          """ if self.new.cookies_label, you're not gonna get it without the cookies, ie you must continue at the end of this if statement """
          continue
        """ """
        magentaprint("[url][%s]" % self.new.w)
        proxies = Proxy().get_random_proxy()if(1==proxy)else(None)
        processes = []
        for i in range(process_count):
          def run_once():
            if Get(Request,id=self.new.id).y == None:
              magentaprint(Get(Request,id=self.new.id).y)
              #a = tryreturn(requests.get,self.new.w,timeout=10,headers=session_headers,proxies=proxies,ep=True)
              #a = tryreturn(requests.get,self.new.w,timeout=10,headers=session_headers,proxies=proxies,ep=True)
              a = None
              try:
                if "amazon" in self.new.w:
                  a = requests.get(self.new.w,timeout=10,proxies=proxies,headers=amazon_headers)
                else:
                  a = requests.get(self.new.w,timeout=10,proxies=proxies,headers=session_headers)
              except Exception as e:
                redprint(e)
                time.sleep(10)
              print(a)
              print(a)
              print("going")
              if (0!=a) and (-1!=getattr(a,"status_code",-1)) and (notInUrl not in getattr(a,"url",notInUrl)) and (notInText not in getattr(a,"text",notInText)):
                if Get(Request,id=self.new.id).y != None:
                  if no_return == True:
                    Update(self.new,y=a.text,x=True,time_added=datetime.now()).y
                  else:
                    return Update(self.new,y=a.text,x=True,time_added=datetime.now()).y
              else:
                  return run_once()
          print("appending process")
          processes.append(process_(run_once)if(1==self.process_)else(process(run_once)))
        while True:
          time.sleep(1/4)
          if Get(Request,id=self.new.id).y != None:
            magentaprint(Get(Request,id=self.new.id).y)
            if self.process_ == True: keycall("terminate",processes)
            return Get(Request,id=self.new.id).y
        """ if notInUrl set to partial correct url, it will request x/second And Likely 443. """
  class Recaptcha:
    def __init__(self):
      # Attempt No.1
      # Attempt No.1
      # Attempt No.1
      # Attempt No.1
      # Attempt No.1
      # Attempt No.1
      os.system("brew install pocketsphinx")
      os.system("brew install ffmpeg")
      os.system("pip install moviepy")
      os.system("pip install gtts")
      OSA.display_dialog("Download the audio from the recaptcha.", text_prompt = False)

      os.remove("audio.mp3")
      os.remove("audio.wav")
      os.system("mv ~/Downloads/audio.mp3 audio.mp3")
      Slime().mp3_to_wav("audio.mp3", "audio.wav")
      a = Speech_Recognition().recognize_sphinx("audio.wav")
      b = Speech_Recognition().recognize_google("audio.wav")
      c = Speech_Recognition().recognize_google_cloud("audio.wav")
      print(a, b, c)


""" Business-Utils-Product-Utils """
def adjustvariantname(x):
  x = x.title()
  x = re_found_function(x,"(?i)X{6}l",lambda i:re_substitute(i,["(?i)X{6}l","6XL"]))
  x = re_found_function(x,"(?i)X{5}l",lambda i:re_substitute(i,["(?i)X{5}l","5XL"]))
  x = re_found_function(x,"(?i)X{4}l",lambda i:re_substitute(i,["(?i)X{4}l","4XL"]))
  x = re_found_function(x,"(?i)X{3}l",lambda i:re_substitute(i,["(?i)X{3}l","3XL"]))
  x = re_found_function(x,"(?i)X{2}l",lambda i:re_substitute(i,["(?i)X{2}l","2XL"]))
  x = re_found_function(x,"(?i)^Xl$",lambda i:re_substitute(i,["(?i)^Xl$","XL"]))
  x = re_found_function(x,"(?i)^Xs$",lambda i:re_substitute(i,["(?i)^Xs$","XS"]))
  x = re_found_function(x,"(?i)^Xxs$",lambda i:re_substitute(i,["(?i)^Xxs$","XXS"]))


  x = re_found_function(x,"(?i)^\d+Xl",lambda i:re_substitute(i,["(?i)(^\d+)Xl","\\1XL"]))
  x = re_found_function(x,"(?i)^\d+Xs",lambda i:re_substitute(i,["(?i)(^\d+)Xs","\\1XS","\\1XS"]))
  x = re_found_function(x,"(?i)\d+in",lambda i:re_substitute(i,["(?i)(\d+)in","\\1in"]))
  x = re_found_function(x,"(?i)\d+cm",lambda i:re_substitute(i,["(?i)(\d+)cm","\\1cm"]))

  x = re_found_function(x,"(?i)^asian",lambda i:re_substitute(i,["(?i)^asian",""]).strip())
  # x = re_found_function(x,"(?i)cm",lambda i:re_substitute(re_substitute_function(i,"[\d\.]+",lambda i:or_list(lambda:list_and(lambda:str(round(flt(i)/2.54,1)).endswith(".0"),lambda:str(int(round(flt(i)/2.54,1)))),lambda:str(round(flt(i)/2.54,1)))),["(?i)cm","in"])  )
  x = re_found_function(x,"(?i)^For",lambda i:re_substitute(i,["(?i)^For",""]).strip())
  x = re_found_function(x,"(?i)iPhone",lambda i:re_substitute(i,["(?i)iPhone","iPhone"]).strip())
  x = re_found_function(x,"(?i)iPhone",lambda i:re_substitute(i,["(?i)Xs","XS"]).strip())
  x = re_found_function(x,"(?i)iPhone",lambda i:re_substitute(i,["(?i)Xr","XR"]).strip())
  x = re_found_function(x,"(?i)iPhone",lambda i:re_substitute(i,["(?i)Se","SE"]).strip())
  x = re_found_function(x,"(?i)iPhone",lambda i:re_substitute(i,["(?i)Xsmax","XS Max"]).strip())
  x = re_found_function(x,"(?i)Style",lambda i:i)
  x = re_found_function(x," {2,}",lambda i:re_substitute(i,[" {2,}"," "]))
  x = re_found_function(x,"(?i)eu size",lambda i:re_substitute(i,["(?i)eu size",""]).strip())
  x = re_found_function(x,"(?i)^Size[- ]",lambda i:re_substitute(i,["(?i)^Size[- ]",""]).strip())
  x = re_found_function(x,"(?i)(^A\d+)",lambda i:re_substitute(i,["(?i)(^A\d+)","Samsung \\1"]).strip())
  x = re_found_function(x,"(?i)(^J\d+)",lambda i:re_substitute(i,["(?i)(^J\d+)","Samsung \\1"]).strip())
  x = re_found_function(x,"(?i)(^P\d+)",lambda i:re_substitute(i,["(?i)(^P\d+)","Huawei \\1"]).strip())
  x = re_found_function(x,"(?i)^Galaxy",lambda i:re_substitute(re_substitute(i,["(?i)^Galaxy","Samsung Galaxy"]),["Samsung Galaxy","Samsung"]).strip())
  x = re_found_function(x,"(?i)(^P Smart)",lambda i:re_substitute(i,["(?i)(^P Smart)","Huawei \\1"]).strip())
  x = re_found_function(x,"(?i)(\d+)Xl",lambda i:re_substitute(i,["(?i)(\d+)Xl","\\1XL"]).strip())
  x = re_found_function(x,"(?i)((?:^Xl$|^Xs$))",lambda i:re_substitute(i,["(?i)((?:^Xl$|^Xs$))","\\1"]).upper())

  return x
def address_string_from_dict(x):
  return ifelseget(lambda:x.get("address2"),lambda:"{first_name} {last_name}, {address1}, {address2}, {city}, {province_code} {zip} {country}".format(**{a:re.sub(" +"," ",str(b)).strip().title() for a,b in x.items()}),lambda:"{first_name} {last_name}, {address1}, {city}, {province_code} {zip} {country}".format(**{a:re.sub(" +"," ",str(b)).strip().title() for a,b in x.items()}))
def address_string_from_dict_2(x):
  return ifelseget(lambda:x.get("Card Address Line2"),lambda:"{Card Name}, {Card Address Line1}, {Card Address Line2}, {Card Address City}, {Card Address State} {Card Address Zip} {Card Address Country}".format(**{a:re.sub(" +"," ",str(b)).strip().title() if a != "Card Address Country" else country_code_dict[b] for a,b in x.items()}),lambda:"{Card Name}, {Card Address Line1}, {Card Address City}, {Card Address State} {Card Address Zip} {Card Address Country}".format(**{a:re.sub(" +"," ",str(b)).strip().title() if a != "Card Address Country" else country_code_dict[b] for a,b in x.items()}))
def affix_option_names(p, shop):
  p = shop.shopify.Product.find(id_=p.id)
  data = {}
  for i in p.options:
    i = i.to_dict()
    data[i["name"]] = i["values"]
    print(i["name"], i["values"])
  
  to_make_changes = input("to_make_changes to variant names (y/n): ")
  #to_make_changes = "n"
  if to_make_changes == "n":
    print("Finished creating all variant changes")
    return

  changes = {}
  while True:
    x = input("q\old->new eg- 'XXL->2XL' : ")
    if x=="q":break
    old, new = x.split("->")
    changes[old] = new
  print("changes:\n%s\n"%changes)
  for i in p.variants:
    changed  = False
    for old,new in changes.items():
      try:
        if i.option1 == old:
          i.option1 = new
          changed = True
      except : pass
      try:
        if i.option2 == old:
          i.option2 = new
          changed = True
      except : pass
      try:
        if i.option3 == old:
          i.option3 = new
          changed = True
      except : pass
    if changed == True:
      print("changed, saving")
      i.save()
      p = shop.shopify.Product.find(id_=p.id)
  print("[Reminder] if you want to directly delete an option; as far as i know how, you would do it thru the browser")
  return affix_option_names(p, shop)
def affix_product_descriptions():
  #for shop  in Shop.objects.filter(shop_abbreviation="aws"):
  for shop  in Shop.objects.all()[:1]:
    shop = Shop()( shop.shop_abbreviation)
    products = [i for i in getshopifyproducts(shop) if len(Product.objects.filter(id=i.id)) > 0]
    products = [i for i in products if Product.objects.get(id=i.id).description!=None]
    for idx,p in enum(products):
      #p = affix_product_title(p)
      #distinct_print(describe_product(p))
      zz(0.5)
      try:
        Shop()(shop.shop_abbreviation)
        distinct_print(describe_product(p)[:25])
      except Exception as e:
        redprint("[%s][%s][affix_product_descriptions]"%(idx,e))
def append_pictures():
  workmode = None
  if Muta()().sciencevessels_on:
    x = list(All(ScienceVessel))[-1]
    y = {"index":None, "urls":None}
    io = OSA.log("Enter in a number to specify the image (usually 0 or -1) and then the urls. Delimit with ', '").split(", ")
    index = int(io[0])
    urls = io[1:]
    y["index"] = io
    y["urls"] = urls
    x.append_pictures = url
    x.save()
  else:
    io = OSA.log("Enter in a number to specify the image (usually 0 or -1) and then the urls. Delimit with ', '").split(", ")
    product = list(All(Product))[-1]
    index = int(io[0])
    if index < 0:
      index = len(product.images) + index + 1
    urls = io[1:]
    product_ = Shop()(product.shop).pfind(id_=product.id)
    images = lmap(lambda i: {"attachment": i}, pool(lambda i: Images().image_base64(i), pool(Images().sharpen, pool(Images().download, urls).result()).result()).result())
    product_.images = product_.images[:index] + images + product_.images[index:]
    product_.save()
def create_navigation_menu_items(shop, menu_name, menu_items):
  shop.Login_Shopify_Store()
  globals().update(g.__globals__)
  ss.get("{}/menus".format(shop.Administrative_Url))
  for i in ss.fcns("next-table__cell--full-width-when-condensed"):
    if i.text == menu_name:
      ss.get(ss.fxsxs(i)[0].get_attribute("href"))
  x = []
  for idx, i in enum(menu_items):
    print("idx: %s, total: %s" % ((idx+1), len(menu_items)))
    ss.fcn("menu__add-menu-item").click().sp(3)
    ss.fid("addMenuItemLink").send_keys(i).sp(3)
    ss.tp(lambda: ss.jtns("a","click",{"data-bind-event-click":'itemSelected(event, "collection")'},_time=2)).sp(2)
    if tryprocess(lambda: ss.fcns("next-list__item--disabled",_time=2)[0].text.split("result")[0].strip()) == 1:
      if 1 != int(ss.fcns("next-list__item--disabled",_time=4)[0].text.split("result")[0].strip()):
        x.append(i)
    ss.fid("addMenuItemLink").send_keys(ss.Keys.ARROW_DOWN).sp(3)
    ss.fid("addMenuItemLink").send_keys(ss.Keys.ARROW_DOWN).sp(3)
    ss.fid("addMenuItemLink").send_keys(ss.Keys.ENTER).sp(4)
    ss.ffst("button","Add").click().sp(5)
  ss.ffs("button","aria-label","Save").click().sp(7)
def delete_product_images(shop_abbreviation, id_):
  shop = Shop()( shop_abbreviation)
  p = shop.shopify.Product.find(id_=id_)
  images = input("Images delimited by ',' ie 2,4,5,6 : ")
  images_numbers = list(map(int, images.split(",")))
  previous_image_count = len(p.images)
  print("previous image count: %s" % previous_image_count)
  for i in images_numbers:
    p.images[i].destroy()
  p = shop.shopify.Product.find(id_=id_)
  new_image_count = len(p.images)
  print("new image count: %s" % new_image_count)
  deleted_count = previous_image_count - new_image_count
  print("deleted count: %s" % deleted_count)
  return None
def describe_product(p):
  if type(p) == Product: p = Shop()( p.shop).shopify.Product.find(id_=p.id)
  i = Product.objects.get(id=p.id)
  description = i.description
  shop = Shop()( Product.objects.get(id=p.id).shop)

  get_size_chart = lambda product_type: Sizechart.objects.get(product_type=product_type).size_chart
  #if p.image == None: return "product image was None"
  #if p.image.alt == None: return "product image alt was None"
  x = ((( (( description if description != None else """""" )) + (( "<p></p>" )) ))) + \
  ((( (( shop.product_page_general_information )) + ((  "<p></p>"  )) )))


  if i.size_chart != None and i.is_available() and i.product_type in SIZE_CHART_PRODUCT_TYPES and i.shop != None:
    if i.is_unavailable():
      ""
    elif i.size_chart == "Unmatched":
      "None/Text in <p>/Redo"
    else:
      size_chart_string_size_chart = ""
      if i.size_chart[0].startswith("http"):
        if len(i.size_chart) == 1:
          for b in i.size_chart:
            size_chart_string_size_chart += """<img src="{}" alt="Size Chart" />""".format(b)
        elif len(i.size_chart) >  1:
          for b in i.size_chart[-1:]:
            size_chart_string_size_chart += """<img src="{}" alt="Size Chart" />""".format(b)
      elif not i.size_chart[0].startswith("http"):
        if len(i.size_chart) == 1:
          for b in i.size_chart[-1:]:
            size_chart_string_size_chart += b
            size_chart_string_size_chart += "<br />"
        elif len(i.size_chart) >  1:
          for b in i.size_chart:
            size_chart_string_size_chart += b
            size_chart_string_size_chart += "<br />"
      size_chart_string = """<p><strong>Size Chart*<br />{}<br /></strong>*This size chart is specifically for this item.</p>""".format(size_chart_string_size_chart)
      #distinct_print(size_chart_string)
      x = re.sub(r"(<p.*?<table.*</table>)", "<br /><br />%s"%size_chart_string, x)

  try:
    if p.image == None: p.destroy(); return
  except Exception as e:
    print(e)
  x = x.replace("\xa0", "").replace("\n", "<br />")
  # x is the description you should be creating.
  # if database product's body_html is not x... then save.
  # so if `i`.body_html != x:

  if i.body_html != x:
    i.body_html = x; i.save()
    p.body_html = x
    assert p.save() == True
    distinct_print("[different body html][saving][%s]" % p.id)
  else:
    distinct_print("[same body_html][not saving][%s]"%p.id, end="")
  return x
def delete_product(x):
  if type(x) == int: x = Get(Product,id=x)
  tp(lambda:Del(Get(GhostProduct,id=x.id)))
  pool(lambda:[apilimitcall(lambda:x.p().destroy()),print(apilimitcall(lambda:Shop()(x.shop).pfind(handle=x.handle)))])
  print("deleting product")
  tp(lambda:Del(x))
def generate_price_list():
  v={0:9.95,1: 9.95,2: 9.95,3: 9.95,4: 9.95,5: 12.99,6: 12.99,7: 14.99,8: 17.99,9: 17.99,10: 18,11: 22,12: 23,13: 23,14: 29.99,15: 29.99,16: 34,17: 38,18: 40,19: 40,20: 42,21: 42,22: 45,23: 49,24: 50,25: 54,26: 55,27: 59,28: 60,29: 60,30: 61,31: 62,32: 63,33: 64,34: 68,35: 70,36: 71,37: 71,38: 75,39: 80,40: 82,41: 85,42: 85,43: 85,44: 88,45: 90,46: 90,47: 100,48: 100,49: 100,50: 100}
  v={0:9.99,1: 9.99,2: 9.99,3: 9.99,4: 12.99,5: 12.99,6: 12.99,7: 17.99,8: 17.99,9: 17.99,10: 17.99,11: 24.99,12: 24.99,13: 24.99,14: 24.99,15: 29.99,16: 38,17: 39,18: 40,19: 40,20: 42,21: 42,22: 45,23: 49,24: 50,25: 54,26: 55,27: 59,28: 60,  29: 60,30: 61,31: 62,32: 63,33: 64,34: 68,35: 70,36: 71,37: 71,38: 75,39: 80,40: 82,41: 85,42: 85,43: 85,44: 88,45: 90,46: 90,47: 100,48: 100,49: 100,50: 100}
  ne={}
  for i in lrange(5000):
      q = i/100
      #print(q)
      try:
          low,high = [i for i in v if i < q][-1], [i for i in v if i>q][-0]
          print(low,q,high)
          assert low < q < high
          ne[float(q)] = v[high]
          print(q,v[high])
      except:
          print(q)
  return ne
def get_added_product_urls(x):
  products_sent = x
  products = []
  for i in products_sent:
    x = Filter(Product,title=i.title)
    products.extend(x)
  urls = []
  for i in products:
    x = get_product_url(i)
    urls.append(x)
  urls = oset(urls)
  for i in products:
    print(Filter(Product,title=i.title))
    print(Filter(GhostProduct,title=i.title))
  return urls
def get_all_products_all_shops_created_at_time(x):
  return sum([Shop()(i.shop_abbreviation).pfind(created_at_min=x) for i in Shop.objects.all()],[])
def get_all_custom_collections(shop):
  return flatten(lmap(lambda i: Shop()(shop).shopify.CustomCollection.find(status="any",limit=250,page=i+1),list(range(int(Shop()(shop).shopify.CustomCollection.count()/250)+1))),1)     
def get_handle_from_title(x):
  return re.sub(r"[-]+","-",re.sub(r" ","-","".join(re.findall(r"[0-9a-zA-Z ]",x)).lower()))
def get_logo_size():
  import cv2
  system("rm -rf ~/Desktop/.* &>/dev/null")
  x = lmap(lambda i:int(i),list(cv2.imread(homepath("~/Desktop/%s"%os.listdir(homepath("~/Desktop"))[0])).shape)[:2] )
  # x = lmap(lambda i:int(i/2),list(cv2.imread(homepath("~/Desktop/%s"%os.listdir(homepath("~/Desktop"))[0])).shape)[:2] )
  system("rm -rf ~/Desktop/* &>/dev/null")
  return x
def get_product_video(r):
  ss = Browser()("ch+")
  try:
    ss.get(r,timeout=10)
  except Exception as e:
    redprint(e)
    OSA.notify(str(e))
    return get_product_video(r)
  url = ss.ftn("video",2).get_attribute("src")
  ss.quit()
  return url
def getshopifyproducts(shop,**kwargs):
  if type(shop) is str: shop = Shop()( shop)
  products = sum([shop.shopify.Product.find(status='any',limit=250,page=pg,**kwargs) for pg in range(1,(ceil(shop.shopify.Product.count()/250)+1))],[])
  return products
def handle_captcha(url):
  captcha = OSA.log("Handle captcha", tp = False)
  return captcha
def handle_security_page(ss):
  if "sec.aliexpress.com" in ss.current_url:
    captcha = handle_captcha(url)
    ss.fid("checkcodeInput").send_keys(captcha.get("text"))
    ss.ffs("div","class","submit").click()
    time.sleep(5)
    handle_security_page(ss)
  else:
    redprint("ok")
    return
def productsFeed(shop, created_at_min = 365 * 4  )  :
  shop=((Shop()(shop))if(type(shop)==str)else(shop))
  """
  shop = a_shop()
  created_at_min = 365

  """
  product_count = shop.shopify.Product.count()

  kwargs = dict(  status="any"  ,  created_at_min = datetime.now()-timedelta(days=created_at_min)  ,  limit=250  )

  products =  [AttrDict({ ("shop")if("vendor"==a)else(a):( getattr(shop,"init_shop")if("vendor"==a) else(Date().parse_date(b)) if("created_at"==a) else(b) )    for a,b in x.to_dict().items()  if a not in ["admin_graphql_api_id","image"]}) for x in apilimitcall(lambda:shop.pfind(page=1, **kwargs))]   if ceil( (product_count/250) ) >= 1    else [redprint("1"),[]][1]  +\
              [AttrDict({ ("shop")if("vendor"==a)else(a):( getattr(shop,"init_shop")if("vendor"==a) else(Date().parse_date(b)) if("created_at"==a) else(b) )    for a,b in x.to_dict().items()  if a not in ["admin_graphql_api_id","image"]}) for x in apilimitcall(lambda:shop.pfind(page=2, **kwargs))]   if ceil( (product_count/250) ) >= 2    else [redprint("2"),[]][1]  +\
              [AttrDict({ ("shop")if("vendor"==a)else(a):( getattr(shop,"init_shop")if("vendor"==a) else(Date().parse_date(b)) if("created_at"==a) else(b) )    for a,b in x.to_dict().items()  if a not in ["admin_graphql_api_id","image"]}) for x in apilimitcall(lambda:shop.pfind(page=3, **kwargs))]   if ceil( (product_count/250) ) >= 3    else [redprint("3"),[]][1]  +\
              [AttrDict({ ("shop")if("vendor"==a)else(a):( getattr(shop,"init_shop")if("vendor"==a) else(Date().parse_date(b)) if("created_at"==a) else(b) )    for a,b in x.to_dict().items()  if a not in ["admin_graphql_api_id","image"]}) for x in apilimitcall(lambda:shop.pfind(page=4, **kwargs))]   if ceil( (product_count/250) ) >= 4    else [redprint("4"),[]][1]  +\
              [AttrDict({ ("shop")if("vendor"==a)else(a):( getattr(shop,"init_shop")if("vendor"==a) else(Date().parse_date(b)) if("created_at"==a) else(b) )    for a,b in x.to_dict().items()  if a not in ["admin_graphql_api_id","image"]}) for x in apilimitcall(lambda:shop.pfind(page=5, **kwargs))]   if ceil( (product_count/250) ) >= 5    else [redprint("5"),[]][1]  +\
              [AttrDict({ ("shop")if("vendor"==a)else(a):( getattr(shop,"init_shop")if("vendor"==a) else(Date().parse_date(b)) if("created_at"==a) else(b) )    for a,b in x.to_dict().items()  if a not in ["admin_graphql_api_id","image"]}) for x in apilimitcall(lambda:shop.pfind(page=6, **kwargs))]   if ceil( (product_count/250) ) >= 6    else [redprint("6"),[]][1]  +\
              [AttrDict({ ("shop")if("vendor"==a)else(a):( getattr(shop,"init_shop")if("vendor"==a) else(Date().parse_date(b)) if("created_at"==a) else(b) )    for a,b in x.to_dict().items()  if a not in ["admin_graphql_api_id","image"]}) for x in apilimitcall(lambda:shop.pfind(page=7, **kwargs))]   if ceil( (product_count/250) ) >= 7    else [redprint("7"),[]][1]  +\
              [AttrDict({ ("shop")if("vendor"==a)else(a):( getattr(shop,"init_shop")if("vendor"==a) else(Date().parse_date(b)) if("created_at"==a) else(b) )    for a,b in x.to_dict().items()  if a not in ["admin_graphql_api_id","image"]}) for x in apilimitcall(lambda:shop.pfind(page=8, **kwargs))]   if ceil( (product_count/250) ) >= 8    else [redprint("8"),[]][1]  +\
              [AttrDict({ ("shop")if("vendor"==a)else(a):( getattr(shop,"init_shop")if("vendor"==a) else(Date().parse_date(b)) if("created_at"==a) else(b) )    for a,b in x.to_dict().items()  if a not in ["admin_graphql_api_id","image"]}) for x in apilimitcall(lambda:shop.pfind(page=9, **kwargs))]   if ceil( (product_count/250) ) >= 9    else [redprint("9"),[]][1]  +\
              [AttrDict({ ("shop")if("vendor"==a)else(a):( getattr(shop,"init_shop")if("vendor"==a) else(Date().parse_date(b)) if("created_at"==a) else(b) )    for a,b in x.to_dict().items()  if a not in ["admin_graphql_api_id","image"]}) for x in apilimitcall(lambda:shop.pfind(page=10, **kwargs))]   if ceil( (product_count/250) ) >= 10   else [redprint("10"),[]][1]   
  total_updated = 0
  globalise(0,"errors")
  for x in products:
    if x.id in sud("id",All(Product)):
      try:Get(Product,id=x.id).feed(x)
      except Exception as e:[print(e),globalise(globe("errors")+1,"errors")]
      InceptedProduct().handle_update(x)
      total_updated += 1
    else:
      blueprint("skipping id: %s" % (x.id))
  OSA.notify("ProductsFeed total updated: %s" % (total_updated))
  OSA.notify("ProductsFeed errors: %s" % (errors))
  return products
def productsFeedNonDicts(shop):
  products = sum([shop.shopify.Product.find(status='any',limit=250, page=pg) for pg in range(1,10)],[])
  return products
def proper_title_input(store_abbre):
  title = input("title? (this will return a redirect url as well): ")
  existing_titles = Shop()( store_abbre).shopify.Product.find(title=title)
  if len(existing_titles) > 0:
    print("title exists, ")
    return proper_title_input(store_abbre)
  else:
    print("%s not existing in %s" % (title, store_abbre))

  # ok
  shop = Shop()(store_abbre)
  desired_path = redinput("desired path? (/x-y-z): ")
  path = automatically_generated_handle = "/" + "".join(re.findall(r"[0-9a-zA-Z ]",title)).lower().replace(" ","-").replace("--","-").replace("--","-")
  target = automatically_generated_target = shop.Domain_Name + "/products" + automatically_generated_handle
  x = create_redirect(shop, desired_path, automatically_generated_target)
  redirect_url = x
  return [title, redirect_url]
def remove_extra_note_error_in_image_alt(product):
  # note images need to save individually
  i = product
  if i.image == None:return
  if i.image.alt != None and "Note" in i.image.alt:
    i.image.alt = re.sub("Note.*","",i.image.alt)
    print(i.image.alt)
    i.image.save()
    time.sleep(0.5)

  for j in i.images:
    if j.alt != None and "Note" in j.alt:
      j.alt = re.sub("Note.*","",j.alt)
      j.save()
      time.sleep(0.5)

      print(j.alt)
def rename_product_variants(shop_abbreviation, id_):
  p = Shop()(shop_abbreviation).shopify.Product.find(id_=id_)
  rename_dict = {}
  while True:
    x = input("q\old->new: ")
    if x == "q":
      break
    old, new = x.split("->")
    rename_dict[old] = new
  changed_data = []
  for v in p.variants:
    for old in rename_dict:
      changed = False
      if v.option1 == old:
        v.option1 = rename_dict[old]
        changed = True
        changed_data.append("Hello; changed %s to %s" % (old, rename_dict[old]))
      if v.option2 == old:
        v.option2 = rename_dict[old]
        changed = True
        changed_data.append("Hello; changed %s to %s" % (old, rename_dict[old]))
      if v.option3 == old:
        v.option3 = rename_dict[old]
        changed = True
        changed_data.append("Hello; changed %s to %s" % (old, rename_dict[old]))
      if changed == True:
        v.save()
  print("\n".join(changed_data))
def republish_product(p):
  p.published_at = datetime.now().strftime("%Y-%m-%dT-%HP:%M:%S-04:00")
  assert(True==p.save())
  redprint("set [%s][%s][published_at][%s]"%(p.id,p.handle,p.published_at))
  return p
def save_and_return(x):
  if type(x) != shopify.product.Product:
    x = shopify.product.Product(x)
  distinct_print("[saving product] .. [%s]"%x.save())
  return x
def sort_variants(x):
  option1s = oset(sud("option1",x))
  '''exec("""print(str(x).replace("},","},\\n"))""")'''
  print(option1s)
  new_list = []
  for option in option1s:
    for i in x:
      if i["option1"] == option:
        new_list.append(i)

  option2s = oset(sud("option2",new_list))
  '''exec("""print(str(new_list).replace("},","},\\n"))""")'''
  print(option2s)
  new_list_ = []
  for option in option1s:
    for option_ in option2s:
      for i in new_list:
        if i["option1"] == option:
          if i["option2"] == option_:
            new_list_.append(i)

  if "option3" not in new_list_[0].keys():
    '''exec("""print(str(new_list_).replace("},","},\\n"))""")'''
    return new_list_
  else:
    option3s = oset(sud("option3",new_list))
    '''exec("""print(str(new_list_).replace("},","},\\n"))""")'''
    print(option3s)
    new_list__ = []
    for option in option1s:
      for option_ in option2s:
        for option__ in option3s:
          for i in new_list_:
            if i["option1"] == option:
              if i["option2"] == option_:
                if i["option3"] == option__:
                  new_list__.append(i)
    '''exec("""print(str(new_list__).replace("},","},\\n"))""")'''
    return new_list__
def txt_to_dictlist(txt, headers):
  data = txt.split("\n\n")
  payload = []
  for a in data:
    x = OrderedDict()
    for b, c in zip(a.split("\n"), headers):
      x[c] = b
    payload.append(x)
  return payload
def unpublish_product(p):
  p.published_at = None
  assert(True==p.save())
  redprint("set [%s][%s][published_at][%s]"%(p.id,p.handle,None))
  return p
def unsplash_download(v):
  os.makedirs(homepath("~/Documents/%s"%v), exist_ok=True)
  setitem(globals(),"idx",0)
  address_url_dict = {}
  results = [[setitem(globals(),"fn", homepath("~/Documents/%s/%s_%s.png"%(v,str(globals()["idx"]).zfill(3),v)) ),tryprocess(Images().download,x,fn),redprint(fn),setitem(address_url_dict,fn,x),setitem(globals(),"idx",globals()["idx"]+1),] for x in [x["urls"]["regular"] for x in sum([json.loads(requests.get("https://unsplash.com/napi/search/photos?query=%s&xp=&per_page=20&page=%s"%(v.replace(" ","+"),i)).text)["results"] for i in range(1,1+ceil(int(re.findall(r"([0-9]+) free .*? pictures", requests.get("https://unsplash.com/search/photos/{}".format(k.replace(" ","+"))).text)[0])/20))[:50]], [])]]
  json.dump(address_url_dict, open(homepath("~/Documents/%s/address_url_dict.json"%v), "w"))
class Aliexpress_Products:
  def __init__(self):
    self.rq = Aliexpress_Requests()()
  def get_product_data(self, url,check_for_epacket=False):
    x = AD(data = None, shipping = None, y = None)
    count_of_soups = Filter(Soup,url=url).len()
    time_elapsed = or_list(lambda: (Date().Now()-Get(Soup,url=url).last_check).total_seconds(), None)

    TO_REFRESH_SOUP = False

    assert count_of_soups > 0

    if time_elapsed > (86400*2):
      TO_REFRESH_SOUP = True


    if TO_REFRESH_SOUP == True:
      Push(Soup,url=url)(page_source=self.rq.get(url).text,is_available=True,last_check=Date().Now())



    soup = SOUP(Get(Soup,url=url).page_source)

    if not soup.text and TO_REFRESH_SOUP == False:
      print("Not Found")
      x.data = str(soup)
      x.y = "Not Found"
      return x


    item_not_found = None
    if len(soup.findAll("div",attrs={"class":"item-not-found-title"})):
      item_not_found = True
    if "Page Not Found" in soup.findAll("title")[0].text:
      item_not_found = True
    aliexpressvendor = or_list(tryreturn(lambda:"https:%s" % list(soup.findAll("span",attrs={"class":"shop-name"})[0])[1].attrs["href"])  ,  tryreturn(lambda:"https:%s" % list(soup.findAll("span",attrs={"class":"shop-name"})[0])[0].findAll("a")[0].attrs["href"])  ,  tryreturn(lambda:"https://aliexpress.com/store/%s"%(findall(Get(Soup,url=url).page_source,1,'(?s)window.runParams.*"storeNum":(\d+)')))  ,  None)

    if item_not_found:
      x.y = "Not Found"

    if aliexpressvendor == None:
      x.y = "Not Found"

    shipping = None
    if x.y != "Not Found":
      shipping = json.loads(findall(requests.get("https://freight.aliexpress.com/ajaxFreightCalculateService.htm?&f=d&productid={}&currencyCode=USD&transactionCurrencyCode=USD&sendGoodsCountry=&country=US&province=&city=&abVersion=1".format(int(findall(findall(Get(Soup,url=url).page_source,1,'(?s)window.runParams.*productIds: "(.*?)"'),1,".*?(\d+)")))).text,1,"{.*}"))["freight"]

      if check_for_epacket:
        if "ePacket" not in key("companyDisplayName",shipping):
          x.y = "No ePacket"

    x.data = str(soup)
    x.shipping = shipping
    return x
class Posts:
  def start(self,shop):
    products = Filter(Product,shop=shop)
    for i in products:
      create_directories(i.shop,i.product_type,i.handle)
      os.chdir("/".join([i.shop,i.product_type,i.handle]))
      self.run(int(findall(i.ali_url,1,"(\d+)\.html")))
      os.chdir("/".join([".."]*3))
  def run(self,product_id):
    x = []
    page_number = 1
    url = "https://feedback.aliexpress.com/display/productEvaluation.htm"
    data = {'companyId':'','currentPage':'1','evaSortValue':'sortdefault@feedback','evaStarFilterValue':'all Stars','i18n':'true','isOpened':'true','jumpToTop':'false','memberType':'seller','onlyFromMyCountry':'false','ownerMemberId':'229975677','page':'1','productId':'32924594152','startValidDate':'','translate':' Y ','v':'2','version':'','withAdditionalFeedback':'false','withPersonalInfo':'false','withPictures':'true'}
    headers = {'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8','accept-encoding':'gzip, deflate, br','accept-language':'en-US,en;q=0.9','authority':'feedback.aliexpress.com','cache-control':'max-age=0','content-length':'334','content-type':'application/x-www-form-urlencoded','method':'POST','origin':'https://feedback.aliexpress.com','path':'/display/productEvaluation.htm','referer':'https://feedback.aliexpress.com/display/productEvaluation.htm','scheme':'https','upgrade-insecure-requests':'1','user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
    data["productId"] = str(product_id)
    data['page'] = str(page_number)
    r = requests.post(url,headers=headers,data=data)
    images = BeautifulSoup(r.text).findAll("img")
    page_numbers = listminus(lmap(lambda i:tryreturn(lambda:int(i)),sud("text",BeautifulSoup(r.text).findAll("a",attrs={"class":"ui-goto-page"}))),0)
    x.append(images)
    if page_number+1 in page_numbers:
      while True:
        page_number = page_number + 1
        url = "https://feedback.aliexpress.com/display/productEvaluation.htm"
        data = {'companyId':'','currentPage':'1','evaSortValue':'sortdefault@feedback','evaStarFilterValue':'all Stars','i18n':'true','isOpened':'true','jumpToTop':'false','memberType':'seller','onlyFromMyCountry':'false','ownerMemberId':'229975677','page':'1','productId':'32924594152','startValidDate':'','translate':' Y ','v':'2','version':'','withAdditionalFeedback':'false','withPersonalInfo':'false','withPictures':'true'}
        headers = {'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8','accept-encoding':'gzip, deflate, br','accept-language':'en-US,en;q=0.9','authority':'feedback.aliexpress.com','cache-control':'max-age=0','content-length':'334','content-type':'application/x-www-form-urlencoded','method':'POST','origin':'https://feedback.aliexpress.com','path':'/display/productEvaluation.htm','referer':'https://feedback.aliexpress.com/display/productEvaluation.htm','scheme':'https','upgrade-insecure-requests':'1','user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
        data["productId"] = str(product_id)
        data['page'] = str(page_number)
        r = requests.post(url,headers=headers,data=data)
        images = BeautifulSoup(r.text).findAll("img")
        page_numbers = listminus(lmap(lambda i:tryreturn(lambda:int(i)),sud("text",BeautifulSoup(r.text).findAll("a",attrs={"class":"ui-goto-page"}))),0)
        x.append(images)
        if page_number+1 not in page_numbers:
          break

    pool(lambda idx,i:Images().download(i,"%s.jpg"%(idx)),lrange(len(flatten(x,1))),lmap(lambda i:i.attrs["src"],flatten(x,1))).result()
    print("+1, %s" % (len(flatten(x,1))))
class ProductTroubleshoot:
  def remove_int_handles(self,shop):
    x=getshopifyproducts(shop)
    for i in x:
      y = i.handle[-1]
      if tryprocess(lambda i:int(y)):
        i.destroy()
  def migrate_shop_add_new_shop_object(self):
    All(Shop)[2:]
    shops = All(Shop)[2:]
    uniq = ["id","shop_abbreviation"]
    s = All(Shop)[0]
    for shop in shops:
      for field in Shop._meta.fields:
        if field.name not in uniq:
          setattr(shop,field.name,getattr(s,field.name))
          print(field.name,getattr(s,field.name))
          shop.save()
  def update_shops(self,shop1,shop2):
    Filter(AceInTheHole,shop=shop1).update(shop=shop2) #
    Filter(AceInTheHoleHeaderColumns,shop=shop1).update(shop=shop2) #
    Filter(AddProduct,shop=shop1).update(shop=shop2) #
    Filter(Adset,shop_abbreviation=shop1).update(shop_abbreviation=shop2)
    Filter(Adsethourlyinsightdata,shop_abbreviation=shop1).update(shop_abbreviation=shop2)
    Filter(Aliexpress_Dispute,shop=shop1).update(shop=shop2)
    Filter(Aliexpress_Dispute,store=shop1).update(store=shop2)
    Filter(Aliexpressorder_event,shop=shop1).update(shop=shop2)
    Filter(Aliexpressorder_update,shop=shop1).update(shop=shop2)
    Filter(ApprovedTransaction,shop=shop1).update(shop=shop2) #
    Filter(GhostProduct,shop=shop1).update(shop=shop2)
    Filter(GhostProductUpdate,shop=shop1).update(shop=shop2)
    Filter(Handle,shop=shop1).update(shop=shop2)
    Filter(InceptedProduct,shop=shop1).update(shop=shop2)
    Filter(Keep_Exchange,shop=shop1).update(shop=shop2) #
    Filter(Lineitem,shop=shop1).update(shop=shop2)
    Filter(LineitemsFeed,shop=shop1).update(shop=shop2)
    Filter(Muta,current_shop=shop1).update(current_shop=shop2) #
    Filter(Muta,store_abbre=shop1).update(store_abbre=shop2) #
    Filter(New_Email,shop=shop1).update(shop=shop2)
    Filter(New_Email_Template,shop=shop1).update(shop=shop2)
    Filter(Order,shop=shop1).update(shop=shop2)
    Filter(Payment,shop=shop1).update(shop=shop2)
    Filter(Payout,shop=shop1).update(shop=shop2)
    Filter(PriceChange,shop=shop1).update(shop=shop2) #
    Filter(Product,shop=shop1).update(shop=shop2)
    Filter(ProductsFeed,shop=shop1).update(shop=shop2)
    Filter(ProductTalk,shop=shop1).update(shop=shop2)
    Filter(ReOrder,shop=shop1).update(shop=shop2)
    Filter(ScienceVessel,shop=shop1).update(shop=shop2)
    Filter(Settlement,shop=shop1).update(shop=shop2)
    Filter(StatusVerification,shop=shop1).update(shop=shop2)
    Filter(Subscription,shop=shop1).update(shop=shop2)
    Filter(TertiaryAction,shop=shop1).update(shop=shop2)
    Filter(TertiaryAction_Template,shop=shop1).update(shop=shop2)
    Filter(UniqueProductIdentifier,shop=shop1).update(shop=shop2)
class ShippingCost:
  def get_shipping_cost(self,x,shop):
    sorted_companies_list = ifelseget(lambda:Shop()(shop).Allow_Additional_Shipping_Methods,lambda:["SunYou Economic Air Mail","Yanwen Economic Air Mail","China Air Post","China Post Registered Air Mail","ePacket","AliExpress Standard Shipping"],lambda:["ePacket"])
    data = sorted([new_dict(i,["companyDisplayName","price"]) for i in x if i.companyDisplayName in sorted_companies_list],key=lambda i:sorted_companies_list.index(i.companyDisplayName))
    return flt(data[0].price)
  def get_shipping_company(self,x,shop):
    sorted_companies_list = ifelseget(lambda:Shop()(shop).Allow_Additional_Shipping_Methods,lambda:["SunYou Economic Air Mail","Yanwen Economic Air Mail","China Air Post","China Post Registered Air Mail","ePacket","AliExpress Standard Shipping"],lambda:["ePacket"])
    data = sorted([new_dict(i,["companyDisplayName","price"]) for i in x if i.companyDisplayName in sorted_companies_list],key=lambda i:sorted_companies_list.index(i.companyDisplayName))
    return data[0].companyDisplayName
class Variant_Titler:
  def title_variant(self,x):
    products = getshopifyproducts("rom",created_at_min=datetime(2020, 1, 19, 23, 8, 13))
    option_names = []
    for i in products:
      for j in i.variants:
        option_names.append(j.option1)
        option_names.append(j.option2)
        option_names.append(j.option3)
    option_names = sorted(oset(listminus(option_names,None)))
    option_names = lmap(lambda i:re_found_function(i,"(?i)^asian",lambda i:re_substitute(i,["(?i)^asian",""]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)cm",lambda i:re_substitute(re_substitute_function(i,"[\d\.]+",lambda i:or_list(lambda:list_and(lambda:str(round(flt(i)/2.54,1)).endswith(".0"),lambda:str(int(round(flt(i)/2.54,1)))),lambda:str(round(flt(i)/2.54,1)))),["(?i)cm","cm"])  ),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)^For",lambda i:re_substitute(i,["(?i)^For",""]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)iPhone",lambda i:re_substitute(i,["(?i)iPhone","iPhone"]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)Style",lambda i:i),option_names)
    option_names = lmap(lambda i:re_found_function(i," {2,}",lambda i:re_substitute(i,[" {2,}"," "])),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)eu size",lambda i:re_substitute(i,["(?i)eu size",""]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)^Size[- ]",lambda i:re_substitute(i,["(?i)^Size[- ]",""]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)(^A\d+)",lambda i:re_substitute(i,["(?i)(^A\d+)","Samsung \\1"]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)(^J\d+)",lambda i:re_substitute(i,["(?i)(^J\d+)","Samsung \\1"]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)(^P\d+)",lambda i:re_substitute(i,["(?i)(^P\d+)","Huawei \\1"]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)^Galaxy",lambda i:re_substitute(re_substitute(i,["(?i)^Galaxy","Samsung Galaxy"]),["Samsung Galaxy","Samsung"]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)(^P Smart)",lambda i:re_substitute(i,["(?i)(^P Smart)","Huawei \\1"]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)(\d+)Xl",lambda i:re_substitute(i,["(?i)(\d+)Xl","\\1XL"]).strip()),option_names)
    option_names = lmap(lambda i:re_found_function(i,"(?i)((?:^Xl$|^Xs$))",lambda i:re_substitute(i,["(?i)((?:^Xl$|^Xs$))","\\1"]).upper()),option_names)

    option_names = sorted(oset(option_names))
  def run(self):
    products = getshopifyproducts("rom",created_at_min=datetime(2020, 1, 19, 23, 8, 13))
    for a in products:
      for b in a.variants:
        for c in [1,2,3]:
          if getattr(b,"option%s"%(c)) != None:
            old = getattr(b,"option%s"%(c))
            setattr(b,"option%s"%(c),adjustvariantname(getattr(b,"option%s"%c)))
            print(old, getattr(b,"option%s"%(c)))
      pool(lambda:apilimitcall(a.save))
      time.sleep(1)
class Product_Manager:
  def __init__(self, sleeptime = 3600 * 3):
    Aliexpress_Products().refresh_product_inventories()
    blueprint("[sleeping][%s]"%sleeptime)
    time.sleep(sleeptime)
    self.__init__(sleeptime)
class Product_Unpender:
  def __init__(self):
    strand( Aliexpress_Products().create_product )
  class Product_Handles:
    # Basically, it shows the day's sales for all shops, as well and if clicked, shows the adsets.
    def __init__(self):
      import rumps
      from rumps import MenuItem as M
      from rumps import MenuItem
      self.app = rumps.App("Product_Handles",quit_button=Null)
      globals().update(locals())


      self.set_menu()
      #process(  lambda: [time.sleep(6.15), self.set_menu()]  )
      time.sleep(4)
      self.app.run()


    def set_menu(self):
      keys = list(self.app.menu.keys())
      redprint(keys)
      for i in keys:
        self.app.menu.pop(i)
      keycall("Icon",All(Adset))
      self.app.menu = [MenuItem("/",callback=lambda _=None:[])]+[
                        MenuItem("") for i in All(Handle)
                      ]
  class ProductUpdates:
    def run(self,shop):
      for i in Filter(Product,shop=shop):
        i.Refresh()
  def create_products_via_csv(infile):
    data = CSV().DictRead(infile)
    [Aliexpress(c=20, verbose=False).create_product(**row) for row in data[350:]]
    affix_product_descriptions()
  def sort_collections():
    pass
  def theme():
    @timedtask
    def theme():
      os.system("/Applications/Google\ Chrome\ 70.app/Contents/MacOS/Google\ Chrome &")
      os.system("/Applications/Adobe\ Photoshop\ CC\ 2018/Adobe\ Photoshop\ CC\ 2018.app/Contents/MacOS/Adobe\ Photoshop\ CC\ 2018 &")
      redinput(" Theme -- ")
  def unpend_orders():
    Order_Unpender().unpend_orders()
  class eCommerce_Item_Enlivener(DecisionTree):
    def wordcount(self, x):
      apostrophes = x.count("'")
      words = len(x.split(" "))
      count = apostrophes + words
      return count
    def wordcount_by_productIds(self, x, shop):
      return [eCommerce_Item_Enlivener().wordcount(Shop()(shop).pfind(id_=i).body_html) for i in x]
    def format_products_feed1(self, shop):
      x = [i.split("/")[-1] for i in get_all_chrome_urls() if "/products/" in i]
      x = [Shop()( shop).pfind(handle=i)[0] for i in x]
      [[setattr(i,"body_html",""),i.save()] for i in x]
      y = ""
      y += "\n"
      for i in x:
        y += "url: " + "https://"+Shop()(shop).Shopify_App_API_Url.split("@")[1]+"/products/%s"%i.id
        y += "\n"
        y += "words: "
        y += "\n"
        y += "\n"
      with open(homepath("~/tavern/tavern/bag/%s"%datetime.now().strftime("%m_%d_%Y_set.txt")), "w") as f:
        f.write(y)
    def format_products_feed(self, io=None):
      io = get_all_chrome_urls() if(None==io) else io
      y = ""
      y += "\n"
      data = []
      if(type(io[0]) == str):
        for i in io:
          SHOP = Get(Shop,Domain_Name__icontains=re.findall("[a-zA-Z]+.com",i)[0])
          p = Shop()( SHOP.shop_abbreviation  ).pfind(handle=i.split("/")[-1])[0]
          data.append(p)
      else:
        data = io


      for p in data:
        SHOP = Shop()(Get(Shop,Business_Name=p.vendor).shop_abbreviation)
        p.body_html = ""; p.save()
        y += "url: " + "https://"+SHOP.Shopify_App_API_Url.split("@")[1]+"/products/%s"%p.id
        y += "\n"
        y += "words: "
        y += "\n"
        y += "\n"
      with open(homepath("~/tavern/tavern/bag/%s"%datetime.now().strftime("%m_%d_%Y_set.txt")), "w") as f:
        f.write(y)
    def read(self):
      address = input("address?: ")
      shop = input("shop?: ")
      wordsum = sum(     [int(i) for i in re.findall("[\n ]([0-9][0-9])[\n ]",open(address).read()+"\n")]      )
      productIds = [int(i) for i in re.findall("[/]([0-9][0-9][0-9][0-9]+)[\n ]",open(address).read()+"\n")]
      wordcount = eCommerce_Item_Enlivener().wordcount_by_productIds(productIds, shop = shop)
      redprint("wordsum: %s" % wordsum, "wordcount: %s" % wordcount, "productIds: %s" % productIds)
def a_shop():
  return Shop()(All(Shop)[0].shop_abbreviation)




""" Business-Utils-Order-Utils """
def aliexpress_dialog_box_adjust_city(city):
  city = city.upper()
  
  if "ST." in city:
    redprint("ST. in %s, replacing ST. with SAINT" % (city))
    city = city.replace("ST.", "SAINT")

  city = city.replace("'", "")
    
 
  city = city.capitalize()
  return city
def alitracker(*args):
  print(args)
  order = Get(Order,order_number=int(args[1]))
  x = Filter(Lineitem,shop=args[0],order_id=order.id)
  if x:
    return Get(Lineitem,shop=args[0],order_id=order.id).ali_tracking_number
  else:
    return "Unable to get tracking number for order number %s in %s. It is not available yet." % (args[1],args[0])
def calculate_average_shipping_time():
  x = Lineitem.objects.filter(~Q(ali_tracking_number=None))
  keycall("get_tracking_events",x)
  no_data = [i for i in x if i == None]
  delivered = [i for i in x if i != None and "DELIVERED" in i.events()[-1].upper()]
  delivering = [i for i in x if i != None and "DELIVERED" not in i.events()[-1].upper()]
  assert len(delivered) + len(delivering) + len(no_data) == len(x)

  average_delivered_times = [(i.events()[-1].date()-i.events()[0].date()).days+(((i.events()[-1].date()-i.events()[0].date())).seconds/(24*60*60)) for i in delivered]
  average_delivered_time_days = tryreturn(lambda:sum(average_delivered_times)/len(average_delivered_times))
  average_delivered_time_business_days = average_delivered_time_days * (5/7)
  average_delivered_time = average_delivered_time_business_days
  average_delivered_times = [round(i,2) for i in average_delivered_times]

  average_delivering_times = [(i.events()[-1].date()-i.events()[0].date()).days+(((i.events()[-1].date()-i.events()[0].date())).seconds/(24*60*60)) for i in delivering]
  average_delivering_time_days = tryreturn(lambda:sum(average_delivering_times)/len(average_delivering_times))
  average_delivering_time_business_days = average_delivering_time_days * (5/7)
  average_delivering_time = average_delivering_time_business_days
  average_delivering_times = [round(i,2) for i in average_delivering_times]

  distinct_print(ordered_json_dumps({a:b for a,b in locals().items() if "average" in a}))
def lineitemsFeed(shop, date_range=36):
  shop=((Shop()(shop))if(type(shop)==str)else(shop))
  ordersFeed(shop, date_range=date_range)
  # oken orders should be already deleted by then now.

  x = 0
  for order in Order.objects.filter(shop=shop.shop_abbreviation):

    for lineitem in order.line_items:
      lineitem = AttrDict(lineitem) #
      new = Lineitem()


      existing = Lineitem.objects.filter(id=lineitem.id)
      if len(existing) != 0:
        new = existing[0]

      # [shop, order, lineitem]
      new.shop = shop.shop_abbreviation; #print("abbre: %s" % shop.shop_abbreviation)
      new.financial_status = order.financial_status
      new.id = lineitem.id
      new.variant_id = lineitem.variant_id
      
      #if "product_id" not in new.__dict__.keys():
      #  greenprint("product id is not inside existing lineitem __dict__ keys. add it in.")
      try:
        int(new.product_id)
      except Exception as e:
        magentaprint("[disregard [lineitem.product deleted]] Error, %s [setting a new product_id [%s] for line_item %s] -- [lineitem.product_id == None, lineitem.product deleted]"%(e,lineitem.product_id,lineitem.id))
        new.product_id = lineitem.product_id
      #else:
      #  redprint("product id is inside existing lineitem __dict__ keys. not add it in.")
      new.order_id = order.id
      new.quantity = lineitem.quantity
      new.grams = lineitem.grams
      new.fulfillment_tracking_numbers = []
      new.date = order.date
      new.created_at = order.created_at

      if new.created_at < Shop()(shop.shop_abbreviation).Lineitem_Most_Recent_Date:
        continue

      for i in order.fulfillments:
        for j in i["line_items"]:
          if j["id"] == lineitem.id:
            #try:
            new.fulfillment_id = i["id"]
            tracking_numbers =  i.get("tracking_numbers", None)
            if tracking_numbers != None:
              new.fulfillment_tracking_numbers.extend(tracking_numbers)
            #except:
            #  return j

      new.fulfillment_service = lineitem.fulfillment_service # [added 4/21/19]
      new.fulfillment_status = lineitem.fulfillment_status
      new.variant_title = lineitem.variant_title
      new.title = lineitem.title
      new.sku = lineitem.sku
      #if order.total_line_items_price == None:
      #  new.price = order.total_price
      #else:
      #  evened_shipping_price = ((float(order.total_price) - order.total_line_items_price) / len(order.line_items)) #Calculate Shipprice via Total-price-lineitemsprice and Divide that by # lineitems.
      #  old = float(lineitem.price)
      #  new.price = float(lineitem.price) + evened_shipping_price
      #  print(order.id, 'old: ', old, evened_shipping_price, "new with even, %s" % new.price)
      new.price = float(lineitem.price) + ((float(order.total_price) - order.total_line_items_price) / len(order.line_items)) if order.total_line_items_price != None else order.total_price
      # new.ali_price              (nothingtodohere)
      # new.ali_tracking_number    (nothingtodohere)
      # new.ali_tracking_method    (nothingtodohere)
      # new.ali_order_number       (nothingtodohere) 
      new.shipping_address = order.shipping_address
      # new.e2 # time between fulfillment and tracking number post
      # new.e1 # time between orderplacement and fulfillment
      # new.t3 # time tracking number posts
      # new.t2 # time fulfilled
      new.t1 = Date().myDatetimenow(order.created_at)  # (TypeError: can't subtract offset-naive and offset-aware datetimes)
                                    # datetime.datetime(2018, 3, 4, 6, 49, 19, tzinfo=tzoffset(None, -18000))
      new.save()
      #print( " saving: %s " % new.save() )
      x += 1
  OSA.notify(str(x))
  # lineitemsFeed(a_shop())
def onyx(e=None):
  # lmao, this also works.
  return onyx_lineitems(e)
def onyx_lineitems(e=None):
  # lmao, this also works.
  x = All(Lineitem)
  data = []
  for i in x:
    to_add = True
    if i.financial_status == "refunded":
      to_add = False
    if i.fulfillment_status == "unfulfilled":
      to_add = False
    if i.fulfillment_status == None:
      to_add = False
    if to_add == True:
      assert i.fulfillment_status in ["partial"] or i.fulfillment_status in ["fulfilled"]
    if to_add == True:
      data.append(i)

  not_refunded = Filter(Lineitem,(~Q(financial_status="refunded")))
  if e == None:
    return data
  elif e == "e1":
    return [i for i in not_refunded if i.t1 and not i.t2] # not_refunded because this is for ... not refunded. so, leftover is to-go. w/means partial/fulfilled can't be. so must be: unfulfilled. but, include partial/fulfilled, just in case.
  elif e == "e2":
    return [i for i in data if i.t2 and not i.t3]
  elif e == "e3":
    return [i for i in data if i.t3 and not i.t4]
  elif e == "e4":
    return [i for i in data if i.t4]
def onyx_orders():
  not_refunded = Filter(Order,(~Q(financial_status="refunded")))
  partially_fulfilled = not_refunded.filter(fulfillment_status="partial")
  fulfilled = not_refunded.filter(fulfillment_status="fulfilled")
  W = list(partially_fulfilled) + list(fulfilled)
  redprint("ONYX ORDERS REIGNED %s ORDERS" % len(W))
  return W
def ordersCreate():
  print("ordersCreating...")
def ordersFeed(shop, date_range=36):
  shop=((Shop()(shop))if(type(shop)==str)else(shop))
  print("Setting Orders in last %s days"%date_range)
  orders = sum([shop.shopify.Order.find(status='any',limit=250, page=pg, created_at_min=Date().dt(-1 * date_range,'%Y-%m-%d')) for pg in range(1, 1+ceil(shop.shopify.Order.count(created_at_min=(Date()-date_range).dateobj )  /250)) ],[])
  payload = []
  for i in orders:
    x = i.to_dict()
    x["created_at"] = Date().parse_date(x["created_at"]).replace(tzinfo=None)
    x['date'] = x["created_at"].date()
    x['shop'] = shop.init_shop
    x["billing_address_contact_name"] = "%s %s"%(x["billing_address"]["first_name"],x["billing_address"]["last_name"])
    if x['fulfillment_status'] is None:
      x['fulfillment_status'] = 'null'
    x["line_items"] = [{f:r[f] for f in ["fulfillment_service","fulfillment_status","gift_card","grams","id","name","price","product_exists","product_id","quantity","sku","title","total_discount","total_discount_set","variant_id","variant_inventory_management","variant_title",]} for r in x["line_items"]]
    SecondaryAction().take_from_order(x)
    payload.append(x)

    Order.objects.update_or_create(**x)
  # I cancelled an order that was a test to myself, so It could not be filtered. manually delete it.
  return payload
def ordersTrack():
  print("...summoning ordersTrack...")
  payload = []
  for i in range(10):
    data = {}
    payload.append(data)
  print("orders_tracking_core payload: %s"%payload)
  return payload
def query_google_tracking_urls(tracking_number):
  return re.findall(r'http.*?"',requests.get("https://www.google.com/async/lrfapt?ei=2grpW47TMKza5gKd16vIAg&yv=3&async=lrfsb:{},_id:lrf-pt-async,_pms:s,_fmt:pc".format(tracking_number)).text)
def similarimagesCreate():
  print("similarimagesCreating...")
  # exec(boot_django)
def test_variant_names():
  return chromejs("x = document.getElementsByClassName('sku-property-list'); y = x.length; var a = []; for (i=0;i<y;i++) { z = x[i].getElementsByTagName('img'); if(z.length > 0){a.push(...z)}; b = x[i].getElementsByClassName('sku-property-text'); if (b.length > 0) {a.push(...b)}  } ; a; c = []; e = a.length; for (i=0;i<e;i++) {if(a[i].title) {c = c.concat(a[i].title)}; if(a[i].textContent) {c = c.concat(a[i].textContent)} }; c")
def update_address():
  shop, order_number = dune(OSA.log("Shop abbreviation and order number to update an address for [separated by ', ', for example: 'xyz, 1001']?").split(", "),[lambda i: i,lambda i:int(i)])
  name, address1, address2, city, state, zip_code = None, None, None, None, None, None
  x = OSA.log("Updated shipping address [For example: Adam Watson, 123 A St, Address Line 2 (optional), City A, State, Zip Code]?").split(", ")
  if len(x) == 6:
    name, address1, address2, city, state, zip_code = x
  elif len(x) == 5:
    name, address1, city, state, zip_code = x

  updated_shipping_address = {"name":name,"address1":address1,"address2":address2,"city":city,"province":state,"zip_code":zip_code}

  order = Get(Order,shop=shop,order_number=order_number)
  lineitems = Filter(Lineitem,order_id=order.id)
  lmap(lambda i: Update(i, updated_shipping_address = updated_shipping_address), lineitems)

  updated_shipping_addresses = key("updated_shipping_address",lineitems)
  updated_shipping_addresses_x = oset(updated_shipping_addresses)
  assert len(updated_shipping_addresses_x) == 1
  updated_shipping_address_x = updated_shipping_addresses_x[0]
  if updated_shipping_address_x["address2"] != None:
    OSA.log("Updated shipping address:\n%s, %s, %s, %s, %s, %s"%(updated_shipping_address_x["name"], updated_shipping_address_x["address1"], updated_shipping_address_x["address2"], updated_shipping_address_x["city"], updated_shipping_address_x["province"], updated_shipping_address_x["zip_code"]),tp=False)
  elif updated_shipping_address_x["address2"] == None:
    OSA.log("Updated shipping address:\n%s, %s, %s, %s, %s"%(updated_shipping_address_x["name"], updated_shipping_address_x["address1"], updated_shipping_address_x["city"], updated_shipping_address_x["province"], updated_shipping_address_x["zip_code"]),tp=False)
def verification_slider(self):
  try:
    count_of_verification_slider_elements = self.ss.ffss("label","for","fm-login-checkcode")
    if len(count_of_verification_slider_elements) == 1:
      ##
      def move_verification_slider(x1=431, x2=574, y1=273, signin_x1=571, signin_y1=304):
        print("Found verification slider.")
        OSA("Firefox")
        self.ss.zoom_out()
        self.ss.zoom_in(1)
        zz(2)
        os.system("~/tavern/tavern/.MouseTools -x %s -y %s; sleep 1" % (x1, y1))
        os.system("~/tavern/tavern/.MouseTools -x %s -y %s; sleep 0" % (x1, y1))
        os.system("~/tavern/tavern/.MouseTools -doubleLeftClick; sleep 2")
        os.system("~/tavern/tavern/.MouseTools -leftClickNoRelease; sleep 0.5")
        os.system("~/tavern/tavern/.MouseTools -x %s -y %s; sleep 1" % (x2, y1))
        os.system("~/tavern/tavern/.MouseTools -releaseMouse; sleep 0.2")
        os.system("~/tavern/tavern/.MouseTools -leftClick; sleep 2")
        os.system("~/tavern/tavern/.MouseTools -x %s -y %s; sleep 0" % (x1+15, y1))
        os.system("~/tavern/tavern/.MouseTools -leftClick; sleep 2")
  
        OSA("Firefox")
        self.ss.find_element_by_name("password").clear()
        self.ss.find_element_by_name("password").send_keys(password)
        OSA("Firefox", ["return"])
        zz(10)
        self.ss.refresh()
        try:
          self.ss.switch_to_frame("alibaba-login-box")
          self.ss.find_element_by_name("loginId").clear()
          self.ss.find_element_by_name("loginId").send_keys(username)
          self.ss.find_element_by_name("password").send_keys(password)
          self.ss.find_element_by_name("submit-btn").send_keys(self.ss.Keys.ENTER)
        except Exception as e:
          print("error: %s" % e)
        zz(15)
      move_verification_slider()
      ##
  except Exception as e:
    print("No slider.")
class Aliexpress_Requests:
  def __init__(self,window_index=[0,0,3.5,3.5],ph=True,exit_browser=True):
    setattrs(self,"ph",ph,"exit_browser",exit_browser,"window_index",window_index,"headers",session_headers,"username",Get(Shop,shop_abbreviation=Muta()().store_abbre).AliExpress_Email,"password",Get(Shop,shop_abbreviation=Muta()().store_abbre).AliExpress_Password,)
    if(tryreturn(lambda: cookies_to_session(cookies_to_database(self.username, "AliExpress"), requests.Session()).get("https://trade.aliexpress.com/orderList.htm",headers=session_headers).url.find("aliexpress.com/orderList.htm"))>0):
      tryprocess(lambda: cookies_to_database(username=self.username,website_name="AliExpress",cookies=self.ss.get_cookies(),reverse=False))
      self.rq = cookies_to_session(cookies_to_database(self.username, "AliExpress"), requests.Session())
      self.rq.headers = session_headers
      return
    else:
      self.ss = Browser()( ("ch+"if(True==self.ph)else("sele")) ).get("https://login.aliexpress.com/").sp(5).tp(lambda:globe("ss_v").frame("alibaba-login-box")).bat().fid("fm-login-id").fid("fm-login-password").fcn("password-login").bat(self.username,self.password,globe("ss_v").SHADOW.ENTER).sp(10).tp(lambda: cookies_to_database(username=self.username,website_name="AliExpress",cookies=globe("ss_v").get_cookies(),reverse=False)).tp(lambda:setattr(self,"rq",cookies_to_session(cookies_to_database(self.username,"AliExpress"),requests.Session()))).tp(lambda:globe("ss_v").quit()if(self.exit_browser)else())
      self.__init__(window_index=window_index,ph=ph,exit_browser=exit_browser)
  def __call__(self):
    return self.rq
class Aliexpressorderpager:
  def get_urls(self, x1, x2, get_order_info = True):
    # x1,x2,get_order_info=(Date()-15)(),(Date()-0)(),False

    session = Aliexpress_Requests()()
    r = session.get("https://trade.aliexpress.com/orderList.htm")
    if r.status_code != 200: OSA.log("Error in requesting Aliexpress orders. Some things that can cause this is using a vpn or a using a vps. Please make sure your password is correct as well")
    soup = tryreturn(lambda:BeautifulSoup(Replacements(r.content.decode(),"\n", "", "\r", "", "\t", ""), "lxml"))
    if soup == 0: OSA.log("Error in requesting Aliexpress orders. Some things that can cause this is using a vpn or a using a vps. Please make sure your password is correct as well")
    m_page = (or_list(lambda:[int(i.text) for i in soup.findAll(attrs={"class": "ui-goto-page"})[::-1] if i.text.isdigit()][0],0)) + 1
    print('max ', m_page)
    for page in range(0, m_page):
      _csrf_input = soup.find(attrs={"name": '_csrf_token'})
      if _csrf_input == None:
        return
      csrf = _csrf_input.attrs["value"]

      if a_shop().AliExpress_Most_Recent_Date > x1:
        x1 = Date(a_shop().AliExpress_Most_Recent_Date)
      if a_shop().AliExpress_Most_Recent_Date > x2:
        x2 = Date(a_shop().AliExpress_Most_Recent_Date)

      query = {
        "action": "OrderListAction",
        "eventSubmitDoPage": "doPage",
        "_fm.o._0.s":(x1).strftime("%m/%d/%Y"),
        "_fm.o._0.e":(x2).strftime("%m/%d/%Y"),
        "_fm.o._0.cu": page,
        "pageNum": page + 1,
        "_csrf_token": csrf}
      print("Wait...")
      time.sleep(2)
      r = session.post("https://trade.aliexpress.com/orderList.htm", data=query)
      if r.status_code != 200: OSA.log("error in requesting Aliexpress orders. Some things that can cause this is using a vpn or a using a vps. Please make sure your password is correct as well")

      soup = BeautifulSoup(Replacements(r.content.decode(),"\n", "", "\r", "", "\t", ""), "lxml")
      order_ids = lmap(lambda i: int(findall(i.attrs["href"],"orderId=(.*)")[0]), soup.findAll(attrs={"class": "view-detail-link"}))
      order_times = [Date().myDatetimenow(Date().parse_date(i.text)) for i in soup.findAll("span", attrs={"class":"info-body"}) if tryprocess(lambda: Date().parse_date(i.text)) == 1]
      print("len order ids: %s" % len(order_ids))
      print("Get order list Success, current page is %s" % (page + 1))
      links = soup.findAll(attrs={"class": "view-detail-link"})
      exec(subtract)
      # AliExpress_Account_Order_Scan_Earliest_Date
      lmap(lambda i: Push(Aliexpressorder,id=i[0])(order_time=i[1]) , list(zip(order_ids,order_times)))
      if len(order_ids) == 0:
        return
      if get_order_info == True:
        for order_id, order_time in zip(order_ids, order_times):
          pool(lambda:Aliexpressorder().order_info(order_id, order_time))
          time.sleep(1)

    """ 'x1 = Date()-400\nx2 = Date() - 0\nget_order_info = True\nr = Aliexpress_Requests()().get("https://trade.aliexpress.com/orderList.htm")\nif r.status_code != 200: OSA.log("Error in requesting Aliexpress orders. Some things that can cause this is using a vpn or a using a vps. Please make sure your password is correct as well")\nsoup = tryreturn(lambda:BeautifulSoup(Replacements(r.content.decode(),"\\n", "", "\\r", "", "\\t", ""), "lxml"))\nif soup == 0: OSA.log("Error in requesting Aliexpress orders. Some things that can cause this is using a vpn or a using a vps. Please make sure your password is correct as well")\nm_page = (or_list(lambda:[int(i.text) for i in soup.findAll(attrs={"class": "ui-goto-page"})[::-1] if i.text.isdigit()][0],0)) + 1\nprint(\'max \', m_page)\nfor page in range(0, m_page):\n  _csrf_input = soup.find(attrs={"name": \'_csrf_token\'})\n  csrf = _csrf_input.attrs["value"]\n  query = {\n    "action": "OrderListAction",\n    "eventSubmitDoPage": "doPage",\n    "_fm.o._0.s":(x1).strftime("%m/%d/%Y"),\n    "_fm.o._0.e":(x2).strftime("%m/%d/%Y"),\n    "_fm.o._0.cu": page,\n    "pageNum": page + 1,\n    "_csrf_token": csrf}\n  print("Wait...")\n  time.sleep(2)\n  response = Aliexpress_Requests()().post("https://trade.aliexpress.com/orderList.htm", data=query)\n  if response.status_code != 200: OSA.log("error in requesting Aliexpress orders. Some things that can cause this is using a vpn or a using a vps. Please make sure your password is correct as well")\n\n  soup = BeautifulSoup(Replacements(r.content.decode(),"\\n", "", "\\r", "", "\\t", ""), "lxml")\n  order_ids = lmap(lambda i: int(findall(i.attrs["href"],"orderId=(.*)")[0]), soup.findAll(attrs={"class": "view-detail-link"}))\n  order_times = [Date().myDatetimenow(Date().parse_date(i.text)) for i in soup.findAll("span", attrs={"class":"info-body"}) if tryprocess(lambda: Date().parse_date(i.text)) == 1]\n  print("len order ids: %s" % len(order_ids))\n  print("Get order list Success, current page is %s" % (page + 1))\n\n  if len(order_ids) > 0 and get_order_info == True:\n    for order_id, order_time in zip(order_ids, order_times):\n      Aliexpressorder().order_info(order_id, order_time)\n      time.sleep(1)\n' """
class Order_Unpender:
  def __init__(self,window_index=[0,0,3.5,3.5],ph=False,exit_browser=False):
    setattrs(self,"ph",ph,"exit_browser",exit_browser,"window_index",window_index,"headers",session_headers,"username",Get(Shop,shop_abbreviation=Muta()().store_abbre).AliExpress_Email,"password",Get(Shop,shop_abbreviation=Muta()().store_abbre).AliExpress_Password,)
    self.ss = Browser()( ("ch+"if(True==self.ph)else("sele")) ).get("https://login.aliexpress.com/").sp(5).tp(lambda:globe("ss_v").frame("alibaba-login-box")).bat().fid("fm-login-id").fid("fm-login-password").fcn("password-login").bat(self.username,self.password,globe("ss_v").SHADOW.ENTER).sp(10).tp(lambda: cookies_to_database(username=self.username,website_name="AliExpress",cookies=globe("ss_v").get_cookies(),reverse=False)).tp(lambda:setattr(self,"rq",cookies_to_session(cookies_to_database(self.username,"AliExpress"),requests.Session()))).tp(lambda:globe("ss_v").quit()if(self.exit_browser)else())
  def __call__(self_):
    # Exec("x_shop = Muta()().store_abbre\nLineitemsFeed().LineitemsFeed(x_shop)\nunfulfilled_orders = keyby(lambda i: InceptedProduct().RScan(id=i.product_id).ali_url, list(tcer(Lineitem.objects.filter(fulfillment_status=None, financial_status='paid', shop=x_shop))))",globals(),locals())
    """ Exec = exec; self_ = self """
    x_shop = Muta()().store_abbre
    LineitemsFeed().LineitemsFeed(x_shop)
    unfulfilled_orders = keyby(lambda i: InceptedProduct().RScan(id=i.product_id).ali_url, list(tcer(Lineitem.objects.filter(fulfillment_status=None, financial_status='paid', shop=x_shop))))
    # """
    if not unfulfilled_orders: return (print("Waiting"), sp(60), self_())

    # """
    setattrs(self_,"seed_order",
      lambda:unfulfilled_orders[-1],
      "shop",lambda:Shop()(self_.seed_order.shop),
      "real_order",lambda:Get(Order,id=self_.seed_order.order_id),
      "orders",lambda:lmap(lambda i:Get(Lineitem,id=AttrDict(i).id), keyby(lambda i: (InceptedProduct().RScan(id=AD(i).product_id).aliexpressvendor)  ==  (InceptedProduct().RScan(id=self_.seed_order.product_id).aliexpressvendor), self_.real_order.line_items)),
      "fulfilled_line_items",lambda:[])
    print(self_.seed_order)
    Exec('globalise(lmap(lambda i: AttrDict(i.to_dict()), Shop()(x_shop).shopify.OrderRisk.find(order_id=self_.seed_order.order_id)),"a")\nif(globe("a") != []):\n  if (max(set(lmap(lambda i:float(i),sud("score",globe("a")))))>=0.5 or "cancel" in sud("recommendation",globe("a"))):\n    OSA.log("Please go to %s in your browser and cancel or refund any high fraud order items"%("%s/orders/%s"%(self_.shop.Administrative_Url,self_.seed_order.id)))\n    (0/0)\nelse:\n  x = OSA.log("Order Risk Details\\n\\nScores: %s\\nMessages: %s\\nRecommendations: %s\\n\\n\\nContinue?"%(Join(", ",sud("score",globe("a"))),Join(", ",sud("message",globe("a"))),Join(", ",sud("recommendation",globe("a")))),tp=False,buttons=["No","Yes"])\n  if x == "Yes":\n    (OSA.log("Continuing",tp=False))\n  else:\n    (0/0)',globals(),locals())
    self_.ss.get("https://shoppingcart.aliexpress.com/shopcart/shopcartDetail.htm?").tp(lambda:lmap(lambda i: (i.click(),sp(2),self_.ss.ffst("button","OK").click().sp(5)), self_.ss.jtns("button",0,{"ae_button_type":"remove"})))

    shipping_address = or_list(lambda:self_.seed_order.updated_shipping_address,lambda:self_.seed_order.shipping_address)
    country, state, city, zip_, address1, address2, name, province = (country_code_dict[shipping_address['country_code']]  ,  states.get(shipping_address['province_code']) if shipping_address['country_code'] == "US" else shipping_address['province']  ,  aliexpress_dialog_box_adjust_city(shipping_address['city'].strip().capitalize())  ,  shipping_address['zip']  ,  shipping_address['address1']  ,  shipping_address['address2']  ,  shipping_address['name']  ,  shipping_address['province'])
    tp(lambda:lmap(lambda i: print("%s: %s"%(i, eval(i))), ["country", "state", "city", "zip_", "address1", "address2", "name", "province"]))
    #
    self_.ss.get("https://ilogisticsaddress.aliexpress.com/addressList.htm").tp(lambda:ifelseget(lambda:"selectedAddressId" in self_.ss.current_url,lambda:None,lambda:self_.ss.fcns("sa-edit").click()))
    lmap(lambda i:i.click(),[i for i in self_.ss.fcns("sa-country")[0].find_elements_by_tag_name("option") if i.text == country])
    for i in self_.ss.fcns("sa-country")[0].find_elements_by_tag_name("option"):
      if i.text == country:
        i.click()
        time.sleep(1)
        break
    for i in self_.ss.fcns("sa-province-wrapper")[0].find_elements_by_tag_name("option"):
      if i.text == state:
        i.click()
        time.sleep(1)
        break
    for i in self_.ss.fcns("sa-city-wrapper")[0].find_elements_by_tag_name("option"):
      if i.text == city:
        i.click()
        time.sleep(1)
        break
    self_.ss.bat().fn("contactPerson").send_keys(name).sp(1).fn("address").send_keys(address1).sp(1).fn("address2").send_keys(address2)
    self_.ss.sp(1).fn("zip").send_keys(zip_).sp(1).fn("mobileNo").send_keys(Shop()(x_shop).Business_Phone_Number).sp(1)
    self_.ss.fn("isDefault").click().fcns("sa-confirm").click()
    shipping_address_ = get_random_address(homepath("~/tavern/tavern/soda/dls")).png()
    self_.ss.save_screenshot(shipping_address_)

    OSA.log("The projected count of items in this order is %s"%(len(self_.orders)))
    for order in self_.orders:
      # Exec('# Get Self Url\nself_.url = InceptedProduct().RScan(id=order.product_id).ali_url\nself_.order = order\nself_.saved_data_1 = [{"shipping_address":address_string_from_dict(self_.real_order.shipping_address),"idx":idx,"total quantity":i["quantity"],"title":i["title"],"variant_title":i["variant_title"],"fulfilled quantity":i["quantity"] if i["fulfillment_status"] == "fulfilled" else 0, "ali_url":Get(Product,id=Get(Lineitem,id=i["id"]).product_id).ali_url,"sku":i["sku"]} for idx,i in enum(self_.real_order.line_items)]\n# Get DATA\nx = Aliexpress_Products().get_product_data(url=InceptedProduct().RScan(id=self_.order.product_id).ali_url)\nx_saved = x\n# Get Important VARIABLES\n\n\nshipping_cost = ShippingCost().get_shipping_cost(x.shipping,x_shop)\ndata2 = or_list(lambda: AD(json.loads(findall(str(x.data),1,\'data: ({"actionModule.*),\'))).skuModule.skuPriceList, lambda: lmap(AD,json.loads(findall(str(x.data),1,"var skuProducts=(.*);"))))\nsku_list = or_list(lambda: AD(json.loads(findall(str(x.data),1,\'data: ({"actionModule.*),\'))).skuModule.productSKUPropertyList, lambda: lmap(AD,json.loads(findall(str(x.data),1,"var skuProducts=(.*);"))))\nvariants = lmap(lambda i: AD(sku = Join("|",Split(", ", i.skuPropIds)), inventory_quantity = i.skuVal.availQuantity, price = or_list(lambda: flt(i.skuVal.actSkuCalPrice) + shipping_cost, lambda: flt(i.skuVal.skuCalPrice) + shipping_cost)), data2)\nproduct = Get(Product,id=self_.order.product_id)',globals(),locals())
      # Get Self Url
      self_.url = InceptedProduct().RScan(id=order.product_id).ali_url
      self_.order = order
      self_.saved_data_1 = [{"shipping_address":address_string_from_dict(self_.real_order.shipping_address),"idx":idx,"total quantity":i["quantity"],"title":i["title"],"variant_title":i["variant_title"],"fulfilled quantity":i["quantity"] if i["fulfillment_status"] == "fulfilled" else 0, "ali_url":Get(Product,id=Get(Lineitem,id=i["id"]).product_id).ali_url,"sku":i["sku"]} for idx,i in enum(self_.real_order.line_items)]
      # Get DATA
      x = Aliexpress_Products().get_product_data(url=InceptedProduct().RScan(id=self_.order.product_id).ali_url)
      x_saved = x
      # Get Important VARIABLES

      to_continue = False        
      # Not Found
      if x.y == "Not Found":
        if("Refund"==OSA.log("This product is not found.\n\nRefund or Manually Add Item To Cart?\n[%s %s %s]"%(((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))),buttons=["Refund","Manually Add Item To Cart"],tp=False)):
          (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
          to_continue = True
        else:
          OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
          setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
          self_.manually_setted = True
          to_continue = True
          self_.fulfilled_line_items.append(order)
          OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))
      #here, continue if it's not found because the rest of the details cannot be calculated
      print("to continue: %s" % (to_continue))
      if to_continue == True: continue

      shipping_cost = ShippingCost().get_shipping_cost(x.shipping,x_shop)
      data2 = or_list(lambda: AD(json.loads(findall(str(x.data),1,'data: ({"actionModule.*),'))).skuModule.skuPriceList, lambda: lmap(AD,json.loads(findall(str(x.data),1,"var skuProducts=(.*);"))))
      sku_list = or_list(lambda: AD(json.loads(findall(str(x.data),1,'data: ({"actionModule.*),'))).skuModule.productSKUPropertyList, lambda: lmap(AD,json.loads(findall(str(x.data),1,"var skuProducts=(.*);"))))
      variants = lmap(lambda i: AD(sku = Join("|",Split(", ", i.skuPropIds)), inventory_quantity = i.skuVal.availQuantity, price = or_list(lambda: flt(i.skuVal.actSkuCalPrice) + shipping_cost, lambda: flt(i.skuVal.skuCalPrice) + shipping_cost)), data2)
      product = Get(Product,id=self_.order.product_id)
      # Exec('to_continue = False        \n# Not Found\nif x.y == "Not Found":\n  if("Refund"==OSA.log("This product is not found.\\n\\nRefund or Manually Add Item To Cart?",buttons=["Refund","Manually Add Item To Cart"],tp=False)):\n    (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))\n    to_continue = True\n# A Variant Not Found\nif Get(UniqueProductIdentifier,product_id=product.id,shop=self_.order.shop,y=self_.order.sku).x.replace("|",",") not in key("sku", variants):\n  if("Refund"==OSA.log("This variant with title: %s at the url: %s is not found.\\n\\nRefund or Manually Add Item To Cart?"%(self_.order.title,InceptedProduct().RScan(id=self_.order.product_id).ali_url),buttons=["Refund","Manually Add Item To Cart"],tp=False)):\n    (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))\n    to_continue = True\n# Out Of Stock\nif keyby(lambda i:Get(UniqueProductIdentifier,product_id=product.id,shop=self_.order.shop,y=self_.order.sku).x.replace("|",",") == i.sku, variants)[0].inventory_quantity == 0:\n  if("Refund"==OSA.log("This variant with title: %s at the url: %s is out of stock.\\n\\nRefund or Manually Add Item To Cart?"%(self_.order.title,InceptedProduct().RScan(id=self_.order.product_id).ali_url),buttons=["Refund","Manually Add Item To Cart"],tp=False)):\n    (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))\n    to_continue = True\n# Low Q\nif keyby(lambda i:Get(UniqueProductIdentifier,product_id=product.id,shop=self_.order.shop,y=self_.order.sku).x.replace("|",",") == i.sku, variants)[0].inventory_quantity < self_.order.quantity:\n  if("Refund"==OSA.log("This variant with title: %s at the url: %s does not have the amount of inventory that the order requires.\\n\\nRefund or Manually Add Item To Cart?"%(self_.order.title,InceptedProduct().RScan(id=self_.order.product_id).ali_url),buttons=["Refund","Manually Add Item To Cart"],tp=False)):\n    (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))\n    to_continue = True\n# High Price\nif keyby(lambda i:Get(UniqueProductIdentifier,product_id=product.id,shop=self_.order.shop,y=self_.order.sku).x.replace("|",",") == i.sku, variants)[0].price > self_.order.price:\n  if("Refund"==OSA.log("This variant with title: %s at the url: %s is priced over the price that it sold for of %s.\\n\\nRefund or Manually Add Item To Cart?"%(self_.order.title,InceptedProduct().RScan(id=self_.order.product_id).ali_url,self_.order.price),buttons=["Refund","Manually Add Item To Cart"],tp=False)):\n    (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))\n    to_continue = True\n# Country Not Supported\nif self_.order.shipping_address.get("country_code") not in ["US"]:\n  if("Refund"==OSA.log("This order is shipping to a country outside of the United States. Refund or Manually Add Item To Cart?",buttons=["Refund","Manually Add Item To Cart"],tp=False)):\n    (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))\n    to_continue = True\n# Shipping Problem\nif x.y == "No ePacket":\n  if("Refund"==OSA.log("This product does not have ePacket Shipping.\\n\\nRefund or Manually Add Item To Cart?",buttons=["Refund","Manually Add Item To Cart"],tp=False)):\n    (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))\n    to_continue = True\n# Order Note\nif self_.real_order.note:\n  if("Refund"==OSA.log("This order has the note:\\n%s\\n\\nRefund or Manually Add Item To Cart?"%(self_.real_order.note),buttons=["Refund","Manually Add Item To Cart"],tp=False)):\n    (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))\n    to_continue = True',globals(),locals())
      #continue and refund/manually order another boxes
      # Country Not Supported
      # if self_.order.shipping_address.get("country_code") not in ["US"]:
      #   if("Refund"==OSA.log("This order is shipping to a country outside of the United States. Refund or Manually Add Item To Cart?",buttons=["Refund","Manually Add Item To Cart"],tp=False)):
      #     (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
      #     to_continue = True
      #   else:
      #     OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
      #     setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
      #     self_.manually_setted = True
      #     to_continue = True
      #     self_.fulfilled_line_items.append(order)
      #     OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))
      # A Variant Not Found
      if Get(UniqueProductIdentifier,product_id=product.id,shop=self_.order.shop,y=self_.order.sku).x.replace("|",",") not in key("sku", variants):
        if("Refund"==OSA.log("This variant with variant title: %s at the url: %s is not found.\n\nRefund or Manually Add Item To Cart?"%(self_.order.variant_title,InceptedProduct().RScan(id=self_.order.product_id).ali_url),buttons=["Refund","Manually Add Item To Cart"],tp=False)):
          (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
          to_continue = True
        else:
          OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
          setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
          self_.manually_setted = True
          to_continue = True
          self_.fulfilled_line_items.append(order)
          OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))
      # Out Of Stock
      if keyby(lambda i:Get(UniqueProductIdentifier,product_id=product.id,shop=self_.order.shop,y=self_.order.sku).x.replace("|",",") == i.sku, variants)[0].inventory_quantity == 0:
        if("Refund"==OSA.log("This variant with title: %s at the url: %s is out of stock.\n\nRefund or Manually Add Item To Cart?"%(self_.order.title,InceptedProduct().RScan(id=self_.order.product_id).ali_url),buttons=["Refund","Manually Add Item To Cart"],tp=False)):
          (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
          to_continue = True
        else:
          OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
          setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
          self_.manually_setted = True
          to_continue = True
          self_.fulfilled_line_items.append(order)
          OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))
      # Low Q
      if keyby(lambda i:Get(UniqueProductIdentifier,product_id=product.id,shop=self_.order.shop,y=self_.order.sku).x.replace("|",",") == i.sku, variants)[0].inventory_quantity < self_.order.quantity:
        if("Refund"==OSA.log("This variant with title: %s at the url: %s does not have the amount of inventory that the order requires.\n\nRefund or Manually Add Item To Cart?"%(self_.order.title,InceptedProduct().RScan(id=self_.order.product_id).ali_url),buttons=["Refund","Manually Add Item To Cart"],tp=False)):
          (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
          to_continue = True
        else:
          OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
          setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
          self_.manually_setted = True
          to_continue = True
          self_.fulfilled_line_items.append(order)
          OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))
      # High Price
      if keyby(lambda i:Get(UniqueProductIdentifier,product_id=product.id,shop=self_.order.shop,y=self_.order.sku).x.replace("|",",") == i.sku, variants)[0].price > self_.order.price:
        if("Refund"==OSA.log("This variant with title: %s at the url: %s is priced over the price that it sold for of %s.\n\nRefund or Manually Add Item To Cart?"%(self_.order.title,InceptedProduct().RScan(id=self_.order.product_id).ali_url,self_.order.price),buttons=["Refund","Manually Add Item To Cart"],tp=False)):
          (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
          to_continue = True
        else:
          OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
          setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
          self_.manually_setted = True
          to_continue = True
          self_.fulfilled_line_items.append(order)
          OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))
      # Shipping Problem
      if x.y == "No ePacket":
        if("Refund"==OSA.log("This product does not have ePacket Shipping.\n\nRefund or Manually Add Item To Cart?",buttons=["Refund","Manually Add Item To Cart"],tp=False)):
          (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
          to_continue = True
        else:
          OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
          setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
          self_.manually_setted = True
          to_continue = True
          self_.fulfilled_line_items.append(order)
          OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))
      # Order Note
      if self_.real_order.note:
        if("Refund"==OSA.log("This order has the note:\n%s\n\nRefund or Manually Add Item To Cart?"%(self_.real_order.note),buttons=["Refund","Manually Add Item To Cart"],tp=False)):
          (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
          to_continue = True
        else:
          OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
          setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
          self_.manually_setted = True
          to_continue = True
          self_.fulfilled_line_items.append(order)
          OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))
      print("to continue: %s" % (to_continue))
      if to_continue == True: continue
      # 'x = AD(data=requests.get("https://www.aliexpress.com/item/32972321655.html?spm=a2g0o.productlist.0.0.502be3db6PIFg5&algo_pvid=6e6ab535-2674-4ada-badb-f307fa42baaf&algo_expid=6e6ab535-2674-4ada-badb-f307fa42baaf-1&btsid=2e90407e-a1e1-4487-a2f2-a56ac864f81f&ws_ab_test=searchweb0_0,searchweb201602_7,searchweb201603_53").text)\nshipping_cost = 1\ndata2 = or_list(lambda: AD(json.loads(findall(str(x.data),1,\'data: ({"actionModule.*),\'))).skuModule.skuPriceList, lambda: lmap(AD,json.loads(findall(str(x.data),1,"var skuProducts=(.*);"))))\nsku_list = or_list(lambda: AD(json.loads(findall(str(x.data),1,\'data: ({"actionModule.*),\'))).skuModule.productSKUPropertyList, lambda: lmap(AD,json.loads(findall(str(x.data),1,"var skuProducts=(.*);"))))\nvariants = lmap(lambda i: AD(sku = Join("|",Split(", ", i.skuPropIds)), inventory_quantity = i.skuVal.availQuantity, price = or_list(lambda: flt(i.skuVal.actSkuCalPrice) + 1, lambda: flt(i.skuVal.skuCalPrice) + 1)), data2)\n# SKU = Get(UniqueProductIdentifier,product_id=self_.order.product_id,shop=self_.order.shop,y=self_.order.sku).x\nSKU = "1583|6144"\nif SKU != "":\n  SKU_OPTIONS = lmap(int, Split("|", SKU))\n  # for idx, i in enum(SKU_OPTIONS):\n  #   self_.ss.fid("sku-%s-%s"%((idx+1), i)).click().sp(2)\n  r = list(enum(SKU_OPTIONS))\n  sku_info_list = []\n  for idx, a in r:\n    options = keyby(lambda i:i.order == idx+1, sku_list)\n    option = options[0]\n    for idx2, b in enum(option.skuPropertyValues):\n      if b.propertyValueId == a:\n        data = AD(option_list_data=None,sku=None,title=None,image_url=None)\n        data.option_list_data = (idx, idx2)\n        sku_info_list.append(data)\n  for info in sku_info_list:\n    a, b = info.option_list_data\n    sku = info.sku\n    title = info.title\n    image_url = info.image_url\n    entries = self_.ss.fcns("sku-property-list")\n    entry = entries[a]\n    entry_values = entry.find_elements_by_class_name("sku-property-item")\n    entry_value = entry_values[b]\n    data.sku = sku\n    text,image_url = None, None\n    if entry_value.find_elements_by_class_name("sku-property-color"):\n      text = entry_value.find_elements_by_class_name("sku-property-color")[0].find_elements_by_tag_name("span")[0].get_attribute("title")\n      image_url = None\n      data.update(title = text, image_url = image_url)\n    if entry_value.find_elements_by_class_name("sku-property-image"):\n      text = entry_value.find_elements_by_class_name("sku-property-image")[0].find_elements_by_tag_name("img")[0].get_attribute("title")\n      text = entry_value.find_elements_by_tag_name("img")[0].get_attribute("title")\n      image_url = entry_value.find_elements_by_class_name("sku-property-image")[0].find_elements_by_tag_name("img")[0].get_attribute("src")\n      image_url = entry_value.find_elements_by_tag_name("img")[0].get_attribute("src")\n      data.update(title = text, image_url = image_url)\n    if entry_value.find_elements_by_class_name("sku-property-text"):\n      text = entry_value.find_elements_by_class_name("sku-property-text")[0].text\n      image_url = None\n      data.update(title = text, image_url = image_url)\n    OSA.log("option list data: %s, %s\\nsku: %s\\ntitle: %s\\nimage_url: %s\\n\\nPlease check that the info is correct."%(a, b, data.sku, data.title, data.image_url))\n    if "selected" not in entry_value.get_attribute("class"):\n      entry_value.click()\n    sp(2)'
      # Exec('# Get URL and CLIKC options\nself_.ss.get(self_.url)\nif self_.order.sku == "Auto":\n  # Auto\n  OSA.log("Sku is auto. Please fill it out.",tp=False)\nelse:\n  SKU = Get(UniqueProductIdentifier,product_id=self_.order.product_id,shop=self_.order.shop,y=self_.order.sku).x\n  if SKU != "":\n    SKU_OPTIONS = lmap(int, Split("|", SKU))\n    # for idx, i in enum(SKU_OPTIONS):\n    #   self_.ss.fid("sku-%s-%s"%((idx+1), i)).click().sp(2)\n    r = list(enum(SKU_OPTIONS))\n    sku_info_list = []\n    for idx, a in r:\n      sku_list_ = key("skuPropertyValues",sku_list)[idx]\n      options = keyby(lambda i:i.order == idx+1, sku_list)\n      option = options[0]\n      for idx2, b in enum(sku_list_):\n        if b.propertyValueId == a:\n          data = AD(option_list_data=None,sku=None,title=None,image_url=None)\n          data.option_list_data = (idx, idx2)\n          sku_info_list.append(data)\n    for info in sku_info_list:\n      a, b = info.option_list_data\n      sku = info.sku\n      title = info.title\n      image_url = info.image_url\n      entries = self_.ss.fcns("sku-property-list")\n      entry = entries[a]\n      entry_values = entry.find_elements_by_class_name("sku-property-item")\n      entry_value = entry_values[b]\n      data.sku = sku\n      text,image_url = None, None\n      if entry_value.find_elements_by_class_name("sku-property-color"):\n        text = entry_value.find_elements_by_class_name("sku-property-color")[0].find_elements_by_tag_name("span")[0].get_attribute("title")\n        image_url = None\n        data.update(title = text, image_url = image_url)\n      if entry_value.find_elements_by_class_name("sku-property-image"):\n        text = entry_value.find_elements_by_class_name("sku-property-image")[0].find_elements_by_tag_name("img")[0].get_attribute("title")\n        text = entry_value.find_elements_by_tag_name("img")[0].get_attribute("title")\n        image_url = entry_value.find_elements_by_class_name("sku-property-image")[0].find_elements_by_tag_name("img")[0].get_attribute("src")\n        image_url = entry_value.find_elements_by_tag_name("img")[0].get_attribute("src")\n        data.update(title = text, image_url = image_url)\n      if entry_value.find_elements_by_class_name("sku-property-text"):\n        text = entry_value.find_elements_by_class_name("sku-property-text")[0].text\n        image_url = None\n        data.update(title = text, image_url = image_url)\n      OSA.log("option list data: %s, %s\\nsku: %s\\ntitle: %s\\nimage_url: %s\\n\\nPlease check that the info is correct."%(a, b, data.sku, data.title, data.image_url))\n      OSA.log("Entry value class: %s" % (entry_value.get_attribute("class")))\n      if "selected" not in entry_value.get_attribute("class"):\n        entry_value.click()\n      sp(2)\n\n    OSA.log("Checking all options could be selected")\n    entries = self_.ss.fcns("sku-property-list")\n    for idx, a in enum(entries):\n      selected = a.find_elements_by_class_name("selected")\n      if selected == []:\n        OSA.log("Unable to select element for option list #%s"%(idx+1))',globals(),locals())
      # Get URL and CLIKC options
      self_.ss.get(self_.url)
      if self_.order.sku == "Auto":
        # Auto
        OSA.log("Sku is auto. Please fill it out.",tp=False)
      else:
        SKU = Get(UniqueProductIdentifier,product_id=self_.order.product_id,shop=self_.order.shop,y=self_.order.sku).x
        if SKU != "":
          SKU_OPTIONS = lmap(int, Split("|", SKU))
          # for idx, i in enum(SKU_OPTIONS):
          #   self_.ss.fid("sku-%s-%s"%((idx+1), i)).click().sp(2)
          r = list(enum(SKU_OPTIONS))
          sku_info_list = []
          for idx, a in r:
            sku_list_ = key("skuPropertyValues",sku_list)[idx]
            for idx_v, i in enum(sku_list):
              i.order_x = idx_v + 1
            options = keyby(lambda i:i.order_x == idx+1, sku_list)
            option = options[0]
            for idx2, b in enum(sku_list_):
              if b.propertyValueId == a:
                data = AD(option_list_data=None,sku=None,title=None,image_url=None)
                print(idx, idx2)
                data.option_list_data = (idx, idx2)
                sku_info_list.append(data)
          for info in sku_info_list:
            a, b = info.option_list_data
            sku = info.sku
            title = info.title
            image_url = info.image_url
            entries = self_.ss.fcns("sku-property-list")
            entry = entries[a]
            entry_values = entry.find_elements_by_class_name("sku-property-item")
            entry_value = entry_values[b]
            data.sku = sku
            text,image_url = None, None
            if entry_value.find_elements_by_class_name("sku-property-color"):
              text = entry_value.find_elements_by_class_name("sku-property-color")[0].find_elements_by_tag_name("span")[0].get_attribute("title")
              image_url = None
              data.update(title = text, image_url = image_url)
            if entry_value.find_elements_by_class_name("sku-property-image"):
              text = entry_value.find_elements_by_class_name("sku-property-image")[0].find_elements_by_tag_name("img")[0].get_attribute("title")
              text = entry_value.find_elements_by_tag_name("img")[0].get_attribute("title")
              image_url = entry_value.find_elements_by_class_name("sku-property-image")[0].find_elements_by_tag_name("img")[0].get_attribute("src")
              image_url = entry_value.find_elements_by_tag_name("img")[0].get_attribute("src")
              data.update(title = text, image_url = image_url)
            if entry_value.find_elements_by_class_name("sku-property-text"):
              text = entry_value.find_elements_by_class_name("sku-property-text")[0].text
              image_url = None
              data.update(title = text, image_url = image_url)
            OSA.log("option list data: %s, %s\nsku: %s\ntitle: %s\nimage_url: %s\n\nPlease check that the info is correct."%(a, b, data.sku, data.title, data.image_url))
            OSA.log("Entry value class: %s" % (entry_value.get_attribute("class")))
            if "selected" not in entry_value.get_attribute("class"):
              entry_value.click()
            sp(2)

          OSA.log("Checking all options could be selected")
          entries = self_.ss.fcns("sku-property-list")
          for idx, a in enum(entries):
            selected = a.find_elements_by_class_name("selected")
            if selected == []:
              OSA.log("Unable to select element for option list #%s"%(idx+1))

      # Exec('to_return = False        \n# ADDINVENTORY\nif 0 in lmap(lambda i: self_.ss.fcn("p-quantity-increase").click().sp(1), lrange(self_.order.quantity - 1)):\n  (OSA.log("Could not add everything to inventory. This is an error that should not happen. Exitting."))\n  to_return = True\n\n# CHECKINVENTORYEQUAL\nif or_list(lambda:int(self_.ss.fcn("product-number-picker",4).find_elements_by_tag_name("input")[0].get_attribute("value")),lambda:int(self_.ss.fcn("p-quantity-input",4).get_attribute("value"))) != self_.order.quantity:\n  (OSA.log("Current quantity to add to cart is not equal to the order quantity. This is an error that should not happen. Exitting."))\n  to_return = True\n\n# SHIPPING BUTTON CHECK\n# self_.ss.fid("j-shipping-company").click().fcn("s-company-title", _time=30).sp(2)\nself_.ss.ffss("span","ae_button_type","detail_change_freight_click",4).click().sp(2)\nif Shop()(x_shop).Allow_Additional_Shipping_Methods == False:\n  if "ePacket" not in sud("text",self_.ss.fcns("service-name")):\n  # if tryprocess(lambda: self_.ss.ffst("td","ePacket")) == 0:\n    (OSA.log("No ePacket button is available. This is an error that should not happen. Exitting."))\n    to_return = True',globals(),locals())
      #continue and refund/manually order another boxes
      to_continue = False        
      # ADDINVENTORY
      if 0 in lmap(lambda i: self_.ss.fcns("next-after").click().sp(1), lrange(self_.order.quantity - 1)):
        (OSA.log("Could not add everything to inventory. This is an error that should not happen."))
        option = OSA.log("Do you want to manually find another one to add it to the cart or do you want to refund the quantity that could not be fulfilled?",buttons=["Refund","Manually Add Items To Cart"])
        if option == "Refund":
          (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
          to_continue = True
        else:
          OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
          setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
          self_.manually_setted = True
          to_continue = True
          self_.fulfilled_line_items.append(order)
          OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))
      # CHECKINVENTORYEQUAL
      if or_list(lambda:int(self_.ss.fcn("product-number-picker",4).find_elements_by_tag_name("input")[0].get_attribute("value")),lambda:int(self_.ss.fcn("p-quantity-input",4).get_attribute("value"))) != self_.order.quantity:
        (OSA.log("Current quantity to add to cart is not equal to the order quantity. This is an error that should not happen."))
        option = OSA.log("Do you want to manually find another one to add it to the cart or do you want to refund the quantity that could not be added to the cart?",buttons=["Refund","Manually Add Items To Cart"])
        if option == "Refund":
          (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
          to_continue = True
        else:
          OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
          setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
          self_.manually_setted = True
          to_continue = True
          self_.fulfilled_line_items.append(order)
          OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))
      # SHIPPING BUTTON CHECK
      # self_.ss.fid("j-shipping-company").click().fcn("s-company-title", _time=30).sp(2)
      self_.ss.ffss("span","ae_button_type","detail_change_freight_click",4).click().sp(2)
      if Shop()(x_shop).Allow_Additional_Shipping_Methods == False:
        if "ePacket" not in sud("text",self_.ss.fcns("service-name")):
        # if tryprocess(lambda: self_.ss.ffst("td","ePacket")) == 0:
          (OSA.log("No ePacket button is available. This is an error that should not happen."))
          option = OSA.log("Do you want to manually find another one with ePacket to add it to the cart or do you want to refund the items without ePacket?",buttons=["Refund","Manually Add Items To Cart"])
          if option == "Refund":
            (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
            to_continue = True
          else:
            OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
            setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
            self_.manually_setted = True
            to_continue = True
            self_.fulfilled_line_items.append(order)
            OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))

      if to_continue == True: continue


      # Exec('# click the shipping option\nshipping_company = ShippingCost().get_shipping_company(x.shipping,x_shop)\n# self_.ss.ffst("td", shipping_company).click().ffs("input","value","OK").click().sp(2)\nself_.ss.jcns("service-name","click",{"text":shipping_company}).sp(2).jtns("button","click",{"ae_button_type":"detail_shipping_panel_apply"}).sp(2)\n# Set TrackMethod and Price\n# setattrs(self_.order, "ali_tracking_method", shipping_company, "ali_price", (self_.order.quantity *float( Join(".",findall(self_.ss.fcn("product-price-value").text,"\\d+"))))+(float(Join(".",findall(self_.ss.fcn("product-shipping-price").text,"\\d+")))) )\n# add shipping price later\nsetattrs(self_.order, "ali_tracking_method", shipping_company, "ali_price", (self_.order.quantity *float( Join(".",findall(self_.ss.fcn("product-price-value").text,"\\d+")))) )\nOSA.log("order price: %s\\nali_order_price: %s\\n\\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))',globals(),locals())
      # click the shipping option
      shipping_company = ShippingCost().get_shipping_company(x.shipping,x_shop)
      # self_.ss.ffst("td", shipping_company).click().ffs("input","value","OK").click().sp(2)
      self_.ss.jcns("service-name","click",{"text":shipping_company}).sp(2).jtns("button","click",{"ae_button_type":"detail_shipping_panel_apply"}).sp(2)
      # Set TrackMethod and Price
      # setattrs(self_.order, "ali_tracking_method", shipping_company, "ali_price", (self_.order.quantity *float( Join(".",findall(self_.ss.fcn("product-price-value").text,"\d+"))))+(float(Join(".",findall(self_.ss.fcn("product-shipping-price").text,"\d+")))) )
      # add shipping price later
      # Exec('to_return = False\n# add to cart action and check it\nclick_add_to_cart_action = tryprocess(lambda: self_.ss.fcn("addcart").click().sp(5))\nif click_add_to_cart_action == 0:\n  (OSA.log("Could not add this product to cart. This is an error that should not happen. Exitting."))\n  to_return = True',globals(),locals())
      to_continue = False
      # add to cart action and check it
      click_add_to_cart_action = tryprocess(lambda: self_.ss.fcn("addcart").click().sp(5))
      if click_add_to_cart_action == 0:
        (OSA.log("Could not add this product to cart. This is an error that should not happen. Exitting."))
        option = OSA.log("Do you want to manually find another one where it can add it to the cart or do you want to refund the item that can't add to cart?",buttons=["Refund","Manually Add Items To Cart"])
        if option == "Refund":
          (OSA.log("Please refund the %s %s at %s"%((self_.order.quantity),("%s(%s)"%(self_.order.title, self_.order.variant_title)),("%s/orders/%s"%(Get(Shop,shop_abbreviation=self_.order.shop).Administrative_Url,self_.real_order.id)))))
          to_continue = True
        else:
          OSA.log("Okay you have manually added it to the cart. Please enter the shipping company and the price of the item without including it's shipping in the following screens",tp=False)
          setattrs(self_.order, "ali_tracking_method", OSA.log("Shipping company?"), "ali_price", float(OSA.log("Ali Price of the item without including the shipping (it will be calculated later)")) )
          self_.manually_setted = True
          to_continue = True
          self_.fulfilled_line_items.append(order)
          OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))

      if to_continue == True: continue
      
      if getattr(self,"manually_setted",False) == False:
        self_.ss.fcns("next-dialog-close-icon").click().sp(2)
        setattrs(self_.order, "ali_tracking_method", shipping_company, "ali_price", (self_.order.quantity *float( Join(".",findall(self_.ss.fcn("product-price-value").text,"\d+")))) )
      else:
        OSA.log("Affirming self order amounts:\nTracking:%s\nAli Price:%s" % (self_.order.ali_tracking_method,self_.order.ali_price))
      OSA.log("order price: %s\nali_order_price: %s\n\nPlease check the order price to the ali order price. This is not including the shipping price."%(self_.order.price, self_.order.ali_price))


      ifdo(lambda:click_add_to_cart_action == 1,lambda:self_.fulfilled_line_items.append(self_.order))
    #
    self_.ss.get("https://shoppingcart.aliexpress.com/shopcart/shopcartDetail.htm").zoom_out(5)

    if self_.fulfilled_line_items == []:
      # if a 1 item order had all items refunded
      self_()
      return

    self_.ss.fcn("next-checkbox-input").click().sp(7).pagestop_timeout().fid("checkout-button").click().sp(5).tp(lambda:self_.ss.frame("poplay-order").fcn("switch-to-full").click().sp(3)).sp(5)

    # Exec('# Adjust Cost Based on Shipping\nshipping_cost = flt(findall(self_.ss.page_source,1,"seller-charges.*?Shipping.*?charge-cost.*?\\$(\\d+\\.\\d+)"))\nsales_tax_cost = flt(findall(self_.ss.page_source,1,"seller-charges.*?tax.*?charge-cost.*?\\$(\\d+\\.\\d+)")) if findall(self_.ss.page_source,"seller-charges.*?tax.*?charge-cost.*?\\$(\\d+\\.\\d+)") else 0\nfree_shipping_orders_count = len([i for i in self_.ss.fcns("shopping-cart-product") if i.find_elements_by_class_name("logistics-cost")[0].text == "Free Shipping"])\nadditional_shipping_cost = or_list(lambda:shipping_cost/(len(self_.orders)-free_shipping_orders_count),lambda:0)\nadditional_sales_tax_cost = or_list(lambda:sales_tax_cost/(len(self_.orders)-free_shipping_orders_count),lambda:0)\nOSA.log("The additional shipping cost: %s" % (additional_shipping_cost))\nlmap(lambda i: setattr(i,"ali_price",i.ali_price+additional_shipping_cost+additional_sales_tax_cost),self_.orders)',globals(),locals())
    
    # Adjust Cost Based on Shipping
    shipping_cost = flt(Join(".",findall(sudby(lambda i:"Shipping" in i,sud("text",self_.ss.fcns("charge-item")))[0],"\d+\.\d+")))
    sales_tax_cost = flt(Join(".",findall(sudby(lambda i:"tax" in i,sud("text",self_.ss.fcns("charge-item")))[0],"\d+\.\d+"))) if sudby(lambda i:"tax" in i,sud("text",self_.ss.fcns("charge-item"))) else 0
    free_shipping_orders_count = len([i for i in self_.ss.fcns("shopping-cart-product") if i.find_elements_by_class_name("logistics-cost")[0].text == "Free Shipping"])
    additional_shipping_cost = or_list(lambda:shipping_cost/(len(self_.orders)-free_shipping_orders_count),lambda:0)
    additional_sales_tax_cost = or_list(lambda:sales_tax_cost/(len(self_.orders)),lambda:0)
    OSA.log("The additional shipping cost: %s" % (additional_shipping_cost))
    lmap(lambda i: setattr(i,"ali_price",i.ali_price+additional_shipping_cost+additional_sales_tax_cost),self_.orders)

    # 3/1 happened where the is_webmoney did not show up but will see if this happens for all other orders.
    is_webmoney = False
    # self_.ss.ffst("p","Payment Methods").click().sp(4).tp(lambda:self_.ss.jcns("pay-title","click",{"text":"Show all payment methods"}).sp(2))
    self_.ss.fcns("payment-title").click().sp(4).tp(lambda:self_.ss.jcns("pay-title","click",{"text":"Show all payment methods"}).sp(2))
    if "WESTUNION" in [i.text for i in self_.ss.fcns("disabled")]: is_webmoney = True
    if is_webmoney == False: self_.ss.fcn("west-union").click().sp(3)
    elif is_webmoney == True: self_.ss.fcn("wm-ebank").click().sp(3)
    self_.ss.tp(lambda:[(i.click(),time.sleep(2)) for i in self_.ss.jcns("seller-message-title",0,{"ae_button_type":"message_for_seller"})])
    self_.ss.tp(lambda: lmap(lambda i: [i.clear(), i.send_keys("Hello, I am dropshipping, please send this without price or invoice\nThank you"), sp(2)], self_.ss.ftns("textarea")))
    # datas = [{"qty":i.quantity,"title":i.title,"url":Get(Product,id=i.product_id).ali_url,"variant_title":i.variant_title,"idx":idx} for idx, i in enum(unfulfilled_orders)]
    datas = [{"qty":i.quantity,"title":i.title,"url":InceptedProduct().RScan(i.product_id).ali_url,"variant_title":i.variant_title,"idx":idx} for idx, i in enum(self_.orders)]
    OSA.log("Check datas:\n\n%s"%(str(json.dumps(datas,indent=4))))
    Exec('# Captcha Loop Until Able To Check Out\nif self_.ss.fcns("captche-input",6):\n  OSA.log("Found captcha")\n  while self_.ss.fcns("captche-input",6):\n    self_.ss.fcn("captche-input").send_keys(handle_captcha(findall(self_.ss.page_source,1,\'(http://captcha.alibaba.com.*?)"\').replace("amp;",""))[\'text\'])\n    complete_order = True\n    if complete_order == True:\n      ss.fid("checkout-button").click().sp(30)\n    # ifdo(lambda:"shoppingcart.aliexpress.com/order/confirm_order.htm" in self_.ss.current_url, lambda:[self_.ss.ffst("p","Payment Methods").click().ffst("p","Other payment methods").click().ffst("button","Confirm").click().sp(2), lmap(lambda i: [i.clear(), i.send_keys("Hello dear, I am dropshipping, please send this without price or invoice\\nThank you"), sp(1)], self_.ss.ftns("textarea"))])\n    ifdo(lambda:"shoppingcart.aliexpress.com/order/confirm_order.htm" in self_.ss.current_url, lambda:[self_.ss.ffst("p","Payment Methods").click().ffst("button","Confirm").click().sp(2), lmap(lambda i: [i.clear(), i.send_keys("Hello dear, I am dropshipping, please send this without price or invoice\\nThank you"), sp(1)], self_.ss.ftns("textarea"))])\n  # input("Proceed")\nelse:\n  complete_order = True\n  if complete_order == True:\n    self_.ss.fid("checkout-button").click().sp(30)',globals(),locals())


    globals().update(locals())
    self_.ss.get("https://trade.aliexpress.com/orderList.htm").fcn("msg-detail").click()
    order_ids = lmap(lambda i:int(i.find_elements_by_class_name("info-body")[0].text),self_.ss.fcns("order-info"))
    self_.ss.zoom_level(2).fcn("all-selector").click().fid("TP_CombinPay").click().sp(5).frame("poplay-order")
    price,card_id=float(Join(".",findall(self_.ss.fcn("price-value").text,"\d+"))),findall(self_.ss.fcn('payment-title').text,"\d+")[1]
    self_.ss.fcns("btn-bind").click().sp(10)
    if len(self_.ss.jcns("next-message-title",0,{"text":"Payment Successful"})) == 0:
      if self_.ss.fcns("card-number-input"):
        self_.ss.fid("cardNum").send_keys(Shop()(x_shop).AliExpress_Financial_Card_Information["Financial_Card_Number"])
        self_.ss.sp(10)
        self_.ss.ffst("button","Confirm").click()
        self_.ss.sp(30)
      elif self_.ss.ftns("iframe") and self_.ss.fids("expires"):
        self_.ss.fid("expires").send_keys(Shop()(x_shop).AliExpress_Financial_Card_Information["Financial_Card_Expiration_Date"])
        self_.ss.sp(10)
        self_.ss.fcns("next-btn-primary").click()
        self_.ss.sp(30)
    ifdo(lambda:len(order_ids)!=1,lambda:OSA.log("The number of order numbers is %s, not 1."%(len(order_ids)),tp=False))
    lmap(lambda i:Update(i,saved_address_screenshot=open(shipping_address_,"rb").read()),self_.orders)
    PaidCardNumber(order_ids=order_ids,price=price,card_id=card_id,paid_at = Date().Now() ).save()

    lmap(lambda i: [Update(i,ali_order_number=order_ids[0],fulfillment_status="fulfilled",t2=Date().myDatetimenow()),Update(i,e1=i.t2-i.t1)], self_.orders)
    lmap(lambda i: exec("assert Get(Lineitem,id=self_.order.id).fulfillment_status == 'fulfilled'"), self_.orders)


    real_order_shopify_side = self_.shop.ofind(id_=self_.real_order.id)
    line_items = keyby(lambda i:i.id in sud("id", self_.fulfilled_line_items), real_order_shopify_side.line_items)
    lmap(lambda i:xir(i,fulfillment_status="fulfilled"),line_items)
    line_items = lmap(lambda i:i.to_dict(), line_items)
    lmap(lambda i: delete_keys(i,"admin_graphql_api_id","discount_allocations","origin_location","price_set","total_discount_set"), line_items)
    data = dict(line_items=line_items,order_id=self_.real_order.id,notify_customer=True,service="manual",location_id=self_.shop.location_id)
    print("\n===fulfillment_data\n%s"%json.dumps(data, indent=4))
    new_fulfillment = self_.shop.shopify.Fulfillment(data)
    ifdo(lambda: new_fulfillment.save() != True,lambda:OSA.log("Fulfillment did not save."))
    ordersFeed(self_.real_order.shop,7)
    self_.real_order = Get(Order,id=self_.real_order.id)
    self_.saved_data_2 = [{"shipping_address":address_string_from_dict(self_.real_order.shipping_address),"idx":idx,"total quantity":i["quantity"],"title":i["title"],"variant_title":i["variant_title"],"fulfilled quantity":i["quantity"] if i["fulfillment_status"] == "fulfilled" else 0, "ali_url":InceptedProduct().RScan(Get(Lineitem,id=i["id"]).product_id).ali_url,"sku":i["sku"]} for idx,i in enum(self_.real_order.line_items)]
    OSA.log(df=Join("\n",[compare_dict(a,b) for a,b in zip(self_.saved_data_1,self_.saved_data_2)]))


    self_()
class Orders(object):
  def __init__(self):
    shop = Shop()(init_shop=shop)
    self.ordersCreate()
    self.ordersTrack()
    self.similarimagesCreate()
    self.ordersEmail()
  def transmit(self):
    ordersSheet.postSelf(Order.Objects())
  def ordersCreate(self):
    pass
  def ordersTrack(self):
    pass
  def ordersEmail(self):
    pass
  def similarimagesCreate(self):
    pass
class ordersEmail(object):
  def __init__(self, shop):
    self.e = Emailer(shop.Business_Email_Address)
  def formulate_email(self, shop, order_no, contact_name, to_email, tracking_number_list):
    print("Sending Email")
    subject = 'Your %s Tracking Number for Order # %s' % (shop.Business_Name, order_no)
    to = to_email
    msgHtml = "<br>Dear %s,<br /><br>Thank you for your purchase at %s! <br /> <br> Attached is the tracking number for Order #%s: "% (contact_name.title(), shop.Business_Name, order_no)
    msgHtml += "<br>Shipping is via USPS and may be tracked as follows: <br />"
    tracking_link = "<br>Link: https://www.17track.net/en/track?nums="
    for tn in tracking_number_list:
      tracking_link += '%s,'%tn
    tracking_link += "<br /><br><br />"
    for i in tracking_number_list:
      tracking_link += "<br>%s<br />" % i
    msgHtml += tracking_link
    msgHtml += "<br>Please do not hesitate to reply back to this email if you have any questions.<br />"
    msgHtml += "<br><br /><br> - Lilith from %s<br />" % shop.Business_Name
    print(msgHtml)
    return_status = self.e.send_message(subject,to,msgHtml)
    print("sleeping 5 seconds to assure no rate limiting.. ")
    time.sleep(5)
    globals()['return_status'] = return_status
    if 'HttpError' in return_status:
      print('HttpError ', return_status, "Sleeping 10 Minutes")
      time.sleep(600)
def create_new_fulfillment(line_item,shopify_order,tracking_company_dict):
  OSA.log("Creating new tracking number fulfillment: %s, %s" % (line_item.ali_tracking_number, tracking_company_dict))
  Update(line_item,ali_tracking_number = line_item.ali_tracking_number.strip())
  fulfillment = None
  for i in shopify_order.fulfillments:
    for j in i.line_items:
      if j.id == line_item.id:
        fulfillment = i

  fulfillment.tracking_numbers.append(str(line_item.ali_tracking_number.strip()))
  fulfillment.tracking_urls.extend(["https://tools.usps.com/go/TrackConfirmAction?tLabels={}".format(line_item.ali_tracking_number.strip()),"https://t.17track.net/en#nums={}".format(line_item.ali_tracking_number.strip())])
  fulfillment.tracking_company = tracking_company_dict.get(line_item.ali_tracking_method, "USPS")
  try:
    Fulfillments_Created().add(order_id=shopify_order.id,lineitem_id=line_item.id,tracking_company_dict=fulfillment.to_dict())
    OSA().log("Fulfillments_Created saved")
  except Exception as e:
    print(e)
    OSA().log("Fulfillment could not create. Not saving the fulfillment.")
    (0/0)

  redprint("saved fulfillment: %s" % fulfillment.save())
  redprint("An email will be sent out. ")
class Aliexpress_Core(object):
  def __init__(self,window_index=[0,0,3.5,3.5],ph=True,exit_browser=True):
    setattrs(self,"username",a_shop().AliExpress_Email,"password",a_shop().AliExpress_Password,)
    self.rq = Aliexpress_Requests()()
class Aliexpress_Login:
  def __init__(self,window_index=[0,0,3.5,3.5],ph=False,exit_browser=True):
    setattrs(self,"ph",ph,"exit_browser",exit_browser,"window_index",window_index,"headers",session_headers,"username",Get(Shop,shop_abbreviation=Muta()().store_abbre).AliExpress_Email,"password",Get(Shop,shop_abbreviation=Muta()().store_abbre).AliExpress_Password,)
    globalise(Browser()( ("sele") ).get("https://login.aliexpress.com/").sp(5).tp(lambda:globe("ss_v").frame("alibaba-login-box")).bat().fid("fm-login-id").fid("fm-login-password").fcn("password-login").bat(self.username,self.password,globe("ss_v").SHADOW.ENTER).sp(10).tp(lambda: cookies_to_database(username=self.username,website_name="AliExpress",cookies=globe("ss_v").get_cookies(),reverse=False)).tp(lambda:setattr(self,"rq",cookies_to_session(cookies_to_database(self.username,"AliExpress"),requests.Session()))).tp(lambda:globe("ss_v").quit()if(self.exit_browser)else()),"ss")
  class Tracker_Updates:
    def run(self,shop):
      for i in onyx_lineitems("e1"):
        i.update_tracker_data() # events = self.get_tracking_events()
      for i in onyx_lineitems("e2"):
        if i.ali_order_number:
          i.update_tracker_data()
      for i in onyx_lineitems("e3"):
        if i.ali_order_number:
          i.update_tracker_data()
  class InventoryLevel:
    def adjust(self, shop, variant, available_adjustment):
      original = (variant.inventory_quantity if(dict!=type(variant))else(variant["inventory_quantity"]))
      calls =  ((Shop()(shop) if(str==type(shop))else(shop)).shopify.InventoryLevel.adjust(location_id=(Shop()(shop) if(str==type(shop))else(shop)).location_id, inventory_item_id = (variant.inventory_item_id if(dict!=type(variant))else(variant["inventory_item_id"])),available_adjustment = available_adjustment))
      
      while True:
        ensurement = ((Shop()(shop) if(str==type(shop))else(shop)).shopify.Variant.find(id_=(variant.id if(dict!=type(variant))else(variant["id"])))).inventory_quantity
        # here, use another call of the variant's inventory_quantity and compare it to the first; ensuring the original has increased or decreased by a quantity over the ladder.
        changed_amount = available_adjustment
        twine = (changed_amount) == ( ( ensurement.__sub__  ( original ) ))
        redprint( "changed_amount:%s\nensurement-original:%s"%((changed_amount), ( ( ensurement.__sub__  ( original ) ))))
        if twine == True:
          break
        else:
          redprint("||Waiting for updated inventory amount..")
          time.sleep(0.5)
      redprint("--end")
      assert (changed_amount) == ( ( ensurement.__sub__  ( original ) ))
      time.sleep(0.25)
      return calls


""" Business-Utils-Ad-Utils """
def Ads(shop):
  active_ads = adsFeed(shop, date_range=100, bd=True, filters='active')
  paused_ads = adsFeed(shop, date_range=7, bd=True, filters='paused')
  _ads_utils_daily_stop(adsets = active_ads)
  _ads_utils_daily_restart(adsets = paused_ads)
  try: shop.ff.quit()
  except: pass
def Ads_Duplicate(shop):
  """
  Download All Ad Sets
  Get All Campaigns via API
  For each Campaign:
    Get All Ads
    Targeting_Spec_Dict keying Ads Targeting_Specs
    
    For Each Targeting_Spec:
      Create a current_budget_list
      Discover count new_budgets
      Duplicate the $5 ad set Accordingly to the count_new_budgets & current_budget_list
  """
  count_of_newly_created_adsets = 0
  sum_of_newly_created_adsets_budget = 0

  #Download All Ad Sets
  csv_adsets = None
  if datetime.now().hour in [0,1,2]:
    csv_adsets = adsFeed(shop, date_range=1, bd=True, filters=None)
  else:
    csv_adsets = adsFeed(shop, date_range=0, bd=True, filters=None)

  errors=0

  #Create a Group of Active Campaign IDs
  campaigns = shop.fb.get_campaigns(params={'limit':9000})
  for campaign in campaigns:
    major_dict = {}
    adsets = campaign.get_ad_sets()
    for adset in adsets:
      targeting_spec = '%s' % adset.remote_read(fields=['targeting', 'daily_budget'])['targeting']._json
      print('targeting spec:\n%s\n\n\n'%targeting_spec)
      if targeting_spec not in major_dict.keys():
        major_dict[targeting_spec] = []
        major_dict[targeting_spec].append(adset)
      elif targeting_spec in major_dict.keys():
        major_dict[targeting_spec].append(adset)

    targeting_spec_count = len(major_dict.keys())
    print("targeting spec count: %s" % targeting_spec_count)
    for targeting_spec, adsets in major_dict.items():
      current_budget_list = sorted(list(map(int, key('daily_budget', adsets))), reverse=False)
      print("current budget list: %s" % current_budget_list)

      original_adset = None
      roi_list = []
      for adset in adsets:
        if adset['daily_budget'] == "500":
          original_adset = adset
        for csv_adset in csv_adsets:
          if csv_adset['Ad Set ID'] == adset['id']:
            roi_list.append(csv_adset['roi'])

      print("original_adset: %s" % original_adset['id'])
      print("roi_list: %s, count: %s" % (roi_list, len(roi_list)))

      count_of_good_rois = len([i for i in roi_list if i > 2])
      print("count of good rois: %s" % count_of_good_rois)
      new_budgets = list(range(max(current_budget_list) + 500, 40000, 500))[:count_of_good_rois]    
      print("new rois: %s" % new_budgets)


      for new_budget in new_budgets:
        try:
          new_adset, new_ad = Copy(shop, original_adset['id'])
          print("making a copy")
          new_adset['daily_budget'] = new_budget
          new_adset.remote_read(fields=['name', 'start_time', 'effective_status', ])
          new_adset.remote_update()
          print('new adset: %s\n' % new_adset)
          time.sleep(12)
          count_of_newly_created_adsets += 1
          sum_of_newly_created_adsets_budget += new_budget
        except:
          errors+=1
  print("error with duplication count is: %s"%errors)


  print('\n\n\n\n\n')
  print("sum of current_budget_today: %s" % (sum(list(map(int, key(csv_adsets, 'Budget'))))))
  print("sum of current_budget_today spent so far: %s" % (sum(list(map(float, key(csv_adsets, 'Amount Spent (USD)'))))))
  print("sum of purchases value today so far: %s" % (sum(list(map(float, key(csv_adsets, 'Website Purchases Conversion Value'))))))
  print("sum of purchases value target today: %s" % (sum(list(map(int, key(csv_adsets, 'Budget')))) * 2))
  print("count of newly created adsets: %s" % count_of_newly_created_adsets)
  print("sum of newly created adsets budgets: %s" % sum_of_newly_created_adsets_budget)
  print('\n\n\n\n\n')
  print('-'*20)
def _ads_utils_daily_restart(adsets):
  # ads_utils_restart_if_sale_in_last_20_spent
  # get_adm_url_by_ids(shop, id_list=restart_ids, date_range=180)
  # Directions: Just get_adm_url, and hit 'turn on'
  # delivery, inactive, go to ads, set bd-> daily, sort adname
  # ads_util_restart_adsets(id_list=restart_ids)

  if len(adsets) == 0:
    return
  adset_ids = key(adsets, key='Ad Set ID')
  
  # dict with key as adset_id
  data = dict(zip(adset_ids, [[] for i in range(len(adset_ids))]))
  # dict with values as all days with that adset_id
  for i in adsets:
    i['date'] = Date(i['Reporting Starts']).dateobj
  for a in data:
    for i in adsets:
      if i['Ad Set ID'] == a:
        data[a].append(i)
  # sort adsets based on date ordered past to future
  # sets spent, purchases, num_consec_bad to 0,0,0
  # for each adset_id, for each day in the value list, adds the spent, purchases.
  # if spent >20, purchases == 0, no matter the day, it is a bad consecutive adset.
  # if it is bad, sets spent, purchases, to 0,0 to restart count & not overlap
  # assigns num_consec_bad to adset's dict.
  for a in data:
    data[a] = keysort('date', data[a], tcer=False)
  for k,v in data.items():
    spent = 0
    purchases = 0
    num_consec_bad = 0
    for adset in v:
      spent += float(adset['Amount Spent (USD)'])
      purchases += float(adset['Website Purchases'])
      #print(spent, purchases)
      if spent > 20 and purchases == 0:
        num_consec_bad += 1
        purchases = 0
        spent = 0
      adset['num_consec_bad'] = num_consec_bad
    print('Ad Set ID: %s | num_consec_bad: %s' % (adset['Ad Set ID'], adset['num_consec_bad']))
  # sorts adsets ordered now to backthen
  # if num_consec_bad is > 3, do not restart
  # otherwise, counts from date now to backthen, if has purchase in last 20 spent, add to restart_id list.
  for a in data:
    data[a] = keysort('date', data[a], tcer=True)
  restart_ids = []
  for k,v in data.items():
    day = 0
    spent = 0
    purchases = 0
    for adset in v:
      day += 1
      spent += float(adset['Amount Spent (USD)'])
      purchases += float(adset['Website Purchases'])
      print("date: %s, spent: %s, pcs: %s" % (adset['date'], adset['Amount Spent (USD)'], adset['Website Purchases']))
      if day <= 4 and spent <= 20 and purchases > 0:
        if adset['num_consec_bad'] <= 2:
          print("will be restarted... ")
          restart_ids.append(int(adset['Ad Set ID'].replace('c:','')))
    print("\n\n\n")
  restart_ids = list(set(restart_ids))
  for _id in restart_ids:
    print("RESTART_IDS: %s"%_id)
  #get_adm_url_by_ids(shop, restart_ids, action='restart')
  _ads_utils_restart_adsets(list(set(restart_ids)))
def _ads_utils_daily_stop(adsets):
  if len(adsets) == 0:
    return
  print(""" If you want to check against it, generate list of pause_ids, 
            filter-> delivery: active,&go to ads,& set bd->daily,& sort adname.""")
  for i in adsets:
    i['id_'] = i['Ad Set ID'].replace('c:','')
    i['date'] = Date(i['Reporting Starts']).dateobj
  pause_ids = []
  adset_ids = list(set(key(adsets, key='id_')))
  for id in adset_ids:
    sorted_ads = keysort('date', keyequals('id_', id, adsets), tcer=True)
    spent = 0
    pcs = 0
    print('id: %s' % id)
    for adset in sorted_ads:
      spent += float(adset['Amount Spent (USD)'])
      pcs += float(adset['Website Purchases'])
      print("date: %s, spent: %s, pcs: %s" % (adset['date'], adset['spent'], adset['pcs']))
      if (spent >= 20 and pcs == 0):
        print("spend over 20: %s" % (spent - 20))
        pause_id = adset['id_']
        if pause_id not in pause_ids:
          pause_ids.append(pause_id)
          print("will be paused.")
    print('\n\n')
    time.sleep(8)

  _ads_utils_pause_adsets(pause_ids)


  #get_adm_url_by_ids(shop, pause_ids, action='pause')
  _ads_utils_pause_adsets(list(set(pause_ids)))
def _ads_utils_pause_adsets(id_list):
  id_list = list(set(id_list))
  for adset_id in list(set(id_list)):
    adset = AdSet(adset_id)
    adset['status'] = 'PAUSED'
    status_check = adset.remote_update()
    print("adset %s: %s √"%(adset_id, status_check))
    assert status_check['status'] == 'PAUSED'
    ad = adset.get_ads()[0]
    ad['status'] = "PAUSED"
    status_check = ad.remote_update()
    assert status_check['status'] == 'PAUSED'
    print("ad %s: %s √" % (ad['id'], status_check))
    print('\n\n')
    time.sleep(10)
    # tested and works
def _ads_utils_restart_adsets(id_list):
  for adset_id in id_list:
    adset = AdSet(adset_id)
    adset['status'] = 'ACTIVE'
    status_check = adset.remote_update()
    print("%s: %s √"%(adset_id, status_check))
    assert status_check['status'] == 'ACTIVE'
    ad = adset.get_ads()[0]
    ad["status"] = "ACTIVE"
    status_check = ad.remote_update()
    assert status_check['status'] == "ACTIVE"
    print("ad %s: %s √" % (ad['id'], status_check))
    print('\n\n')
    time.sleep(10)
    # tested and works
def _create_custom(handle, shop):
  print("...Creating Custom...")
  audience = CustomAudience(parent_id='act_%s' %shop.Facebook_Business_Ad_Account_ID); zz(12)
  print("Creating %s for handle: %s"%(audience, handle))
  params={'pixel_id': shop.Facebook_Pixel_ID,'subtype':'WEBSITE','retention_days':'180',
      'rule':{"url":{"i_contains": handle}}, 'name':handle,}
  custom = audience.remote_create(params=params)['id']
  print("Successfully Created Custom Audience... \n%s"%custom)
  return custom
def adjust_ad_columns():
  pyperclip.copy('x = document.getElementsByTagName("div")\ny = []\nz = x.length\nfor (i=0;i<z;i++) {a=x[i]; if (a.getAttribute("data-testid")=="FixedDataTableRow") {y=y.concat(a);}}\nb = y.length\nfor (i=0;i<b;i++) {\n                    a = y[i];\n                    c = a.getElementsByClassName("_4h2m");\n                    console.log(c.length);\n                    d = c[0]; d.style.width = "40px"; d.style.left = "0px";\n                    d = c[1]; d.style.width = "40px"; d.style.left = "40px";\n                    d = c[2]; d.style.width = "160px"; d.style.left = "80px";\n                    d = c[3]; d.style.width = "100px"; d.style.left = "0px";\n                    d = c[4]; d.style.width = "100px"; d.style.left = "100px";\n                    d = c[5]; d.style.width = "100px"; d.style.left = "200px";\n                    d = c[6]; d.style.width = "100px"; d.style.left = "300px";\n                    d = c[7]; d.style.width = "100px"; d.style.left = "400px";\n                    d = c[8]; d.style.width = "100px"; d.style.left = "500px";\n                    d = c[9]; d.style.width = "100px"; d.style.left = "600px";\n                    d = c[10]; d.style.width = "100px"; d.style.left = "700px";\n                    d = c[11]; d.style.width = "100px"; d.style.left = "800px";\n                    d = c[12]; d.style.width = "100px"; d.style.left = "900px";\n                    d = c[13]; d.style.width = "100px"; d.style.left = "1000px";\n                    d = c[14]; d.style.width = "100px"; d.style.left = "1100px";\n                    d = c[15]; d.style.width = "100px"; d.style.left = "1200px";\n                    d = c[16]; d.style.width = "100px"; d.style.left = "1300px";\n                    d = c[17]; d.style.width = "100px"; d.style.left = "1400px";\n                    e = a.getElementsByClassName("_3pzk");\n                    f = e[1]; f.style.width = "241px"; f.style.left = "241px";\n}\nx = document.getElementsByClassName("_1mic")[0];\ny = x.getElementsByClassName("_4h2m");\nz = y[0]; z.style.width = "40px"; z.style.left = "0px";\nz = y[1]; z.style.width = "40px"; z.style.left = "40px";\nz = y[2]; z.style.width = "160px"; z.style.left = "80px";\nz = y[3]; z.style.width = "100px"; z.style.left = "0px";\nz = y[4]; z.style.width = "100px"; z.style.left = "100px";\nz = y[5]; z.style.width = "100px"; z.style.left = "200px";\nz = y[6]; z.style.width = "100px"; z.style.left = "300px";\nz = y[7]; z.style.width = "100px"; z.style.left = "400px";\nz = y[8]; z.style.width = "100px"; z.style.left = "500px";\nz = y[9]; z.style.width = "100px"; z.style.left = "600px";\nz = y[10]; z.style.width = "100px"; z.style.left = "700px";\nz = y[11]; z.style.width = "100px"; z.style.left = "800px";\nz = y[12]; z.style.width = "100px"; z.style.left = "900px";\nz = y[13]; z.style.width = "100px"; z.style.left = "1000px";\nz = y[14]; z.style.width = "100px"; z.style.left = "1100px";\nz = y[15]; z.style.width = "100px"; z.style.left = "1200px";\nz = y[16]; z.style.width = "100px"; z.style.left = "1300px";\nz = y[17]; z.style.width = "100px"; z.style.left = "1400px";\ne = x.getElementsByClassName("_3pzk");\nf = e[1]; f.style.width = "241px"; f.style.left = "241px";\n\nx = document.getElementsByClassName("_1mme")[0];\ny = x.getElementsByClassName("_1eyi");\nz = y[0]; z.style.width = "40px"; z.style.left = "0px";\nz = y[1]; z.style.width = "40px"; z.style.left = "40px";\nz = y[2]; z.style.width = "160px"; z.style.left = "80px";\nz = y[3]; z.style.width = "100px"; z.style.left = "0px";\nz = y[4]; z.style.width = "100px"; z.style.left = "100px";\nz = y[5]; z.style.width = "100px"; z.style.left = "200px";\nz = y[6]; z.style.width = "100px"; z.style.left = "300px";\nz = y[7]; z.style.width = "100px"; z.style.left = "400px";\nz = y[8]; z.style.width = "100px"; z.style.left = "500px";\nz = y[9]; z.style.width = "100px"; z.style.left = "600px";\nz = y[10]; z.style.width = "100px"; z.style.left = "700px";\nz = y[11]; z.style.width = "100px"; z.style.left = "800px";\nz = y[12]; z.style.width = "100px"; z.style.left = "900px";\nz = y[13]; z.style.width = "100px"; z.style.left = "1000px";\nz = y[14]; z.style.width = "100px"; z.style.left = "1100px";\nz = y[15]; z.style.width = "100px"; z.style.left = "1200px";\nz = y[16]; z.style.width = "100px"; z.style.left = "1300px";\nz = y[17]; z.style.width = "100px"; z.style.left = "1400px";\ne = x.getElementsByClassName("_182x");\nf = e[1]; f.style.left = "241px";\n\n\nx = document.getElementsByClassName("_1mme")[0];\ny = x.getElementsByClassName("_4h2m");\nz = y[0]; z.style.width = "40px";\nz = y[1]; z.style.width = "40px";\nz = y[2]; z.style.width = "160px";\nz = y[3]; z.style.width = "100px";\nz = y[4]; z.style.width = "100px";\nz = y[5]; z.style.width = "100px";\nz = y[6]; z.style.width = "100px";\nz = y[7]; z.style.width = "100px";\nz = y[8]; z.style.width = "100px";\nz = y[9]; z.style.width = "100px";\nz = y[10]; z.style.width = "100px";\nz = y[11]; z.style.width = "100px";\nz = y[12]; z.style.width = "100px";\nz = y[13]; z.style.width = "100px";\nz = y[14]; z.style.width = "100px";\nz = y[15]; z.style.width = "100px";\nz = y[16]; z.style.width = "100px"; z.style.left = "1300px";\nz = y[17]; z.style.width = "100px"; z.style.left = "1400px";\ne = x.getElementsByClassName("_3pzk");\nf = e[1]; f.style.width = "241px"; f.style.left = "241px";\n')
  while True:
    chromejs("x = document.getElementsByTagName('div');y = [];z = x.length;for (i=0;i<z;i++) {a=x[i]; if (a.getAttribute('data-testid')=='FixedDataTableRow') {y=y.concat(a);}};b = y.length; for (i=0;i<b;i++) {a = y[i];c = a.getElementsByClassName('_4h2m');console.log(c.length);d = c[0]; d.style.width = '40px'; d.style.left = '0px';d = c[1]; d.style.width = '40px'; d.style.left = '40px';d = c[2]; d.style.width = '160px'; d.style.left = '80px';d = c[3]; d.style.width = '100px'; d.style.left = '0px';d = c[4]; d.style.width = '100px'; d.style.left = '100px';d = c[5]; d.style.width = '100px'; d.style.left = '200px';d = c[6]; d.style.width = '100px'; d.style.left = '300px';d = c[7]; d.style.width = '100px'; d.style.left = '400px';d = c[8]; d.style.width = '100px'; d.style.left = '500px';d = c[9]; d.style.width = '100px'; d.style.left = '600px';d = c[10]; d.style.width = '100px'; d.style.left = '700px';d = c[11]; d.style.width = '100px'; d.style.left = '800px';d = c[12]; d.style.width = '100px'; d.style.left = '900px';d = c[13]; d.style.width = '100px'; d.style.left = '1000px';d = c[14]; d.style.width = '100px'; d.style.left = '1100px';d = c[15]; d.style.width = '100px'; d.style.left = '1200px';d = c[16]; d.style.width = '100px'; d.style.left = '1300px';d = c[17]; d.style.width = '100px'; d.style.left = '1400px';e = a.getElementsByClassName('_3pzk');f = e[1]; f.style.width = '241px'; f.style.left = '241px';}; x = document.getElementsByClassName('_1mic')[0]; y = x.getElementsByClassName('_4h2m'); z = y[0]; z.style.width = '40px'; z.style.left = '0px'; z = y[1]; z.style.width = '40px'; z.style.left = '40px'; z = y[2]; z.style.width = '160px'; z.style.left = '80px'; z = y[3]; z.style.width = '100px'; z.style.left = '0px'; z = y[4]; z.style.width = '100px'; z.style.left = '100px'; z = y[5]; z.style.width = '100px'; z.style.left = '200px'; z = y[6]; z.style.width = '100px'; z.style.left = '300px'; z = y[7]; z.style.width = '100px'; z.style.left = '400px'; z = y[8]; z.style.width = '100px'; z.style.left = '500px'; z = y[9]; z.style.width = '100px'; z.style.left = '600px'; z = y[10]; z.style.width = '100px'; z.style.left = '700px'; z = y[11]; z.style.width = '100px'; z.style.left = '800px'; z = y[12]; z.style.width = '100px'; z.style.left = '900px'; z = y[13]; z.style.width = '100px'; z.style.left = '1000px'; z = y[14]; z.style.width = '100px'; z.style.left = '1100px'; z = y[15]; z.style.width = '100px'; z.style.left = '1200px'; z = y[16]; z.style.width = '100px'; z.style.left = '1300px'; z = y[17]; z.style.width = '100px'; z.style.left = '1400px'; e = x.getElementsByClassName('_3pzk'); f = e[1]; f.style.width = '241px'; f.style.left = '241px'; x = document.getElementsByClassName('_1mme')[0]; y = x.getElementsByClassName('_1eyi'); z = y[0]; z.style.width = '40px'; z.style.left = '0px'; z = y[1]; z.style.width = '40px'; z.style.left = '40px'; z = y[2]; z.style.width = '160px'; z.style.left = '80px'; z = y[3]; z.style.width = '100px'; z.style.left = '0px'; z = y[4]; z.style.width = '100px'; z.style.left = '100px'; z = y[5]; z.style.width = '100px'; z.style.left = '200px'; z = y[6]; z.style.width = '100px'; z.style.left = '300px'; z = y[7]; z.style.width = '100px'; z.style.left = '400px'; z = y[8]; z.style.width = '100px'; z.style.left = '500px'; z = y[9]; z.style.width = '100px'; z.style.left = '600px'; z = y[10]; z.style.width = '100px'; z.style.left = '700px'; z = y[11]; z.style.width = '100px'; z.style.left = '800px'; z = y[12]; z.style.width = '100px'; z.style.left = '900px'; z = y[13]; z.style.width = '100px'; z.style.left = '1000px'; z = y[14]; z.style.width = '100px'; z.style.left = '1100px'; z = y[15]; z.style.width = '100px'; z.style.left = '1200px'; z = y[16]; z.style.width = '100px'; z.style.left = '1300px'; z = y[17]; z.style.width = '100px'; z.style.left = '1400px'; e = x.getElementsByClassName('_182x'); f = e[1]; f.style.left = '241px'; x = document.getElementsByClassName('_1mme')[0]; y = x.getElementsByClassName('_4h2m'); z = y[0]; z.style.width = '40px'; z = y[1]; z.style.width = '40px'; z = y[2]; z.style.width = '160px'; z = y[3]; z.style.width = '100px'; z = y[4]; z.style.width = '100px'; z = y[5]; z.style.width = '100px'; z = y[6]; z.style.width = '100px'; z = y[7]; z.style.width = '100px'; z = y[8]; z.style.width = '100px'; z = y[9]; z.style.width = '100px'; z = y[10]; z.style.width = '100px'; z = y[11]; z.style.width = '100px'; z = y[12]; z.style.width = '100px'; z = y[13]; z.style.width = '100px'; z = y[14]; z.style.width = '100px'; z = y[15]; z.style.width = '100px'; z = y[16]; z.style.width = '100px'; z.style.left = '1300px'; z = y[17]; z.style.width = '100px'; z.style.left = '1400px'; e = x.getElementsByClassName('_3pzk'); f = e[1]; f.style.width = '241px'; f.style.left = '241px';")
    time.sleep(0.2)
def adsFeed(self, date_range=100, bd=True, filters=None):
  print("FEEDING ADSETS")
  self.ff = Browser()("sele", window_index=[0,0,4,4])
  url = format_url(self, date_range, bd, filters)
  self.ff.get(url)
  self.ff.fcss('._2a2d').click(); zz(6)
  try: adms = CSV().DictRead(time_a_download(method=self.ff.ffs('button','action','confirm').click))
  except: adms = CSV().DictRead(time_a_download(method=self.ff.fcn('layerConfirm').click))
  print('adms: %s'%adms)
  if 'No data available' in str(adms):
    print("no adsets")
    return []
  adms = [i for i in adms if i['Ad Set ID'] != '' and i['Ad Set Name'] != None and 'DPA' not in i['Ad Set Name']]
  for adm in adms:
    for a in adm:
      if adm[a] == '' or adm[a] == None:
        adm[a] = 0
    # adm['data'] = eval(adm['Ad Set Name'])
    adm['spent'] = float(adm['Amount Spent (USD)'])
    adm['pcv'] = float(adm['Website Purchases Conversion Value'])
    adm['pcs'] = float(adm['Website Purchases'])
    adm['cpc'] = float(adm['CPC (Cost per Link Click) (USD)'])
    adm['clicks'] = float(adm['Link Clicks'])
    adm['roi'] = float(adm['pcv']) / float(adm['spent']) if adm['spent'] != 0 else 0
  """
  print("...feedAudience...")
  for x in Audience.objects.all():
    x.pcs = 0
    x.roi = 0
    x.spent = 0.01
    x.pcv = 0
    
    matching_audiences = [i for i in adms if i['data']['audname'] == x.name]
    x.pcs += sum(key(matching_audiences, 'pcs'))
    x.spent += sum(key(matching_audiences, 'spent'))
    x.pcv += sum(key(matching_audiences, 'pcv'))
    x.roi += x.pcv / x.spent
    x.save()
  print("...feedProduct...")
  for x in Product.objects.all():
    x.pcs = 0
    x.roi = 0
    x.spent = 0.01
    x.pcv = 0
    
    x.pcs = sum([i['pcs'] for i in adms if i['data']['handle'] == x.handle])
    x.spent += sum([i['spent'] for i in adms if i['data']['handle'] == x.handle])
    x.pcv = sum([i['pcv'] for i in adms if i['data']['handle'] == x.handle])
    x.roi = x.pcv / x.spent
    print(x.pcs, x.spent, x.pcv, x.roi)
    x.save()
  """

  self.adms = adms
  self.ff.quit()
  return self.adms
def advertise():
  storeabbre = input("what store abbre?: ")
  shop = Shop()( storeabbre)
  BASE_ADSET_DICTIONARY = {'Ad ID': '','Ad Name': 'test','Ad Set Daily Budget': '5','Ad Set ID': '','Ad Set Lifetime Budget': '0','Ad Set Lifetime Impressions': '0','Ad Set Name': 'test','Ad Set Run Status': 'ACTIVE','Ad Set Schedule': '','Ad Set Time Start': '%s 2:00:00 am' % Date().dt(1, '%m/%d/%Y'),'Ad Set Time Stop': '','Ad Status': 'ACTIVE','Add End Card': '','Additional Custom Tracking Specs': '[]','Addresses': '','Age Max': '65','Age Min': '18','Android App Name': '','Android Package Name': '','App Destination': '','Application ID': '','Attribution Spec': '[{"event_type":"CLICK_THROUGH","window_days":7},{"event_type":"VIEW_THROUGH","window_days":1}]','Audience Network Positions': 'classic','Automatically Set Bid': 'Yes','Behaviors': '','Bid Amount': '','Billing Event': 'IMPRESSIONS','Body': '','Broad Category Clusters': '','Buying Type': 'AUCTION','Call to Action': '','Call to Action Link': '','Campaign ID': '','Campaign KPI': '','Campaign KPI Custom Conversion ID': '','Campaign Name': 'test','Campaign Objective': 'Conversions','Campaign Page ID': '','Campaign Spend Limit': '','Campaign Status': 'ACTIVE','Cities': '','College End Year': '','College Start Year': '','Connections': '','Conversion Tracking Pixels': 'tp:141019342913259','Countries': 'US','Creative Optimization': '','Creative Type': 'Photo Page Post Ad','Custom Audiences': '','Deep Link For Android': '','Deep Link For Windows Phone': '','Deep Link For iOS': '','Deep Link For iPad': '','Deep Link For iPhone': '','Deep link to website': '','Destination Type': 'UNDEFINED','Device Platforms': 'mobile, desktop','Display Link': '','Dynamic Ad Voice': '','Education Schools': '','Education Status': '','Electoral Districts': '','Event ID': '','Excluded Addresses': '','Excluded Cities': '','Excluded Connections': '','Excluded Countries': '','Excluded Custom Audiences': '','Excluded Electoral Districts': '','Excluded Geo Markets (DMA)': '','Excluded Global Regions': '','Excluded Product Audience Specs': '','Excluded Publisher Categories': '','Excluded Regions': '','Excluded User AdClusters': '','Excluded User Device': '','Excluded Zip': '','Facebook App ID': '','Facebook Positions': 'feed, right_hand_column','Family Statuses': '','Fields of Study': '','Flexible Exclusions': '','Flexible Inclusions': '[{"interests":[{"id":"6003324061606","name":"Audrey Hepburn"},{"id":"6003347600674","name":"Katharine Hepburn"},{"id":"6003392991271","name":"Rockabilly"},{"id":"6011957502962","name":"www.rockabilly-clothing.de"},{"id":"6013806088087","name":"Viva Las Vegas Rockabilly Weekend"}]}]','Force Single Link': '','Frequency Control': '','Friends of Connections': '','Gender': '','Generation': '','Geo Markets (DMA)': '','Global Regions': '','Home Ownership': '','Home Type': '','Home Value': '','Household Composition': '','Image': '83824348246.jpg','Image Crops': '','Image Hash': '','Image Overlay Float With Margin': '','Image Overlay Position': '','Image Overlay Template': '','Image Overlay Text Font': '','Image Overlay Text Type': '','Image Overlay Theme Color': '','Income': '','Industries': '','Instagram Account ID': '','Instagram Platform Image Crops': '','Instagram Platform Image Hash': '','Instagram Platform Image URL': '','Instagram Positions': '','Instagram Preview Link': '','Interested In': '','Lead Form ID': '','Life Events': '','Link': 'https://www.facebook.com/steampunkstop/photos/p.1998717263718262/1998717263718262/?type=3','Link Description': 'Auxiliary. We’ve Scourged Hotspots Of The Earth Mercilessly With Grandiose Detectors And Finally Our SteamBots Have Enchanted The Auxiliary Dress With Magnetic Seals To Affix Protection Spirits To It Permanently.\nClick Below 👇\nsteampunkstop.com/auxiliary','Link Object ID': 'o:1669573053299353','Locales': '','Location Types': 'home, recent','Messenger Positions': '','Mobile App Deep Link': '','Moms': '','Multicultural Affinity': '','Net Worth': '','Object Store URL': '','Offer ID': '','Office Type': '','Optimization Goal': 'OFFSITE_CONVERSIONS','Optimized Conversion Tracking Pixels': 'tp:141019342913259','Optimized Custom Conversion ID': '','Optimized Event': 'PURCHASE','Optimized Pixel Rule': '','Page Welcome Message': '','Permalink': 'https://business.facebook.com/1669573053299353/posts/1998717263718262?business_id=560484760766872','Place Page Set ID': '','Politics': '','Post Click Item Description': '','Post Click Item Headline': '','Preview Link': 'https://www.facebook.com/?feed_demo_ad=6095601486324&h=AQDKS_Ci6KEDEOCa','Product 1 - Description': '','Product 1 - Display Link': '','Product 1 - Image Crops': '','Product 1 - Image Hash': '','Product 1 - Is Static Card': '','Product 1 - Link': '','Product 1 - Mobile App Deep Link': '','Product 1 - Name': '','Product 1 - Place Data': '','Product 1 - Video ID': '','Product 10 - Description': '','Product 10 - Display Link': '','Product 10 - Image Crops': '','Product 10 - Image Hash': '','Product 10 - Is Static Card': '','Product 10 - Link': '','Product 10 - Mobile App Deep Link': '','Product 10 - Name': '','Product 10 - Place Data': '','Product 10 - Video ID': '','Product 2 - Description': '','Product 2 - Display Link': '','Product 2 - Image Crops': '','Product 2 - Image Hash': '','Product 2 - Is Static Card': '','Product 2 - Link': '','Product 2 - Mobile App Deep Link': '','Product 2 - Name': '','Product 2 - Place Data': '','Product 2 - Video ID': '','Product 3 - Description': '','Product 3 - Display Link': '','Product 3 - Image Crops': '','Product 3 - Image Hash': '','Product 3 - Is Static Card': '','Product 3 - Link': '','Product 3 - Mobile App Deep Link': '','Product 3 - Name': '','Product 3 - Place Data': '','Product 3 - Video ID': '','Product 4 - Description': '','Product 4 - Display Link': '','Product 4 - Image Crops': '','Product 4 - Image Hash': '','Product 4 - Is Static Card': '','Product 4 - Link': '','Product 4 - Mobile App Deep Link': '','Product 4 - Name': '','Product 4 - Place Data': '','Product 4 - Video ID': '','Product 5 - Description': '','Product 5 - Display Link': '','Product 5 - Image Crops': '','Product 5 - Image Hash': '','Product 5 - Is Static Card': '','Product 5 - Link': '','Product 5 - Mobile App Deep Link': '','Product 5 - Name': '','Product 5 - Place Data': '','Product 5 - Video ID': '','Product 6 - Description': '','Product 6 - Display Link': '','Product 6 - Image Crops': '','Product 6 - Image Hash': '','Product 6 - Is Static Card': '','Product 6 - Link': '','Product 6 - Mobile App Deep Link': '','Product 6 - Name': '','Product 6 - Place Data': '','Product 6 - Video ID': '','Product 7 - Description': '','Product 7 - Display Link': '','Product 7 - Image Crops': '','Product 7 - Image Hash': '','Product 7 - Is Static Card': '','Product 7 - Link': '','Product 7 - Mobile App Deep Link': '','Product 7 - Name': '','Product 7 - Place Data': '','Product 7 - Video ID': '','Product 8 - Description': '','Product 8 - Display Link': '','Product 8 - Image Crops': '','Product 8 - Image Hash': '','Product 8 - Is Static Card': '','Product 8 - Link': '','Product 8 - Mobile App Deep Link': '','Product 8 - Name': '','Product 8 - Place Data': '','Product 8 - Video ID': '','Product 9 - Description': '','Product 9 - Display Link': '','Product 9 - Image Crops': '','Product 9 - Image Hash': '','Product 9 - Is Static Card': '','Product 9 - Link': '','Product 9 - Mobile App Deep Link': '','Product 9 - Name': '','Product 9 - Place Data': '','Product 9 - Video ID': '','Product Audience Specs': '','Product Catalog ID': '','Product Link': '','Product Set ID': '','Publisher Platforms': 'facebook, audience_network','Rate Card': '','Regions': '','Relationship': '','Retailer IDs': '','Site Category': '','Story ID': '','Tags': '','Targeted Business Locations': '','Targeting Categories - ALL OF': '','Targeting Optimization': '','Template URL': '','Title': '','URL Tags': '','Unified Interests': '','Use Accelerated Delivery': 'No','Use Average Bid': 'No','Use Page as Actor': 'No','User Device': '','User OS Version': '','User Operating System': '','Video ID': '','Video Retargeting': 'No','Video Thumbnail URL': '','Windows App Name': '','Windows Store ID': '','Wireless Carrier': '','Work Employers': '','Work Job Titles': '','Zip': '','iOS App Name': '','iOS App Store ID': '','iPad App Name': '','iPad App Store ID': '','iPhone App Name': '','iPhone App Store ID': ''}




  DICTIONARYS_FOR_CSV = []






  products_csv=os.path.expanduser('~/tavern/tavern/products.csv')
  PRODUCTS_ROWS_DICTIONARYS = CSV().DictRead(products_csv)


  products = productsFeed(shop)
  FULL_EXTENSION_FILENAMES = []
  for ROW in PRODUCTS_ROWS_DICTIONARYS:

    if ROW["advertise?"] == "TRUE":
      p = [i for i in products if i["title"] == ROW["title"]][-1]
      p = shop.shopify.Product.find(id_=p['id'])




      caption = create_caption(p, shop, ROW['caption'], ROW["shopify_url"])



      NEW_DATA = copy.deepcopy(BASE_ADSET_DICTIONARY)
      NEW_DATA["Flexible Inclusions"] = ""
      NEW_DATA['Campaign Name'] = p.handle
      NEW_DATA['Ad Set Name'] = caption.replace("\n", " ")
      NEW_DATA['Ad Name'] = NEW_DATA['Ad Set Name']
      NEW_DATA['Display Link'] = caption
      NEW_DATA['Title'] = caption
      NEW_DATA['Body'] = caption
      NEW_DATA['Post Click Item Headline'] = caption
      NEW_DATA['Description'] = caption

      try:
        variant_id = int(ROW["shopify_url"].split("variant=")[-1])

        print("variant id: %s" )


        ############ FINDING MATCHING IMAGE FROM PRODUCT IMAGES BASED ON VARIANT ID

        img_id = None
        for i in p.variants:
          if i.id == variant_id:
            img_id = i.image_id
            print("Found matching img_id to URL %s" % url)
        variant_src = None
        for i in p.images:
          if i.id == img_id:
            variant_src = i.src
            print("Found matching variant_id to img_id.. %s" % variant_src)
        fn = None
        if variant_src is not None:
          fn = Images().download_and_resize(variant_src, 1200)
        if img_id is None: # this is in the case its a "1 Title Product"
          fn = Images().download_and_resize(p.image.src, 1200)
        print("image filename for the variant: %s" % fn)
        FULL_EXTENSION_FILENAMES.append(fn)
        NEW_DATA['Image'] = fn.split('/')[-1]

        pprint(NEW_DATA)

        DICTIONARYS_FOR_CSV.append(NEW_DATA)
      except Exception as e:
        print("error with possibly probably - the product has 0 variants and thus variantless URL, error:\n%s"% e )




  tmp_file = os.path.expanduser("~/tmp.csv")
  CSV().DictWrite(tmp_file, DICTIONARYS_FOR_CSV)

  ss = Browser()("sele")
  if not Get(Shop,shop_abbreviation=Muta()().store_abbre).Facebook_Business_Manager_ID:
    Update(Get(Shop,shop_abbreviation=Muta()().store_abbre),Facebook_Business_Manager_ID=OSA.log("Enter in the Facebook Business Manager ID. You can usually find it in the url like business_id=<Business ID>."))

  ss.get("https://business.facebook.com/ads/manage/powereditor/manage/campaigns?act={}&business_id={}&columns=start_time%2Ccampaign_group_name%2Cname%2Ccampaign_id%2Cimpressions%2Cfrequency%2Ccpm%2Cclicks%2Cctr%2Cactions%3Alink_click%2Ccost_per_action_type%3Alink_click%2Cspend%2Caction_values%3Aoffsite_conversion.fb_pixel_purchase%2Cactions%3Aoffsite_conversion.fb_pixel_purchase%2Ccost_per_action_type%3Aoffsite_conversion.fb_pixel_purchase%2Cactions%3Aoffsite_conversion.checkout%2Ccost_per_action_type%3Aoffsite_conversion.checkout%2Cbudget%2Crelevance_score%3Ascore%2Cwebsite_purchase_roas%3Aoffsite_conversion.fb_pixel_purchase&attribution_windows=default&date=2005-02-01_2017-12-31%2Clifetime".format(Get(Shop,shop_abbreviation=Muta()().store_abbre).Facebook_Business_Ad_Account_ID, Get(Shop,shop_abbreviation=Muta()().store_abbre).Facebook_Business_Manager_ID))
  
  #""" # OLD WITH FIREFOX
  try:
    ss.ffs('button','data-tooltip-content','Create & Edit in a Spreadsheet').click()
  except:
    ss.ffs('button','data-tooltip-content','Export & import').click()
  ss.ffss('li','role','presentation')[-2].click()
  ss.ffs('input','data-testid','import-paste-text-link').send_keys(tmp_file)
  IMAGE_UPLOAD_BUTTON = ss.ffs('input','accept','image/jpg, image/jpeg, image/gif, image/bmp, image/png, image/tiff, image/tif')

  for x in FULL_EXTENSION_FILENAMES:
    IMAGE_UPLOAD_BUTTON.send_keys(x)


  ss.ffs('button','data-testid','import-button').click()
  #"""
  while True:
    if "Your import is complete" in ss.page_source:
      time.sleep(3)
      break
  ss.quit()
  # advertise(url, p, caption)
def alter_redirect(shop_abbreviation, previous_path, new_path, new_target):
  redirects = get_redirects(Shop()(shop_abbreviation))
  redirect = [i for i in redirects if i.path == previous_path][0]
  redirect.path = new_path
  redirect.target = new_target
  assert True == redirect.save()
  assert requests.get("%s%s"%(Shop()(shop_abbreviation).Domain_Name,new_path)).url==new_target
def caption_tee():
  caption_to_tee = multi_input("caption to tee: ")
  os.system("echo '============================\n%s\n\n============================' | tee -a ./.teed_captions.txt" % caption_to_tee)
def check_remaining():
  page_name = OSA.log("Page name?")
  OSA.log("%s"%(len(get_scheduled_posts(page_name))))
def cloaker(io=None, direction=None):
  """ ::: Initiate Shop ::: """
  a_shop()
  """ ::: If you use July_Adset_Utilities to update all adset targeting data, to ::: """
  """ ::: Get the most accurate adset effective_status data, it's the same as ::: """
  """ ::: requesting all adset_ids in database, checking if active status, (to change adset name)::: """
  """ ::: So here I update adset targeting data  ///actually at direction==1.\\\::: """
  if direction == 0:
    import builtins
    if type(io) == builtins.dict:
      for adset_id,adset_name in io.items():
        AdSet(adset_id).remote_update(params={"name":adset_name})
        magentaprint(AdSet(adset_id).remote_read(fields=["name"])._json)
  elif direction == 1:
    July_Adset_Utilities().update_adset_targeting_data()
    dict = {}
    for adset in Filter(Adset,status="ACTIVE"):
      name = None
      try:
        name = AdSet(adset.adset_id).remote_read(fields=["name"])._json["name"]
      except Exception as e:
        redprint(e)
        continue
      redprint(adset.adset_id, name)
      dict[adset.adset_id] = name
      AdSet(adset.adset_id).remote_update(params={"name":"0000"})
    return dict
def createCreative(shop, fn, fb_page_id, caption):
  image = AdImage(parent_id='act_%s'%shop.Facebook_Business_Ad_Account_ID)
  image[AdImage.Field.filename] = fn
  image.remote_create()
  # Output image Hash
  print("hash: %s" % image[AdImage.Field.hash])
  photo_data = AdCreativePhotoData()
  photo_data['image_hash'] = image['hash']
  photo_data['caption'] = caption
  object_story_spec = AdCreativeObjectStorySpec()
  object_story_spec[AdCreativeObjectStorySpec.Field.page_id] = fb_page_id
  object_story_spec[AdCreativeObjectStorySpec.Field.photo_data] = photo_data
  creative = AdCreative(parent_id='act_%s'%shop.Facebook_Business_Ad_Account_ID)
  creative[AdCreative.Field.name] = 'AdCreative %s' % random.randrange(0, 10**10)
  creative[AdCreative.Field.object_story_spec] = object_story_spec
  creative.remote_create()
  print(creative)
  return creative
def create_ad(product=None,variant_id=None,store_abbre=None,niche=None,page=None,caption=None):
  short_url = create_redirect(Shop()(Muta()().store_abbre), path=("/%s"%(get_handle_from_title(product.title))), target=("%s/products/%s%s"%(Shop()(Muta()().store_abbre).Domain_Name,get_handle_from_title(product.title),("?variant=%s"%(or_list(variant_id,product.variants[0].id)) ))))
  # OSA.log("C")
  caption = caption.replace("<redirect_url>",short_url)
  # OSA.log("D")
  url = None
  if variant_id == None:
    url = product.images[0].src
  else:
    # OSA.log("%s %s"%(variant_id,type(product)))
    # variant = [i for i in product.variants if i.id == variant_id][0]
    # variant_image_id = variant.image_id
    # image = [i for i in product.images if i.id == variant_image_id][0]
    # image_src = image.src
    # if image_src == None:
    #   # 1
    #   image_src = product.images[0].src
    image_src = or_list(lambda:[j.src for j in product.images if j.id == [i for i in product.variants if i.id == variant_id][0]],lambda:product.images[0].src)
    url = image_src
  campaign_id, adset_id = AdsetCreater()(fbid=Shop()(Muta()().store_abbre).Facebook_Business_Ad_Account_ID,url=url,caption=caption,page_id=[i for i in get_pages() if i["name"] == Muta()().page][0]["id"],interest_ids=[])
  # OSA.log("E")
  Save(Adset, campaign_id=campaign_id, adset_id=adset_id, ad_account_id=Shop()(Muta()().store_abbre).Facebook_Business_Ad_Account_ID, is_created=True, handle=product.handle, niche=Muta()().niche, shop_abbreviation=Muta()().store_abbre, facebook_page=Muta()().page, product_url=short_url, image_url=product.images[0].src, caption=caption, interest_ids=[])
  # OSA.log("F")
  Update(product,adset_id=adset_id)
  # OSA.log("G")
  # OSA.log(str(adset_id))
  July_Adset_Utilities().update_advertisement_all(adset_id)
  # OSA.log("H")
  pool(lambda:OSA().log("adset created",tp=False))
def create_redirect(shop, path, target):
  path = path.lower().strip()
  target = target.lower().strip()

  redirect = shop.shopify.Redirect()
  # redirects = sum([shop.shopify.Redirect.find(status="any", limit=250, page=i) for i in range(1,10)],[])
  redirects = shop.shopify.Redirect.find(path=path)
  if path in key("path", redirects):
    x = [i for i in redirects if i.path == path]
    redirect = x[0]
    print("changing existing redirect of %s to %s"% (redirect.target, target))

  redirect.path = path
  redirect.target = target
  if not redirect.target.startswith("https://"): redirect.target = "https://%s"%redirect.target
  # [3/28/19] https:// required
  assert True == redirect.save()

  distinct_print("%s -----> %s" % (redirect.path, redirect.target))

  x = (shop.Domain_Name + redirect.path).replace("https://","").replace("http://","")
  return x
def export_a_video():
  shop, handle = OSA.log("Please enter the shop abbreviation and handle, separated by ', ', [for example: xyz, wall-decal]").split(", ")
  export_address = OSA.log("Please enter the address to export the video to [for example: /Users/user/video.mp4]")
  product = Get(Product,shop=shop,handle=handle)
  video = Get(Video,product_id = product.id)
  open(export_address,"wb").write(video.video)
def format_url(self, date_range, bd, filters):
  dates = '&date=%s_%s' % (Date().dt(date_range*-1), Date().dt(0))
  day_bd_url = 'https://business.facebook.com/ads/manager/account/adsets/?act='+self.Facebook_Business_Ad_Account_ID+dates+'&time_breakdown=days_1&columns=["start_time"%2C"campaign_group_name"%2C"name"%2C"campaign_id"%2C"impressions"%2C"frequency"%2C"cpm"%2C"clicks"%2C"ctr"%2C"actions%3Alink_click"%2C"cost_per_action_type%3Alink_click"%2C"spend"%2C"action_values%3Aoffsite_conversion.fb_pixel_purchase"%2C"actions%3Aoffsite_conversion.fb_pixel_purchase"%2C"cost_per_action_type%3Aoffsite_conversion.fb_pixel_purchase"%2C"actions%3Aoffsite_conversion.checkout"%2C"cost_per_action_type%3Aoffsite_conversion.checkout"%2C"budget"%2C"relevance_score%3Ascore"]&sort=cost_per_action_type%3Aoffsite_conversion.fb_pixel_purchase~1|delivery_info~1|spent~0|start_time~0&pid=p1'
  if bd==False:
    day_bd_url = day_bd_url.replace('&time_breakdown=days_1', '')
  if filters == 'paused':
    day_bd_url += '&filter_set=[{%22field%22%3A%22campaign.delivery_info%22%2C%22operator%22%3A%22IN%22%2C%22value%22%3A[%22inactive%22]}]'
  if filters == 'active':
    day_bd_url += '&filter_set=[{%22field%22%3A%22campaign.delivery_info%22%2C%22operator%22%3A%22IN%22%2C%22value%22%3A[%22active%22%2C%22limited%22]}]'
  return day_bd_url
def gen_adset_name(niche,audname,handle,budget)    :
  return str(OrderedDict([('niche',niche), ('audname',audname), ('handle',handle),
                          ('budget',budget) ]))
def get_next_scheduled_time(page,scheduled_posts):
  times_to_schedule = page.publish_times
  max_scheduled_time = or_list(lambda:max(sud("scheduled_publish_time",scheduled_posts)),lambda:Date()().replace(hour=times_to_schedule[-1]))
  max_scheduled_time_hour = max_scheduled_time.hour
  max_scheduled_time_date = max_scheduled_time
  max_scheduled_time_second = max_scheduled_time.second
  latest = times_to_schedule[-1]
  next_scheduled_time_hour = None
  next_scheduled_time_date = None
  if max_scheduled_time_hour == latest:
    next_scheduled_time_hour = times_to_schedule[0]
  else:
    index = times_to_schedule.index(max_scheduled_time_hour)
    next_index = index + 1
    next_scheduled_time_hour = times_to_schedule[next_index]
  if max_scheduled_time_hour == latest:
    next_scheduled_time_date = (Date(max_scheduled_time_date)+1)()
  else:
    next_scheduled_time_date = Date(max_scheduled_time_date)()
  next_scheduled_time = next_scheduled_time_date.replace(hour=next_scheduled_time_hour,second=max_scheduled_time_second)
  next_scheduled_time_timestamp = int(timestamp(next_scheduled_time))
  return next_scheduled_time_timestamp
def get_next_scheduled_times(page,publish_times,start_date,count):
  all_data = []
  page = Get(Facebookpage,name=page)
  start_idx = 0
  for i in range(count):
    new = start_date.replace(hour=publish_times[start_idx])
    start_idx = start_idx + 1
    if start_idx+1 > len(publish_times):
      start_idx = 0
      start_date = start_date + timedelta(days=1)
    all_data.append(new)
  return all_data
def get_pages():
  Shop()(All(Shop)[0].shop_abbreviation) # set the api
  user = get_user()
  pages = keycall("export_all_data", user.get_accounts(params={"limit":5000}))
  [tryprocess(Facebookpage(facebook_id=i["id"],name=i["name"],url="https://facebook.com/%s"%i["id"]).save,) for i in pages]
  [Update(Get(Facebookpage,facebook_id=i["id"]),token=i["access_token"]) for i in pages]
  [Update(Get(Facebookpage,facebook_id=i["id"]),publish_times = [14,19]) for i in pages]
  [Del(i) for i in All(Facebookpage) if i.name not in sud("name",pages)]
  return pages
def get_post_reactions(page_name, post_id):
  page = Get(Facebookpage, name = page_name)
  url = "https://graph.facebook.com/%s/reactions"%(post_id)
  token = page.token
  params = {"access_token":token, "fields":["total_count"],"summary":"total_count"}
  r = requests.get(url, params = params)
  data = json.loads(r.text)
  total_count = data["summary"]["total_count"]
  return total_count
def get_posted_posts(page_name):
  page = Get(Facebookpage, name = page_name)
  facebook_id = page.facebook_id
  url = "https://graph.facebook.com/%s/feed"%(facebook_id)
  token = page.token
  params = {"access_token":token, "fields":["created_time","message","id"], "limit":100}
  r = requests.get(url, params = params)
  all_data = []
  data = json.loads(r.text)["data"]
  all_data.extend(data)
  response = json.loads(r.text)
  while "next" in response.get("paging",[]):
    next_url = response["paging"]["next"]
    r = requests.get(next_url)
    response = json.loads(r.text)
    data = json.loads(r.text)["data"]
    all_data.extend(data)
  return all_data
def get_promoted_object():
  promoted_object = {    "custom_event_type": "PURCHASE",     "pixel_id": str(Shop()(adset_to_create.shop_abbreviation).Facebook_Pixel_ID),    "pixel_rule": "{\"event\":{\"eq\":\"Purchase\"}}"    }
  return promoted_object
def get_redirect_from_ad_copy(ad_copy):
  return re.findall(r"[:/a-zA-Z0-9]+\.[/a-zA-Z0-9-]+",body)
def get_redirects(shop):
  redirects = sum([shop.shopify.Redirect.find(status="any", limit=250, page=i) for i in range(1,10)],[])
  return redirects
def get_scheduled_posts(page_name):
  page = Get(Facebookpage, name = page_name)
  facebook_id = page.facebook_id
  url = "https://graph.facebook.com/%s/scheduled_posts"%(facebook_id)
  token = page.token
  params = {"access_token":token, "fields":["scheduled_publish_time"], "limit":100}
  r = requests.get(url, params = params)
  all_data = []
  data = json.loads(r.text)["data"]
  all_data.extend(data)
  response = json.loads(r.text)
  while "next" in response.get("paging",[]):
    next_url = response["paging"]["next"]
    r = requests.get(next_url)
    response = json.loads(r.text)
    data = json.loads(r.text)["data"]
    all_data.extend(data)
  [setitem(i,"scheduled_publish_time",timestamp(i["scheduled_publish_time"],False)) for i in all_data]
  return all_data
def get_url_from_body(x):
  return getitem(re.findall(".*/.*",x),0,"None").split(" ")[-1]
def get_user():
  a_shop()
  from facebookads.adobjects.user import User
  api = FacebookAdsApi.init(app_id=a_shop().Facebook_Business_App_ID,app_secret=a_shop().Facebook_Business_App_Secret,access_token=a_shop().Facebook_Business_App_Token)
  return User(fbid="me", api=api)
def print_sorted_audiences():
  auds = Audience.objects.all()
  auds = keysort('pcs', auds, tcer=True)
  CSV().csvprint(auds, colnames=['pcs','roi','spent','pcv', 'name', 'niche', 'id'])
def print_targeting_data(data):
  print("Targeting DATA for adset:\n\
          1. Age Min: %s\n\
          2. Age Max: %s\n\
          3. Gender: %s\n\
          4. Pixel Goals: %s\n\
          5. Attribution Spec: %s\n\
          6. Device Platforms: %s\n\
          7. Publisher Platforms: %s\n\
          8. Targeting Optimization: %s\n"%(data['targeting']['age_min'], data['targeting']['age_max'],
                                          data['targeting']['genders'], data['promoted_object']['custom_event_type'],
                                          data['attribution_spec'][0]['window_days'], data['targeting']['device_platforms'],
                                          data['targeting']['publisher_platforms'], data['targeting']['targeting_optimization']))
def run():
  products_csv=os.path.expanduser('~/tavern/tavern/products.csv')
  data = CSV().DictRead(products_csv)
  shop = Shop()(All(Shop)[0].shop_abbreviation)

  # dicts = []
  for i in data:
    if i['added'] == "FAILED":
      products = productsFeed(shop)
      for j in products:
        if j.title == i['title']:
          j.delete()
    if i['added'] == 'FALSE':
      p = Aliexpress_Products().create_product(i['url'].split('?')[0], i['niche'], i['item_type'], i['title'], i['description'])
      input("Adjust Images, State / Add to Body - ")
      url = input("Input URL: ")
      p = shop.shopify.Product.find(id_=p.id)
      caption = create_caption(p, shop, i['caption'], url)
      advertise(url, p, caption)


  print("Added items \n\n")
def s():
  a_shop()
def t_format_ids(ids):
  return [{"interests": [{'id':i} for i in ids]}]
def t_format_resp(resp):
  payload = []
  for i in resp:
    if i.get('valid',True) == True:
      payload.append({'id':i['id'], 'audience_size':i['audience_size'],'name':i['name'],
                      'category':i.get('disambiguation_category',''), 'topic':i.get('topic','')})
  return payload
def t_reach_estimate(shop, ids=None):
  account = AdAccount('act_%s'%shop.Facebook_Business_Ad_Account_ID)
  t_spec = {'age_max': 65,
           'age_min': 18,
           'audience_network_positions': ['classic', 'instream_video', 'rewarded_video'],
           'device_platforms': ['mobile', 'desktop'],
           'facebook_positions': ['feed', 'right_hand_column', 'instant_article'],
           'geo_locations': {'countries': ['US'], 'location_types': ['home']},
           'publisher_platforms': ['facebook', 'audience_network'],
           'targeting_optimization': 'none',
           'flexible_spec': []
           }
  # added this 2nd t_spec in as this is how based on 10/2018 targeting was by default
  t_spec = {'age_max': 65,
           'age_min': 18,
           #'audience_network_positions': ['classic', 'instream_video', 'rewarded_video'],
           'device_platforms': ['mobile'],
           'facebook_positions': ['feed'],
           'geo_locations': {'countries': ['US'],},
           'publisher_platforms': ['facebook'],
           'targeting_optimization': 'none',
           'flexible_spec': []
           }
  if ids:
    t_spec['flexible_spec'] = t_format_ids(ids)
  params = {
      #'currency': 'USD',
      #'optimize_for': AdSet.OptimizationGoal.offsite_conversions,
      'targeting_spec': t_spec, }
  reach_estimate = account.get_reach_estimate(params=params)
  return reach_estimate[0]["users"]
def t_search(q,limit=10000):
  resp = TargetingSearch.search(params={'q':q,'type':'adinterest','limit':limit})
  return t_format_resp(resp)
def t_suggestion(names):
  resp = TargetingSearch.search(params={'interest_list':list(names), 'type':'adinterestsuggestion', 'limit':10000})
  return t_format_resp(resp)
def update_adset_names_from_body_url():
  a_shop()
  for adset in Adset.objects.filter(is_created=True):
    url = get_url_from_body(adset.body)
    if "bit.ly" in url:
      url = requests.get(url).url.replace("/products","")
    x = AdSet(adset.adset_id)
    x.remote_read(fields=["name", "daily_budget", "targeting"])

    #name = url
    #name = "%s , %s" % (x["daily_budget"], url)
    name = "US %s-%s"%(x["targeting"]["age_min"], x["targeting"]["age_max"])
    if x["name"] != name:
      ad = x.get_ads()[0]
      x.remote_update(params={"name":name})
      ad.remote_update(params={"name":name})
class AdsetCreater:
  def __call__(self,fbid,url,caption,page_id,interest_ids=[]):
    try:
      """ ::: Make sure to Check If URL in CAPTION ie NO <redirect_url> &&, request200 url. ::: """
      try:get_url_from_body(caption)
      except Exception as e: redprint(e); return
      """ ::: request200 url ::: """

      #h = get_url_from_body(caption)
      """
      h = get_url_from_body( "".join(re.findall(r"[a-zA-Z0-9/:- .\n]",caption))  )
      while True:
        r = requests.get(h) if(h.startswith("http")) else (requests.get( ("https://"+h) ))
        t = r.url.split("/")[-1].split("?")[0]
        if(200!=r.status_code):
          redinput("(before Campaign Creation) \n 200!=status_code for %s\n\n\nASSOCIATED_CAPTION:\n%s\n\n" % (h,caption,"please fix the redirect or something, maybe it was erried"))
        elif(200==r.status_code):
          redprint("200==status_code for %s\n\n\nASSOCIATED_CAPTION:\n%s" % (h,caption))
          break
      """


      c = Campaign(parent_id="act_{}".format(fbid))
      c["name"] = "Conversions"
      c["buying_type"] = "AUCTION"
      c["objective"] = "CONVERSIONS"
      c.save()
      a = AdSet(parent_id="act_{}".format(fbid))
      #a["name"] = "US 18+"
      a["campaign_id"] = c["id"]
      a["daily_budget"] = 500
      a["name"] = "US 18+ "# + t
      a["optimization_goal"] = "OFFSITE_CONVERSIONS"
      a["promoted_object"] = {"custom_event_type": "PURCHASE", "pixel_id": Filter(Shop,Facebook_Business_Ad_Account_ID=fbid)[0].Facebook_Pixel_ID}
      a["start_time"] = "%s 6:00:00 EST"%(Date().dt(0) if datetime.now().hour in [0,1,2] else Date().dt(1))
      #@[2018.12.6 10:26 PM[mvdto(-1)]]a["start_time"] = "%s 5:00:00 EST"%(Date().dt(1) if datetime.now().hour in [0,1,2] else Date().dt(2))
      a["billing_event"] = "IMPRESSIONS"
      a["bid_strategy"] = "LOWEST_COST_WITHOUT_CAP"
      a["targeting"] = dict(age_min = 18,
                            device_platforms = ["mobile"],
                            facebook_positions = ["feed"],
                            publisher_platforms = ["facebook"],
                            targeting_optimization = "none",
                            geo_locations = {"countries": ["US"], "location_types": ["home", "recent"]},
                            flexible_spec = t_format_ids(interest_ids),
                            )
      a.save()
      v = Ad(parent_id="act_{}".format(fbid))
      #@[2018.12.8][Tried accessing nonexisting field (url_tags) on node type (Adgroup)]v["url_tags"] = "adset_id=%s"%(a["id"])
      v["name"] = "US 18+ "# + t
      v["adset_id"] = a["id"]
      (lambda fbid=fbid,url=url,caption=caption,page_id=page_id: [
      setitem(globals(),"image",AdImage(parent_id="act_{}".format(fbid)))  ,  
      #setitem(globals()["image"],"filename", Images().contrast_sharpen(Images().download_and_resize(url, 1200)))  ,  
      setitem(globals()["image"],"filename", Images().contrast_sharpen(Images().download_and_resize(url, 1200),contrast=True,sharpen=False))  ,  
      globals()["image"].remote_create()  ,  
      setitem(globals(),"photo_data",AdCreativePhotoData())  ,  
      setitem(globals()["photo_data"],"image_hash",globals()["image"]["hash"])  ,  
      setitem(globals()["photo_data"],"caption",caption)  ,  
      setitem(globals()["photo_data"],"page_welcome_message","Hello. Do you need any assistance?")  ,  
      setitem(globals(),"object_story_spec",AdCreativeObjectStorySpec())  ,  
      setitem(globals()["object_story_spec"],"page_id",page_id)  ,  
      setitem(globals()["object_story_spec"],"photo_data",globals()["photo_data"])  ,  
      setitem(globals(),"creative",AdCreative(parent_id="act_%s"%fbid))  ,  
      setitem(globals()["creative"],"name","Dark Post")  ,  
      setitem(globals()["creative"],"object_story_spec",globals()["object_story_spec"])  ,  
      setitem(globals()["creative"],"url_tags","&zcli=%s"%( Recompilate().recompilate(str(a["id"])).x ))  ,  
      "ajergcwonirgsncraoigncasdfkadpaksogranopgas;nrgoasingr"  ,  
      # globals()["creative"].remote_create()  ,  
      ])()
      v["creative"] = globals()["creative"]

      if ADSET_TESTING == True:
        a["status"] = "PAUSED"
        a.remote_update()

      v.save()
      return int(a["campaign_id"]), int(v["adset_id"])
    except Exception as e:
      redprint(e)
      redprint("deleting ")
      OSA.notify("deleting. ")
      OSA.notify(str(e))
      tryprocess(c.remote_delete); tryprocess(a.remote_delete); tryprocess(v.remote_delete)
class Adsetinsight_Algorithms:
  def one(self):
    """ ::: Get all adsethourlyinsights with sales. Then, keep adding impressions, get average hour/impression count of 1st sale. :::"""
    x = [keysort("date",Adsethourlyinsight.objects.filter(adset_id=i),tcer=False) for i in set(key("adset_id",Adsethourlyinsight.objects.all())) if list(set(key("website_purchase", Adsethourlyinsight.objects.filter(adset_id=i)))) != [0]]
    v = []
    for i in x:
      impressions = 0
      for idx,j in enumerate(i):
        impressions += j.impression
        if j.website_purchase != 0:
          v.append([impressions, idx])
          break
    print(  "hour       ", sum([b[1] for b in v])/len(v)  )
    print(  "impressions", sum([b[0] for b in v])/len(v)  )
  def one_data(self):
    """ ::: Get all adsethourlyinsights with sales. Then, keep adding impressions, get average hour/impression count of 1st sale. :::"""
    x = set(key("adset_id",Adsethourlyinsightdata.objects.all()))
    data = []
    for i in x:
      if list(set(key("website_purchase_move", Adsethourlyinsightdata.objects.filter(adset_id=i)))) != [0]:      
        data.append(keysort("date",Adsethourlyinsightdata.objects.filter(adset_id=i),tcer=False) )
    v = []
    for i in data:
      impression_moves = 0
      for idx,j in enumerate(i):
        impression_moves += j.impression_move
        if j.website_purchase_move != 0:
          v.append([impression_moves, idx])
          break
    print(  "hour       ", sum([b[1] for b in v])/len(v)  )
    print(  "impressions", sum([b[0] for b in v])/len(v)  )
  def two(self):
    for adset in Adset.objects.filter(is_created=True):
      if adset.status=="ACTIVE":
        data = keysort("date", Adsethourlyinsight.objects.filter(adset_id=adset.adset_id), tcer=False)
        impressions = 0; sales = 0
        for x in data:

          impressions+=x.impression
          sales+=x.website_purchase

          print(impressions, sales)
          if impressions > 500:
            if sales < 1:
              print("stop")
              print("[adset_id][%s]"%adset.adset_id)
              input("please check it, impressions: %s, sales: %s" % (impressions, sales))
              Adset(adset.adset_id).remote_update(params={"status":"PAUSED"})
class Interest_Tools(DecisionTree):
  def t_format_resp(self, resp):
    payload = []
    for i in resp:
      if i.get('valid',True) == True:
        payload.append({'id':i['id'], 'audience_size':i['audience_size'],'name':i['name'],
                        'category':i.get('disambiguation_category',''), 'topic':i.get('topic','')})
    return payload
  def t_search(self, q):
    resp = TargetingSearch.search(params={'q':q,'type':'adinterest','limit':10000})
    return self.t_format_resp(resp)
  def t_suggestion(self, names):
    resp = TargetingSearch.search(params={'interest_list':list(names), 'type':'adinterestsuggestion', 'limit':10000})
    return self.t_format_resp(resp)
  def t_format_ids(self, ids):
    return [{"interests": [{'id':i} for i in ids]}]
  def t_reach_estimate(self, shop, ids=None):
    account = AdAccount('act_%s'%shop.Facebook_Business_Ad_Account_ID)
    t_spec = {'age_max': 65,
             'age_min': 18,
             'audience_network_positions': ['classic', 'instream_video', 'rewarded_video'],
             'device_platforms': ['mobile', 'desktop'],
             'facebook_positions': ['feed', 'right_hand_column', 'instant_article'],
             'geo_locations': {'countries': ['US'], 'location_types': ['home']},
             'publisher_platforms': ['facebook', 'audience_network'],
             'targeting_optimization': 'none',
             'flexible_spec': []
             }
    if ids:
      t_spec['flexible_spec'] = self.t_format_ids(ids)
    params = {
        'currency': 'USD',
        'optimize_for': AdSet.OptimizationGoal.offsite_conversions,
        'targeting_spec': t_spec, }
    reach_estimate = account.get_reach_estimate(params=params)
    return reach_estimate[0]["users"]


  class InstagramBot:
    def __init__(self):
      self.bot = ExecutableText().export("InstagramBot")
  class October_Keyword_Utilities:
    #@[2018.11.23 02:44 PM][I took out the __init__ because i did print the exception in `pool` and i was not able to set the shop that many times in succession. i then got the api call must be set error and then i just set the shop in the beginning]
    t_format_ids = lambda self, ids: [{"interests": [{'id':i} for i in ids]}]
    def t_format_resp(self, resp):
      payload = []
      for i in resp:
        if i.get('valid',True) == True:
          payload.append({'id':i['id'], 'audience_size':i['audience_size'],'name':i['name'],
                          'category':i.get('disambiguation_category',''), 'topic':i.get('topic','')})
      return payload
    def receive_interest_dictlist(self, x, niche):
      """ ::: Problem: (1)Order (2)integer_ids ::: """
      """ ::: Solution: (1)integerify__forloop (2)keysort__id ::: """
      for i in x:   i["id"] = int(i["id"])
      x = keysort("id",x)
      if x not in key("keywordlist",All(Facebookkeywordlist)):
        Facebookkeywordlist(niche=niche, keywordlist=x, audience_size=October_Keyword_Utilities().re(x)).save()
    def re(self, io=None):
      if not io: return 1000000000
      ids = None
      """ ::: if io aint just ids, and its dictlist, ok, make ids the key("id"), else, ids=io(int list) ::: """
      if(type(io[0]) not in [str,int]):
        ids = key("id",io)
      else:
        ids = io
      account = AdAccount("act_%s"%(a_shop().Facebook_Business_Ad_Account_ID))
      t_spec = {'age_max': 65,
               'age_min': 18,
               'audience_network_positions': ['classic', 'instream_video', 'rewarded_video'],
               'device_platforms': ['mobile', 'desktop'],
               'facebook_positions': ['feed', 'right_hand_column', 'instant_article'],
               'geo_locations': {'countries': ['US'], 'location_types': ['home']},
               'publisher_platforms': ['facebook', 'audience_network'],
               'targeting_optimization': 'none',
               'flexible_spec': []
               }
      # automatic placements
      t_spec = {'age_max': 65,
               'age_min': 18,
               'geo_locations': {'countries': ['US'], 'location_types': ['home']},
               'targeting_optimization': 'none',
               'flexible_spec': []
               }
      # added this 2nd t_spec in as this is how based on 10/2018 targeting was by default
      # t_spec = {'age_max': 65,
      #          'age_min': 18,
      #          #'audience_network_positions': ['classic', 'instream_video', 'rewarded_video'],
      #          'device_platforms': ['mobile'],
      #          'facebook_positions': ['feed'],
      #          'geo_locations': {'countries': ['US'],},
      #          'publisher_platforms': ['facebook'],
      #          'targeting_optimization': 'none',
      #          'flexible_spec': []
      #          }
      if ids:
        t_spec['flexible_spec'] = t_format_ids(ids)
      params = {
          #'currency': 'USD',
          #'optimize_for': AdSet.OptimizationGoal.offsite_conversions,
          'targeting_spec': t_spec, }
      reach_estimate = account.get_reach_estimate(params=params)
      return reach_estimate[0]["users"]
    def t_search(self, q, limit=10000):
      resp = TargetingSearch.search(params={'q':q,'type':'adinterest','limit':limit})
      return t_format_resp(resp)
    def t_suggestion(self, names, limit=10000):
      resp = TargetingSearch.search(params={'interest_list':list(names), 'type':'adinterestsuggestion', 'limit':limit})
      return t_format_resp(resp)
    def se(self, q, limit=50):
      #@altered to achieve results with `,` or `\n`
      new = []
      for q in copy.deepcopy(q).replace("\n",",").split(","):
        x = [i for i in json.loads(requests.get(Muta()().targeting_search_url.format(q,limit)).text).get("data",[]) if("interests"==i["type"])      ]
        def pool_target(i):
          x = dict(id=int(i["id"]),name=i["name"],audience_size=Facebookkeyword.re( int(i["id"]) )  )
          return x
        if len(x) == 0:
          OSA.notify("No Results for `{}`".format(q))
          return []
        x = pool(pool_target, x, nodes=2).result()

        x = [Facebookkeyword(**i) for i in x]
        # keycall("save",x)
        for i in x: i.save()
        x = keycall("zone", x)
        new.extend(x)
      return new
    def su(self, ids, limit=50):
      targeting_list = json.dumps([{"id":i,"type":"interests"} for i in ids])
      redprint(targeting_list)
      x = [i for i in json.loads(requests.get(Muta()().targeting_suggestions_url.format(targeting_list,limit)).text).get("data",[]) if("interests"==i["type"]) ]
      def pool_target(i):
        x = dict(id=int(i["id"]),name=i["name"],audience_size=Facebookkeyword.re( int(i["id"]) )  )
        redprint("hello")
        return x
      x = pool(pool_target, x, nodes=15).result()

      x = [Facebookkeyword(**i) for i in x]
      keycall("save",x)
      #return keysort("audience_size", x)
      x = keycall("zone", x)
      return x
  class July_Adset_Utilities:
    def __init__(self):
      r""" This is important since looking at it now I forget the parameters and it looks as if i did not write any of it before"""
      #self.shop = shop
      # keep these for storage purposes
      a_shop()
      self.data_all_fields = ["spend","adset_id","date","frequency","impression","impression_cost","impression_rate","post_click","post_click_cost","post_click_rate","click","click_cost","click_rate","add_to_cart","add_to_cart_cost","add_to_cart_rate","website_purchase","website_purchase_cost","website_purchase_rate","spend","website_purchase_value","return_on_investment","reach","reach_cost","reach_rate","landing_page_view","landing_page_view_cost","landing_page_view_rate","fb_pixel_view_content","fb_pixel_view_content_cost","fb_pixel_view_content_rate","fb_pixel_initiate_checkout","fb_pixel_initiate_checkout_cost","fb_pixel_initiate_checkout_rate","page_engagement","page_engagement_cost","page_engagement_rate","post_engagement","post_engagement_cost","post_engagement_rate","post_reaction","post_reaction_cost","post_reaction_rate"]
      self.data_fields = ["spend","adset_id","date","frequency","impression","impression_cost","impression_rate","post_click","post_click_cost","post_click_rate","click","click_cost","click_rate","add_to_cart","add_to_cart_cost","add_to_cart_rate","website_purchase","website_purchase_cost","website_purchase_rate","spend","website_purchase_value","return_on_investment"]
      self.get_insight_fields = ["adset_id", "action_values", "actions", "adset_name", "clicks", "date_start", "date_stop", "frequency", "impressions", "reach", "relevance_score", "spend"]
      self.get_insight_params = {"time_increment": 1, "time_range": {"since": (Date()-0).datestr,"until": (Date()-0).datestr}}
    def get_campaigns(self, limit = 500):
      return self.shop.fb.get_campaigns(params = {"limit": limit})
    def get_adsets(self, campaign_id, limit = 500):
      scope_campaign = Campaign(campaign_id)
      adsets = scope_campaign.get_ad_sets(params = {"limit": limit})
      return adsets
    def pause_adset(self, adset_id):
      input("is this ok?: ")
      shop = Shop()( Adset.objects.get(adset_id=adset_id).shop_abbreviation)
      adset = AdSet(adset_id)
      adset["status"] = "PAUSED"
      status_check = adset.remote_update()
      print("adset %s: %s √"%(adset_id, status_check))
      assert status_check['status'] == 'PAUSED'
      Update(Get(Adset,adset_id=adset_id),status="PAUSED")
    def restart_adset(self, adset_id):
      input("is this ok?: ")
      shop = Shop()( Adset.objects.get(adset_id=adset_id).shop_abbreviation)
      adset = AdSet(adset_id)
      adset["status"] = "ACTIVE"
      status_check = adset.remote_update()
      print("adset %s: %s √"%(adset_id, status_check))
      assert status_check['status'] == 'ACTIVE'
      Update(Get(Adset,adset_id=adset_id),status="ACTIVE")
    def update_adset(self, id):
      new = Get(Adset,adset_id=id)
      data = AdSet(new.adset_id).remote_read(fields=["campaign_id","id"])
      new.campaign_id = data["campaign_id"]
      new.adset_id = data["id"]
      new.save()
    def update_adsetinsight_data(self, id, date_start = 5, date_end = 0, time_increment = 1, fields = ["adset_id", "action_values", "actions", "adset_name", "clicks", "date_start", "date_stop", "frequency", "impressions", "reach", "relevance_score", "spend"]):
      adset = Filter(Adset, adset_id=id)[0]
      self.shop = Shop()( adset.shop_abbreviation)
      data = [AttrDict(i.export_all_data()) for i in AdSet(adset.adset_id).get_insights(fields = fields, params={"time_increment": time_increment, "time_range": {"since": (Date()-date_start).datestr,"until": (Date()-date_end).datestr}})]
      for i in data:
        new = Adsetinsight()
        existing = Adsetinsight.objects.filter(adset_id = adset.adset_id, date = Date().myDatetimenow(Date(i.date_start).dateobj))
        if len(existing) == 1:
          new = existing[0]
          print("an existing")


        actions = i.get("actions", {})
        action_values = i.get("action_values", {})
        actions_dict = AttrDict(dict(zip(key("action_type", actions), key("value", actions))))
        action_values_dict = AttrDict(dict(zip(key("action_type", action_values), key("value", action_values))))

        spend = round(float(i.spend), 4)
        adset_id = adset.adset_id
        date = Date().myDatetimenow(Date(i.date_start).dateobj)
        frequency = round(float(i.frequency), 4)
        impression = int(i.impressions)
        if(0==impression):continue
        impression_cost = round(float(tryreturn(lambda: spend / impression)), 4)
        impression_rate = 0
        post_click = int(i.clicks)
        post_click_cost = round(float(tryreturn(lambda: spend / post_click)), 4)
        post_click_rate = round(float(tryreturn(lambda: post_click / impression)), 4)
        click = int(actions_dict.get("link_click", 0))
        click_cost = round(float(tryreturn(lambda: spend / click)), 4)
        click_rate = round(float(tryreturn(lambda: click / impression)), 4)
        add_to_cart = int(actions_dict.get("offsite_conversion.fb_pixel_add_to_cart", 0))
        add_to_cart_cost = round(float(tryreturn(lambda: spend / add_to_cart)), 4)
        try:add_to_cart_rate = round(float(tryreturn(lambda: add_to_cart / impression)), 4)
        except:add_to_cart_rate = 0 #(?)
        website_purchase = int(actions_dict.get("offsite_conversion.fb_pixel_purchase", 0))
        ##conversion_pixel_purchase = int(actions_dict.get("offsite_conversion", 0))
        ##if website_purchase > 0 and conversion_pixel_purchase == 0:
        ##  website_purchase = website_purchase
        ##if website_purchase > 0 and conversion_pixel_purchase > 0:
        ##  website_purchase = ((website_purchase+conversion_pixel_purchase) / 2)
        ##if website_purchase == 0 and conversion_pixel_purchase > 0:
        ##  website_purchase = conversion_pixel_purchase

        website_purchase_cost = round(float(tryreturn(lambda: spend / website_purchase)), 4)
        website_purchase_rate = round(float(tryreturn(lambda: website_purchase / impression)), 4)
        spend = round(float(i.spend), 4)
        website_purchase_value = round(float(action_values_dict.get("offsite_conversion.fb_pixel_purchase", 0)), 4)
        return_on_investment = round(float(tryreturn(lambda: website_purchase_value / spend)), 4)
        reach = int(i.reach)
        reach_cost = round(float(tryreturn(lambda: spend / reach)), 4)
        reach_rate = 0
        landing_page_view = int(actions_dict.get("landing_page_view", 0))
        landing_page_view_cost = round(float(tryreturn(lambda: spend / landing_page_view)), 4)
        landing_page_view_rate = round(float(tryreturn(lambda: landing_page_view / impression)), 4)
        fb_pixel_view_content = int(actions_dict.get("offsite_conversion.fb_pixel_view_content", 0))
        fb_pixel_view_content_cost = round(float(tryreturn(lambda: spend / fb_pixel_view_content)), 4)
        fb_pixel_view_content_rate = round(float(fb_pixel_view_content / impression), 4)
        fb_pixel_initiate_checkout = int(actions_dict.get("offsite_conversion.fb_pixel_initiate_checkout", 0))
        fb_pixel_initiate_checkout_cost = round(float(tryreturn(lambda: spend / fb_pixel_initiate_checkout)), 4)
        fb_pixel_initiate_checkout_rate = round(float(fb_pixel_initiate_checkout / impression), 4)
        page_engagement = int(actions_dict.get("page_engagement", 0))
        page_engagement_cost = round(float(tryreturn(lambda: spend / page_engagement)), 4)
        page_engagement_rate = round(float(page_engagement / impression), 4)
        post_engagement = int(actions_dict.get("post_engagement", 0))
        post_engagement_cost = round(float(tryreturn(lambda: spend / post_engagement)), 4)
        post_engagement_rate = round(float(post_engagement / impression), 4)
        post_reaction = int(actions_dict.get("post_reaction", 0))
        post_reaction_cost = round(float(tryreturn(lambda: spend / post_reaction)), 4)
        post_reaction_rate = round(float(post_reaction / impression), 4)


        greenprint("[update_adsetinsight_data][spend][%s]"% spend)
        greenprint("[update_adsetinsight_data][adset_id][%s]"% adset_id)
        greenprint("[update_adsetinsight_data][date][%s]"% date)
        greenprint("[update_adsetinsight_data][frequency][%s]"% frequency)
        greenprint("[update_adsetinsight_data][impression][%s]"% impression)
        greenprint("[update_adsetinsight_data][impression_cost][%s]"% impression_cost)
        greenprint("[update_adsetinsight_data][impression_rate][%s]"% impression_rate)
        greenprint("[update_adsetinsight_data][post_click][%s]"% post_click)
        greenprint("[update_adsetinsight_data][post_click_cost][%s]"% post_click_cost)
        greenprint("[update_adsetinsight_data][post_click_rate][%s]"% post_click_rate)
        greenprint("[update_adsetinsight_data][click][%s]"% click)
        greenprint("[update_adsetinsight_data][click_cost][%s]"% click_cost)
        greenprint("[update_adsetinsight_data][click_rate][%s]"% click_rate)
        greenprint("[update_adsetinsight_data][add_to_cart][%s]"% add_to_cart)
        greenprint("[update_adsetinsight_data][add_to_cart_cost][%s]"% add_to_cart_cost)
        greenprint("[update_adsetinsight_data][add_to_cart_rate][%s]"% add_to_cart_rate)
        greenprint("[update_adsetinsight_data][website_purchase][%s]"% website_purchase)
        greenprint("[update_adsetinsight_data][website_purchase_cost][%s]"% website_purchase_cost)
        greenprint("[update_adsetinsight_data][website_purchase_rate][%s]"% website_purchase_rate)
        greenprint("[update_adsetinsight_data][spend][%s]"% spend)
        greenprint("[update_adsetinsight_data][website_purchase][%s]"% website_purchase_value)
        greenprint("[update_adsetinsight_data][offsite_conversion][%s]"% website_purchase_value)
        greenprint("[update_adsetinsight_data][website_purchase_value][%s]"% website_purchase_value)
        greenprint("[update_adsetinsight_data][return_on_investment][%s]"% return_on_investment)
        greenprint("[update_adsetinsight_data][reach][%s]"% reach)
        greenprint("[update_adsetinsight_data][reach_cost][%s]"% reach_cost)
        greenprint("[update_adsetinsight_data][reach_rate][%s]"% reach_rate)
        greenprint("[update_adsetinsight_data][landing_page_view][%s]"% landing_page_view)
        greenprint("[update_adsetinsight_data][landing_page_view_cost][%s]"% landing_page_view_cost)
        greenprint("[update_adsetinsight_data][landing_page_view_rate][%s]"% landing_page_view_rate)
        greenprint("[update_adsetinsight_data][fb_pixel_view_content][%s]"% fb_pixel_view_content)
        greenprint("[update_adsetinsight_data][fb_pixel_view_content_cost][%s]"% fb_pixel_view_content_cost)
        greenprint("[update_adsetinsight_data][fb_pixel_view_content_rate][%s]"% fb_pixel_view_content_rate)
        greenprint("[update_adsetinsight_data][fb_pixel_initiate_checkout][%s]"% fb_pixel_initiate_checkout)
        greenprint("[update_adsetinsight_data][fb_pixel_initiate_checkout_cost][%s]"% fb_pixel_initiate_checkout_cost)
        greenprint("[update_adsetinsight_data][fb_pixel_initiate_checkout_rate][%s]"% fb_pixel_initiate_checkout_rate)
        greenprint("[update_adsetinsight_data][page_engagement][%s]"% page_engagement)
        greenprint("[update_adsetinsight_data][page_engagement_cost][%s]"% page_engagement_cost)
        greenprint("[update_adsetinsight_data][page_engagement_rate][%s]"% page_engagement_rate)
        greenprint("[update_adsetinsight_data][post_engagement][%s]"% post_engagement)
        greenprint("[update_adsetinsight_data][post_engagement_cost][%s]"% post_engagement_cost)
        greenprint("[update_adsetinsight_data][post_engagement_rate][%s]"% post_engagement_rate)
        greenprint("[update_adsetinsight_data][post_reaction][%s]"% post_reaction)
        greenprint("[update_adsetinsight_data][post_reaction_cost][%s]"% post_reaction_cost)
        greenprint("[update_adsetinsight_data][post_reaction_rate][%s]"% post_reaction_rate)


        new.spend = spend
        new.ad_account_id = self.shop.Facebook_Business_Ad_Account_ID
        new.adset_id = adset_id
        new.date = date
        new.frequency = frequency
        new.impression = impression
        new.impression_cost = impression_cost
        new.impression_rate = impression_rate
        new.post_click = post_click
        new.post_click_cost = post_click_cost
        new.post_click_rate = post_click_rate
        new.click = click
        new.click_cost = click_cost
        new.click_rate = click_rate
        new.add_to_cart = add_to_cart
        new.add_to_cart_cost = add_to_cart_cost
        new.add_to_cart_rate = add_to_cart_rate
        new.website_purchase = website_purchase
        new.website_purchase_cost = website_purchase_cost
        new.website_purchase_rate = website_purchase_rate
        new.spend = spend
        new.website_purchase_value = website_purchase_value
        new.return_on_investment = return_on_investment
        new.reach = reach
        new.reach_cost = reach_cost
        new.reach_rate = reach_rate
        new.landing_page_view = landing_page_view
        new.landing_page_view_cost = landing_page_view_cost
        new.landing_page_view_rate = landing_page_view_rate
        new.fb_pixel_view_content = fb_pixel_view_content
        new.fb_pixel_view_content_cost = fb_pixel_view_content_cost
        new.fb_pixel_view_content_rate = fb_pixel_view_content_rate
        new.fb_pixel_initiate_checkout = fb_pixel_initiate_checkout
        new.fb_pixel_initiate_checkout_cost = fb_pixel_initiate_checkout_cost
        new.fb_pixel_initiate_checkout_rate = fb_pixel_initiate_checkout_rate
        new.page_engagement = page_engagement
        new.page_engagement_cost = page_engagement_cost
        new.page_engagement_rate = page_engagement_rate
        new.post_engagement = post_engagement
        new.post_engagement_cost = post_engagement_cost
        new.post_engagement_rate = post_engagement_rate
        new.post_reaction = post_reaction
        new.post_reaction_cost = post_reaction_cost
        new.post_reaction_rate = post_reaction_rate


        new.save()
    # https://developers.facebook.com/docs/marketing-api/click-tags
    def update_adsethourlyinsight_data(self, id, date_start = 5, date_end = 0, time_increment = 1, breakdowns=["hourly_stats_aggregated_by_advertiser_time_zone"], fields = ["adset_id", "action_values", "actions", "adset_name", "clicks", "date_start", "date_stop", "frequency", "impressions", "reach", "relevance_score", "spend"]):
      """
      date_start = 800
      date_end = 0
      time_increment = 1
      breakdowns=["hourly_stats_aggregated_by_advertiser_time_zone"]
      fields = ["adset_id", "action_values", "actions", "adset_name", "clicks", "date_start", "date_stop", "frequency", "impressions", "reach", "relevance_score", "spend"]
      insights = adset.get_insights(fields = fields, params={"time_increment": time_increment, "time_range": {"since": (Date()-date_start).datestr,"until": (Date()-date_end).datestr}}       )
      """
      # used to be date_start = 0 and date_end = 0, it only gets data for `today` but it could end early, ie, @/3hrs, date_start= 1 would have been better
      # 
      adset = Filter(Adset,adset_id=id)[0]
      self.shop = Shop()( adset.shop_abbreviation)
      data = [AttrDict(i.export_all_data()) for i in AdSet(adset.adset_id).get_insights(fields = fields, params={"breakdowns": breakdowns, "time_increment": time_increment, "time_range": {"since": (Date()-date_start).datestr,"until": (Date()-date_end).datestr}})]

      for i in data:
        new = Adsethourlyinsight()
        date = (round((int(i.hourly_stats_aggregated_by_advertiser_time_zone.split(" - ")[0].split(":")[0])/24),2)+Date().myDatetimenow(Date(i.date_start).dateobj)  )
        distinct_print("[%s][%s]"%(date,i.hourly_stats_aggregated_by_advertiser_time_zone))
        for d in range(24):
          tryprocess(Adsethourlyinsight(ad_account_id=self.shop.Facebook_Business_Ad_Account_ID, date=(Date().myDatetimenow(Date(i.date_start).dateobj)+round((d/24),2)), adset_id=i.adset_id ).save)
        existing = Adsethourlyinsight.objects.filter(adset_id = adset.adset_id, date = date)
        if len(existing) == 1:
          new = existing[0]
          print("an existing")


        actions = i.get("actions", {})
        action_values = i.get("action_values", {})
        actions_dict = AttrDict(dict(zip(key("action_type", actions), key("value", actions))))
        action_values_dict = AttrDict(dict(zip(key("action_type", action_values), key("value", action_values))))

        spend = round(float(i.spend), 4)
        adset_id = adset.adset_id
        #date = Date().myDatetimenow(Date(i.date_start).dateobj)
        #frequency = round(float(i.frequency), 4)
        impression = int(i.impressions)
        if(0==impression):continue
        impression_cost = round(float(tryreturn(lambda: spend / impression)), 4)
        impression_rate = 0
        post_click = int(i.clicks)
        post_click_cost = round(float(tryreturn(lambda: spend / post_click)), 4)
        post_click_rate = round(float(tryreturn(lambda: post_click / impression)), 4)
        click = int(actions_dict.get("link_click", 0))
        click_cost = round(float(tryreturn(lambda: spend / click)), 4)
        click_rate = round(float(tryreturn(lambda: click / impression)), 4)
        add_to_cart = int(actions_dict.get("offsite_conversion.fb_pixel_add_to_cart", 0))
        add_to_cart_cost = round(float(tryreturn(lambda: spend / add_to_cart)), 4)
        try:add_to_cart_rate = round(float(tryreturn(lambda: add_to_cart / impression)), 4)
        except:add_to_cart_rate = 0 #(?)
        website_purchase = int(actions_dict.get("offsite_conversion.fb_pixel_purchase", 0))
        #conversion_pixel_purchase = int(actions_dict.get("offsite_conversion", 0))
        #if website_purchase > 0 and conversion_pixel_purchase == 0:
        #  website_purchase = website_purchase
        #if website_purchase > 0 and conversion_pixel_purchase > 0:
        #  website_purchase = ((website_purchase+conversion_pixel_purchase) / 2)
        #if website_purchase == 0 and conversion_pixel_purchase > 0:
        #  website_purchase = conversion_pixel_purchase
        website_purchase_cost = round(float(tryreturn(lambda: spend / website_purchase)), 4)
        website_purchase_rate = round(float(tryreturn(lambda: website_purchase / impression)), 4)
        spend = round(float(i.spend), 4)
        website_purchase_value = round(float(action_values_dict.get("offsite_conversion.fb_pixel_purchase", 0)), 4)
        return_on_investment = round(float(tryreturn(lambda: website_purchase_value / spend)), 4)
        #reach = int(i.reach)
        #reach_cost = round(float(tryreturn(lambda: spend / reach)), 4)
        #reach_rate = 0
        landing_page_view = int(actions_dict.get("landing_page_view", 0))
        landing_page_view_cost = round(float(tryreturn(lambda: spend / landing_page_view)), 4)
        landing_page_view_rate = round(float(tryreturn(lambda: landing_page_view / impression)), 4)
        fb_pixel_view_content = int(actions_dict.get("offsite_conversion.fb_pixel_view_content", 0))
        fb_pixel_view_content_cost = round(float(tryreturn(lambda: spend / fb_pixel_view_content)), 4)
        fb_pixel_view_content_rate = round(float(fb_pixel_view_content / impression), 4)
        fb_pixel_initiate_checkout = int(actions_dict.get("offsite_conversion.fb_pixel_initiate_checkout", 0))
        fb_pixel_initiate_checkout_cost = round(float(tryreturn(lambda: spend / fb_pixel_initiate_checkout)), 4)
        fb_pixel_initiate_checkout_rate = round(float(fb_pixel_initiate_checkout / impression), 4)
        page_engagement = int(actions_dict.get("page_engagement", 0))
        page_engagement_cost = round(float(tryreturn(lambda: spend / page_engagement)), 4)
        page_engagement_rate = round(float(page_engagement / impression), 4)
        post_engagement = int(actions_dict.get("post_engagement", 0))
        post_engagement_cost = round(float(tryreturn(lambda: spend / post_engagement)), 4)
        post_engagement_rate = round(float(post_engagement / impression), 4)
        post_reaction = int(actions_dict.get("post_reaction", 0))
        post_reaction_cost = round(float(tryreturn(lambda: spend / post_reaction)), 4)
        post_reaction_rate = round(float(post_reaction / impression), 4)



        new.spend = spend
        new.ad_account_id = self.shop.Facebook_Business_Ad_Account_ID
        new.adset_id = adset_id
        new.date = date
        #new.frequency = frequency
        new.impression = impression
        new.impression_cost = impression_cost
        new.impression_rate = impression_rate
        new.post_click = post_click
        new.post_click_cost = post_click_cost
        new.post_click_rate = post_click_rate
        new.click = click
        new.click_cost = click_cost
        new.click_rate = click_rate
        new.add_to_cart = add_to_cart
        new.add_to_cart_cost = add_to_cart_cost
        new.add_to_cart_rate = add_to_cart_rate
        new.website_purchase = website_purchase
        new.website_purchase_cost = website_purchase_cost
        new.website_purchase_rate = website_purchase_rate
        new.spend = spend
        new.website_purchase_value = website_purchase_value
        new.return_on_investment = return_on_investment
        #new.reach = reach
        #new.reach_cost = reach_cost
        #new.reach_rate = reach_rate
        new.landing_page_view = landing_page_view
        new.landing_page_view_cost = landing_page_view_cost
        new.landing_page_view_rate = landing_page_view_rate
        new.fb_pixel_view_content = fb_pixel_view_content
        new.fb_pixel_view_content_cost = fb_pixel_view_content_cost
        new.fb_pixel_view_content_rate = fb_pixel_view_content_rate
        new.fb_pixel_initiate_checkout = fb_pixel_initiate_checkout
        new.fb_pixel_initiate_checkout_cost = fb_pixel_initiate_checkout_cost
        new.fb_pixel_initiate_checkout_rate = fb_pixel_initiate_checkout_rate
        new.page_engagement = page_engagement
        new.page_engagement_cost = page_engagement_cost
        new.page_engagement_rate = page_engagement_rate
        new.post_engagement = post_engagement
        new.post_engagement_cost = post_engagement_cost
        new.post_engagement_rate = post_engagement_rate
        new.post_reaction = post_reaction
        new.post_reaction_cost = post_reaction_cost
        new.post_reaction_rate = post_reaction_rate


        #new.save()
        new.save()
    def update_adsetinsight_data_find_which_adset_had_the_order(self, date_start = 0, date_end = 0, time_increment = 1, fields = ["adset_id", "action_values", "actions", "adset_name", "clicks", "date_start", "date_stop", "frequency", "impressions", "reach", "relevance_score", "spend"], is_a_shopify_order_match_check=False, is_a_shopify_order_match_check_orders=[]):
      redprint("Running 'update_adsetinsight_data_find_which_adset_had_the_order' ... ")
      for adset in Adset.objects.filter(is_created=True):
        self.shop = Shop()( adset.shop_abbreviation)
        data = [AttrDict(i.export_all_data()) for i in AdSet(adset.adset_id).get_insights(fields = fields, params={"time_increment": time_increment, "time_range": {"since": (Date()-date_start).datestr,"until": (Date()-date_end).datestr}})]
        adset_shopify_order_matches = []
        for i in data:
          new = Adsetinsight()
          existing = Adsetinsight.objects.filter(adset_id = adset.adset_id, date = Date().myDatetimenow(Date(i.date_start).dateobj))
          if len(existing) == 1:
            new = existing[0]
            print("an existing")


          actions = i.get("actions", {})
          action_values = i.get("action_values", {})
          actions_dict = AttrDict(dict(zip(key("action_type", actions), key("value", actions))))
          action_values_dict = AttrDict(dict(zip(key("action_type", action_values), key("value", action_values))))

          spend = round(float(i.spend), 4)
          adset_id = adset.adset_id
          date = Date().myDatetimenow(Date(i.date_start).dateobj)
          frequency = round(float(i.frequency), 4)
          impression = int(i.impressions)
          if(0==impression):continue
          impression_cost = round(float(tryreturn(lambda: spend / impression)), 4)
          impression_rate = 0
          post_click = int(i.clicks)
          post_click_cost = round(float(tryreturn(lambda: spend / post_click)), 4)
          post_click_rate = round(float(tryreturn(lambda: post_click / impression)), 4)
          click = int(actions_dict.get("link_click", 0))
          click_cost = round(float(tryreturn(lambda: spend / click)), 4)
          click_rate = round(float(tryreturn(lambda: click / impression)), 4)
          add_to_cart = int(actions_dict.get("offsite_conversion.fb_pixel_add_to_cart", 0))
          add_to_cart_cost = round(float(tryreturn(lambda: spend / add_to_cart)), 4)
          try:add_to_cart_rate = round(float(tryreturn(lambda: add_to_cart / impression)), 4)
          except:add_to_cart_rate = 0 #(?)
          website_purchase = int(actions_dict.get("offsite_conversion.fb_pixel_purchase", 0))
          #conversion_pixel_purchase = int(actions_dict.get("offsite_conversion", 0))
          #if website_purchase > 0 and conversion_pixel_purchase == 0:
          #  website_purchase = website_purchase
          #if website_purchase > 0 and conversion_pixel_purchase > 0:
          #  website_purchase = ((website_purchase+conversion_pixel_purchase) / 2)
          #if website_purchase == 0 and conversion_pixel_purchase > 0:
          #  website_purchase = conversion_pixel_purchase
          website_purchase_cost = round(float(tryreturn(lambda: spend / website_purchase)), 4)
          website_purchase_rate = round(float(tryreturn(lambda: website_purchase / impression)), 4)
          spend = round(float(i.spend), 4)
          website_purchase_value = round(float(action_values_dict.get("offsite_conversion.fb_pixel_purchase", 0)), 4)
          return_on_investment = round(float(tryreturn(lambda: website_purchase_value / spend)), 4)
          reach = int(i.reach)
          reach_cost = round(float(tryreturn(lambda: spend / reach)), 4)
          reach_rate = 0
          landing_page_view = int(actions_dict.get("landing_page_view", 0))
          landing_page_view_cost = round(float(tryreturn(lambda: spend / landing_page_view)), 4)
          landing_page_view_rate = round(float(tryreturn(lambda: landing_page_view / impression)), 4)
          fb_pixel_view_content = int(actions_dict.get("offsite_conversion.fb_pixel_view_content", 0))
          fb_pixel_view_content_cost = round(float(tryreturn(lambda: spend / fb_pixel_view_content)), 4)
          fb_pixel_view_content_rate = round(float(fb_pixel_view_content / impression), 4)
          fb_pixel_initiate_checkout = int(actions_dict.get("offsite_conversion.fb_pixel_initiate_checkout", 0))
          fb_pixel_initiate_checkout_cost = round(float(tryreturn(lambda: spend / fb_pixel_initiate_checkout)), 4)
          fb_pixel_initiate_checkout_rate = round(float(fb_pixel_initiate_checkout / impression), 4)
          page_engagement = int(actions_dict.get("page_engagement", 0))
          page_engagement_cost = round(float(tryreturn(lambda: spend / page_engagement)), 4)
          page_engagement_rate = round(float(page_engagement / impression), 4)
          post_engagement = int(actions_dict.get("post_engagement", 0))
          post_engagement_cost = round(float(tryreturn(lambda: spend / post_engagement)), 4)
          post_engagement_rate = round(float(post_engagement / impression), 4)
          post_reaction = int(actions_dict.get("post_reaction", 0))
          post_reaction_cost = round(float(tryreturn(lambda: spend / post_reaction)), 4)
          post_reaction_rate = round(float(post_reaction / impression), 4)

          if is_a_shopify_order_match_check == True:
            if len(existing) == 1:
              if existing[0].website_purchase > website_purchase:
                print("Found a new conversion for this Ad Set. Adding it to ")
                adset_shopify_order_matches.append(existing[0])
          print("\n")
          redprint("adset-shopify-order-matches: %s | is_a_shopify_order_match_check_orders (count of shopify orders): %s" % (len(adset_shopify_order_matches), len(is_a_shopify_order_match_check_orders)) )
          print("\n")
          """ since this is so bad: the factors are   [count_new_purchases, count_new_orders, count_new_adsets, matching_by_order_difference, and how badly this matters,--  of course you can assume 1 order at most per minute]"""
          # run analysis here, -2 indents b/c the assumption is for i in data(of adset) iterates through 1 adset | keep it here, which will be fine for the next since you are saving the variables: order AND adset
          if   (is_a_shopify_order_match_check==True)   and   (len(adset_shopify_order_matches)==1)   and   (len(is_a_shopify_order_match_check_orders)==1)  :
            adset_shopify_order_match = adset_shopify_order_matches[0]
            adset_shopify_order_match.order_ids.append(is_a_shopify_order_match_check_orders[0].id)
            adset_shopify_order_match.save()
          #elif (is_a_shopify_order_match_check==True)   and   (len(adset_shopify_order_matches)!=len(is_a_shopify_order_match_check_orders))  :
          #  """ This will occur if  for example: is_a_shopify_order_match_check_orders > 1, say 2.     if 2 is unequal to count of   adset_shopify_order_matches,;;˚ then you got 2 sales in shopify confirmed, and less than 1/0 adsets   had new orders.                """
          #  """Assuming a 0-10 second Pixel-Update timeframe--   you will want to solve the case of if 0 adset_shopify_order_matches exist, which is simply assuming `should-have-posted` and assuming `nothing-new-purchasesed` """
          #  """ then is the case of a different sort of match: [where you have to choose which order_id of the 2 orders to update to the adset  ]   \route 1: exacting the closer order_created_time(seconds) to the adset_update_time   \route 2: exacting the closer order amount/2 to the adset.  \ """
          #  """ so route 1: can i find the purchase time to the minute or second ( i dont know)"""
          #  for adset in adset_shopify_order_matches:
          #    price_differences = []
          #    for shopify_order in is_a_shopify_order_match_check_orders:
          #      adset_value_increase = website_purchase_value - existing[0].website_purchase_value
          #      price_difference  = adset_value_increase - total_price
          #      price_differences.append([shopify_order, price_difference])
          #    smallest_difference = min(price_differences)
          #    for price_difference in price_differences:
          #      if price_difference[1] == smallest_difference:
          #        print("price_difference of %s == smallest_difference: %s"% (price_difference[1], smallest_difference))
          #        shopify_order = price_difference[0]
          #        adset.order_ids = [] if adset.order_ids == None else adset.order_ids
          #        adset.order_ids.append(shopify.order_id)
          #        print("adset of id: %s which has previous conversion value of %s and now current conversion value of %s now is matched with order id: %s of total amount %s" % (existing[0].adset_id, existing[0].website_purchase_value, website_purchase_value, shopify_order.id, shopify_order.total_amount))
          #elif (is_a_shopify_order_match_check==True)   and   (len(adset_shopify_order_matches)!=len(is_a_shopify_order_match_check_orders))  :
          #  # try to match by price as well. assuming 2 new orders, 2 new adsets with orders.        if the case 2 new orders 1 new adset with orders, then due to the price match -- that 1 new adset will 
          #  for adset in adset_shopify_order_matches:
          #    price_differences = []
          #    for shopify_order in is_a_shopify_order_match_check_orders:
          #      adset_value_increase = website_purchase_value - existing[0].website_purchase_value
          #      price_difference  = adset_value_increase - total_price
          #      price_differences.append([shopify_order, price_difference])
          #    smallest_difference = min(price_differences)
          #    for price_difference in price_differences:
          #      if price_difference[1] == smallest_difference:
          #        print("price_difference of %s == smallest_difference: %s"% (price_difference[1], smallest_difference))
          #        shopify_order = price_difference[0]
          #        adset.order_ids = [] if adset.order_ids == None else adset.order_ids
          #        adset.order_ids.append(shopify.order_id)
          #        print("adset of id: %s which has previous conversion value of %s and now current conversion value of %s now is matched with order id: %s of total amount %s" % (existing[0].adset_id, existing[0].website_purchase_value, website_purchase_value, shopify_order.id, shopify_order.total_amount))


          print("spend: %s"% spend)
          print("adset_id: %s"% adset_id)
          print("date: %s"% date)
          print("frequency: %s"% frequency)
          print("impression: %s"% impression)
          print("impression_cost: %s"% impression_cost)
          print("impression_rate: %s"% impression_rate)
          print("post_click: %s"% post_click)
          print("post_click_cost: %s"% post_click_cost)
          print("post_click_rate: %s"% post_click_rate)
          print("click: %s"% click)
          print("click_cost: %s"% click_cost)
          print("click_rate: %s"% click_rate)
          print("add_to_cart: %s"% add_to_cart)
          print("add_to_cart_cost: %s"% add_to_cart_cost)
          print("add_to_cart_rate: %s"% add_to_cart_rate)
          print("website_purchase: %s"% website_purchase)
          print("website_purchase_cost: %s"% website_purchase_cost)
          print("website_purchase_rate: %s"% website_purchase_rate)
          print("spend: %s"% spend)
          print("website_purchase_value: %s"% website_purchase_value)
          print("return_on_investment: %s"% return_on_investment)
          print("reach: %s"% reach)
          print("reach_cost: %s"% reach_cost)
          print("reach_rate: %s"% reach_rate)
          print("landing_page_view: %s"% landing_page_view)
          print("landing_page_view_cost: %s"% landing_page_view_cost)
          print("landing_page_view_rate: %s"% landing_page_view_rate)
          print("fb_pixel_view_content: %s"% fb_pixel_view_content)
          print("fb_pixel_view_content_cost: %s"% fb_pixel_view_content_cost)
          print("fb_pixel_view_content_rate: %s"% fb_pixel_view_content_rate)
          print("fb_pixel_initiate_checkout: %s"% fb_pixel_initiate_checkout)
          print("fb_pixel_initiate_checkout_cost: %s"% fb_pixel_initiate_checkout_cost)
          print("fb_pixel_initiate_checkout_rate: %s"% fb_pixel_initiate_checkout_rate)
          print("page_engagement: %s"% page_engagement)
          print("page_engagement_cost: %s"% page_engagement_cost)
          print("page_engagement_rate: %s"% page_engagement_rate)
          print("post_engagement: %s"% post_engagement)
          print("post_engagement_cost: %s"% post_engagement_cost)
          print("post_engagement_rate: %s"% post_engagement_rate)
          print("post_reaction: %s"% post_reaction)
          print("post_reaction_cost: %s"% post_reaction_cost)
          print("post_reaction_rate: %s"% post_reaction_rate)


          new.spend = spend
          new.ad_account_id = self.shop.Facebook_Business_Ad_Account_ID
          new.adset_id = adset_id
          new.date = date
          new.frequency = frequency
          new.impression = impression
          new.impression_cost = impression_cost
          new.impression_rate = impression_rate
          new.post_click = post_click
          new.post_click_cost = post_click_cost
          new.post_click_rate = post_click_rate
          new.click = click
          new.click_cost = click_cost
          new.click_rate = click_rate
          new.add_to_cart = add_to_cart
          new.add_to_cart_cost = add_to_cart_cost
          new.add_to_cart_rate = add_to_cart_rate
          new.website_purchase = website_purchase
          new.website_purchase_cost = website_purchase_cost
          new.website_purchase_rate = website_purchase_rate
          new.spend = spend
          new.website_purchase_value = website_purchase_value
          new.return_on_investment = return_on_investment
          new.reach = reach
          new.reach_cost = reach_cost
          new.reach_rate = reach_rate
          new.landing_page_view = landing_page_view
          new.landing_page_view_cost = landing_page_view_cost
          new.landing_page_view_rate = landing_page_view_rate
          new.fb_pixel_view_content = fb_pixel_view_content
          new.fb_pixel_view_content_cost = fb_pixel_view_content_cost
          new.fb_pixel_view_content_rate = fb_pixel_view_content_rate
          new.fb_pixel_initiate_checkout = fb_pixel_initiate_checkout
          new.fb_pixel_initiate_checkout_cost = fb_pixel_initiate_checkout_cost
          new.fb_pixel_initiate_checkout_rate = fb_pixel_initiate_checkout_rate
          new.page_engagement = page_engagement
          new.page_engagement_cost = page_engagement_cost
          new.page_engagement_rate = page_engagement_rate
          new.post_engagement = post_engagement
          new.post_engagement_cost = post_engagement_cost
          new.post_engagement_rate = post_engagement_rate
          new.post_reaction = post_reaction
          new.post_reaction_cost = post_reaction_cost
          new.post_reaction_rate = post_reaction_rate


          #new.save()
          new.save()
    # 2. Stop AdSets based on today- data
    def stop_adset_based_on_today_data(self, id):

      todays_date = int(Date().myDatetimenow())
      # check it out. i filtered adset insights to those which will have the id.
      adsetinsights = Adsetinsight.objects.filter(date=todays_date, adset_id=id)
      #cyanprint("[Count active today][%s]"%len(adsetinsights))
      for adsetinsight in adsetinsights:
        if Adset.objects.get(adset_id=adsetinsight.adset_id).status == "ACTIVE":
          if (adsetinsight.spend >= 20 and adsetinsight.website_purchase == 0):#   or   (adsetinsight.impression_cost > .015 and adsetinsight.website_purchase == 0):
            redprint("[stop_adsets_based_on_today_data][%s][%s][%s] [%s]['!=OK']"%(adsetinsight.adset_id,adsetinsight.spend,adsetinsight.impression_cost,adsetinsight.website_purchase))
            July_Adset_Utilities().pause_adset(adset_id=adsetinsight.adset_id)
          else:
            greenprint("[%s][%s][%s] [%s]['OK']"%(adsetinsight.adset_id,adsetinsight.spend,adsetinsight.impression_cost,adsetinsight.website_purchase))
    # 1. Stop AdSets based on summation data
    def stop_adset_based_on_past_data(self, id):
      # maybe i should print out in sentences?  as when i read the data fields, i'm having to utter words in my head to transmit the data through my brain
      todays_date = int(Date().myDatetimenow())
      # check it out, i filtered adset insights to those containing this id as the adset_id
      adsetinsights = Adsetinsight.objects.filter(date=todays_date, adset_id=id)
      print("[Count active today][%s]"%len(adsetinsights))
      """ this will be a unique iteration for adsetinsights with date(delivery) today AND with adset_id """  
      adset_ids_unique = list(sorted(list(set(key("adset_id", adsetinsights)))))
      for adset_id in adset_ids_unique:
        adsetinsights = Adsetinsight.objects.filter(adset_id = adset_id)
        adsetinsights = keysort("date", adsetinsights)
        spend = 0
        website_purchase = 0
        days = 0
        cyanprint("[%s][activedays][%s]"%(adset_id,len(adsetinsights)))
        for adsetinsight in adsetinsights:
          spend += adsetinsight.spend
          website_purchase += adsetinsight.website_purchase
          days += 1
          #input("? ? ? ? ? ? ? ? ?")
          if Adset.objects.get(adset_id=adsetinsight.adset_id).status == "ACTIVE":
            if (spend >= 20   and   website_purchase == 0):
              redprint("[stop_adsets_based_on_past_data][%s][%s][%s][%s]['!=OK']"%(adsetinsight.date, days, spend, website_purchase))
              July_Adset_Utilities().pause_adset(adset_id=adsetinsight.adset_id)
            else:
              greenprint("[%s][%s][%s][%s]['OK']"%(adsetinsight.date, days, spend, website_purchase))
    def restart_adset_based_on_today_data(self, id):
      # Goal Is Restart If Sale
      #todays_date = int(Date().myDatetimenow())
      #adsetinsights = Adsetinsight.objects.filter(date=todays_date)
      #cyanprint("[Count active today][%s]"%len(adsetinsights))
      #for adsetinsight in adsetinsights:
      #  if Adset.objects.get(adset_id=adsetinsight.adset_id).status == "PAUSED":
      #    print(adsetinsight.id, adsetinsight.website_purchase)
      #    if (adsetinsight.website_purchase > 0):
      #      redprint("[restart_adsets_based_on_today_data][%s][%s][%s] [%s]['!=OK']"%(adsetinsight.adset_id,adsetinsight.spend,adsetinsight.impression_cost,adsetinsight.website_purchase))
      #      July_Adset_Utilities().restart_adset(adset_id=adsetinsight.adset_id)
      #    else:
      #      greenprint("[%s][%s][%s][%s] [%s]['OK']"%(adsetinsight.id,adsetinsight.adset_id,adsetinsight.spend,adsetinsight.impression_cost,adsetinsight.website_purchase))
      todays_date = int(Date().myDatetimenow())
      adsetinsight = tryreturn(Get, Adsetinsight, date=todays_date)
      if(0==adsetinsight): print("No adsetinsight to restart adset on todays data with"); return
      


      print(adsetinsight.id, adsetinsight.website_purchase)
      if (adsetinsight.website_purchase > 0):
        greenprint("[restart_adsets_based_on_today_data][%s][%s][%s] [%s]['!=OK']"%(adsetinsight.adset_id,adsetinsight.spend,adsetinsight.impression_cost,adsetinsight.website_purchase))
        July_Adset_Utilities().restart_adset(adset_id=adsetinsight.adset_id)
      else:
        redprint("[%s][%s][%s][%s] [%s]['OK']"%(adsetinsight.id,adsetinsight.adset_id,adsetinsight.spend,adsetinsight.impression_cost,adsetinsight.website_purchase))
        todays_date = int(Date().myDatetimenow())
            
      print(adsetinsight.id, adsetinsight.website_purchase)
      adsetinsight.save()
    def update_ad_keyword_data(self, id):
      time.sleep(2)
      distinct_print("\nupdate_ad_keyword_data\n")
      fields = ["actions", "clicks", "frequency", "impressions", "reach", "spend",]
      #if (Adset.objects.get(adset_id=adset_id).date_last_requested_keyword_stats != None) and ( (int(Date().myDatetimenow()) - Adset.objects.get(adset_id=adset_id).date_last_requested_keyword_stats) < 7):
      #  # (default is 0 for date_last_requested_keyword_stats); continue if Previously requested keyword stats, and  timerange since: < 7 days. <7 since.   200 is last day requested. on 208 it will send 201-207. 208-200 = 8. 8>7.
      #  continue

      adset = Filter(Adset,adset_id=id)[0]
      adset_id = id
      if Adset.objects.get(adset_id=adset_id).date_last_requested_keyword_stats == None:
        adset = Adset.objects.get(adset_id=adset_id); adset.date_last_requested_keyword_stats = 0; adset.save()
      date_last_requested_keyword_stats_time_length = ((int(Date().myDatetimenow()-1) - Adset.objects.get(adset_id=adset_id).date_last_requested_keyword_stats))
      distinct_print("date last requested keyword stats time length: %s" % date_last_requested_keyword_stats_time_length)
      if (date_last_requested_keyword_stats_time_length >= 1) == False:
        return None
      Shop()(Adset.objects.get(adset_id=adset_id).shop_abbreviation)
      adset = AdSet(adset_id)

      ad = None
      ads = adset.get_ads()
      if len(ads) == 0:
        return
      ad = ads[0]


      q=[]
      data = []
      dates = lmap(lambda i: (Date()-i)().strftime("%Y-%m-%d"), [8,7,6,5,4,3,2])
      for i in dates:
        keyword_stats = ad.get_keyword_stats(fields=fields,params={"date":i})
        # print(keyword_stats)
        if len(keyword_stats) > 0:
          q.append(keyword_stats)
          keyword_stat = keyword_stats[0].export_all_data()
          for a in keyword_stat:
            keyword_stat[a]["date"] = Date().myDatetimenow(Date(i)())
            x = keyword_stat[a]
            distinct_print(":Keyword Stat:\nImpressions:%s, Reach: %s, Spend: %s, Date: %s, Name: %s"%(x["impressions"], x["reach"], x["spend"], x["date"], a))
          keyword_stat = AttrDict(keyword_stat)
          data.append(keyword_stat)
          #[2018.12.18 8:03:55 AM]Removed for ascii errordistinct_print("adset id, %s, len data, %s" % (adset_id, len(data)))
          #[2018.12.18 8:03:55 AM]Removed for ascii errordistinct_print(data[-1])
          print("\n\n")
          #input("continue")



      for keyword_stat in data:
        for name,values in keyword_stat.items():
          new = Interestinsight()
          existing = Interestinsight.objects.filter(adset_id = adset_id, date = values.date, interest_name = name)
          if len(existing) == 1:
            new = existing[0]
            #asciidistinct_print("[existing][adset_id][date][interest_name][%s][%s][%s]"%(adset_id,values.date,name))
            ""
          elif len(existing) == 0:
            #asciidistinct_print("[addition][adset_id][date][interest_name][%s][%s][%s]"%(adset_id,values.date,name))
            ""

          new.adset_id = adset_id
          new.date = values.date
          new.interest_name = name

          try:actions = AttrDict(keyword_stat[name]).actions
          except: actions = {}
          try:actions_dict = AttrDict(dict(zip(key("action_type", actions), key("value", actions))))
          except:actions_dict = {}

          interest_id = int(values.id)
          interest_name = name
          spend = getattr(new,"spend",0) + float(values.get("spend",0))
          reach = getattr(new,"reach",0) + int(values.get("reach",0))
          impression = getattr(new,"impression",0) + int(values.get("impressions",0))
          click = getattr(new,"click",0) + int(actions_dict.get("link_click",0))
          post_click = getattr(new,"post_click",0) + int(values.get("clicks", 0))
          add_to_cart = getattr(new,"add_to_cart",0) + int(actions_dict.get("offsite_conversion.fb_pixel_add_to_cart",0))
          website_purchase = getattr(new,"website_purchase",0) + int(actions_dict.get("offsite_conversion.fb_pixel_purchase", 0))
          page_engagement = getattr(new,"page_engagement",0) + int(actions_dict.get("page_engagement",0))
          photo_view = getattr(new,"photo_view",0) + int(actions_dict.get("photo_view",0))
          post_engagement = getattr(new,"post_engagement",0) + int(actions_dict.get("post_engagement",0))
          post_like = getattr(new,"post_like",0) + int(actions_dict.get("post_like",0))
          

          new.interest_id = interest_id
          new.interest_name = interest_name
          new.spend = spend
          new.reach = reach
          new.impression = impression
          new.click = click
          new.post_click = post_click
          new.add_to_cart = add_to_cart
          new.website_purchase = website_purchase
          new.page_engagement = page_engagement
          new.photo_view = photo_view
          new.post_engagement = post_engagement
          new.post_like  = post_like

          new.save()
        adset = Adset.objects.get(adset_id=adset_id)
        adset.date_last_requested_keyword_stats = int(Date().myDatetimenow()-1)
        #print("[%s][%s][%s]" % (adset_id, interest_name, adset.date_last_requested_keyword_stats))
        adset.save()








        #input("?: ")
    def update_adset_targeting_data(self, id):
      adset_id = id
      adset = AdSet(adset_id)
      Shop()(Adset.objects.get(adset_id=adset_id).shop_abbreviation)
      data = AttrDict(adset.remote_read(fields=["daily_budget", "created_time","effective_status","targeting","attribution_spec","promoted_object","billing_event","optimization_goal","recommendations","bid_info","name","source_adset_id"]).export_all_data())

      attribution_spec_dict = dict(zip(key("event_type", data.attribution_spec), key("window_days", data.attribution_spec)))

      flexible_spec1 = None
      flexible_spec2 = None
      flexible_spec3 = None
      flexible_spec4 = None
      flexible_spec5 = None

      created_time = datetime.strptime('-'.join(data.get("created_time").split("-")[:-1]), '%Y-%m-%dT%H:%M:%S')
      click_attribution = attribution_spec_dict.get("CLICK_THROUGH", 0)
      view_attribution = attribution_spec_dict.get("VIEW_THROUGH", 0)
      custom_event_type = data.promoted_object.custom_event_type
      billing_event = data.billing_event
      optimization_goal = data.optimization_goal
      recommendations = data.get("recommendations", "")
      bid_info = data.get("bid_info", "")
      device_platforms = list(sorted(data.targeting.get("device_platforms", [])))
      publisher_platforms = list(sorted(data.targeting.get("publisher_platforms", [])))
      facebook_positions = list(sorted(data.targeting.get("facebook_positions", [])))
      print(data)
      targeting_optimization = data.targeting.get("targeting_optimization","none")
      user_device = list(sorted(data.targeting.get("user_device", [])))
      user_os = list(sorted(data.targeting.get("user_os", [])))
      age_min = data.targeting.age_min
      age_max = data.targeting.age_max
      genders = data.targeting.get("genders", [0])[0] # 2 is F, 1 is M, 0 is Both?
      geo_locations = list(sorted(data.targeting.geo_locations.countries))
      status = data.get("effective_status")
      name = data.get("name")
      daily_budget = float(data.get("daily_budget")) / 100
      source_adset_id = data.get("source_adset_id", None)
      custom_audiences = data.targeting.get("custom_audiences", None)
      #body = Null
      #try:
      #  try:
      #    v = AdSet(adset_id).get_ads()[0].get_ad_creatives()[0].remote_read(fields=["effective_object_story_id", "body"])
      #    body = v["body"]
      #    effective_object_story_id = v["effective_object_story_id"]
      #    body_url = re.findall(r"[a-zA-Z]*.com.*",body)
      #    distinct_print(body_url)
      #
      #
      #  except:
      #    """ an error here means an ad or creative was deleted and database needs to delete adset, """
      #    magentaprint("[adset_id][%s]"%adset_id)
      #    try:mysql_delete(Adset.objects.get(id=adset_id)) # continue # ( no effective object story id )
      #    except:pass
      #  if body == Null: 0/0
      #except Exception as e:
      #  redprint(e)
      # F L E X I B L E S P E C 
      flexible_specs_ordered_list = []
      interest_dicts = {}
      """ ::: Add Friendly Part In Here, you want to save the Facebookkeywordlist for all things 1 len ::: """
      ## testing
      #return data
      #return data.targeting.flexible_spec
      ## testing
      if "flexible_spec" in data.targeting: # here add line say, only if flexible_spec in targeting
        if(1==len(data.targeting.flexible_spec)):
          x = data.targeting.flexible_spec[0]
          October_Keyword_Utilities().receive_interest_dictlist(x.get("interests"), niche=getattr(Get(Adset,adset_id=adset_id),"niche",None))
      """ ::: Add Friendly Part In Here, you want to save the Facebookkeywordlist for all things 1 len ::: """

      try:
        for idx,i in enumerate(data.targeting.flexible_spec):
          interest_dictlist = i["interests"]
          interest_dict = dict(zip(list(map(int, key("id", interest_dictlist))), list(map(str, key("name", interest_dictlist)))))
          interest_dict_id_sum = sum(list(map(int, interest_dict.keys())))
          interest_dicts[interest_dict_id_sum] = interest_dict
        for idx, id_sum in enumerate(list(sorted(interest_dicts.keys()))):
          flexible_specs_ordered_list.append(interest_dicts[id_sum])
        for idx,flexible_spec in enumerate(flexible_specs_ordered_list):
          sorted_interest_ids = list(sorted(flexible_spec.keys()))
          ordered_interests = []
          for interest_id in sorted_interest_ids:
            interest_name = flexible_spec[interest_id]
            ordered_interests.append([interest_id, interest_name])
          flexible_specs_ordered_list[idx] = ordered_interests
        if len(flexible_specs_ordered_list) > 0:
          flexible_spec1 = flexible_specs_ordered_list[0]
        if len(flexible_specs_ordered_list) > 1:
          flexible_spec2 = flexible_specs_ordered_list[1]
        if len(flexible_specs_ordered_list) > 2:
          flexible_spec3 = flexible_specs_ordered_list[2]
        if len(flexible_specs_ordered_list) > 3:
          flexible_spec4 = flexible_specs_ordered_list[3]
        if len(flexible_specs_ordered_list) > 4:
          flexible_spec5 = flexible_specs_ordered_list[4]
      except Exception as e:
        redprint("[no interests][error: %s]"%e)
      # F L E X I B L E S P E C 

      redprint("[%s][update_adset_targeting_data][created_time][%s]" % (adset["id"],created_time))
      redprint("[%s][update_adset_targeting_data][attribution_spec_dict][%s]" % (adset["id"],attribution_spec_dict))
      redprint("[%s][update_adset_targeting_data][click_attribution][%s]" % (adset["id"],click_attribution))
      redprint("[%s][update_adset_targeting_data][view_attribution][%s]" % (adset["id"],view_attribution))
      redprint("[%s][update_adset_targeting_data][custom_event_type][%s]" % (adset["id"],custom_event_type))
      redprint("[%s][update_adset_targeting_data][billing_event][%s]" % (adset["id"],billing_event))
      redprint("[%s][update_adset_targeting_data][optimization_goal][%s]" % (adset["id"],optimization_goal))
      redprint("[%s][update_adset_targeting_data][recommendations][%s]" % (adset["id"],recommendations))
      redprint("[%s][update_adset_targeting_data][bid_info][%s]" % (adset["id"],bid_info))
      redprint("[%s][update_adset_targeting_data][device_platforms][%s]" % (adset["id"],device_platforms))
      redprint("[%s][update_adset_targeting_data][publisher_platforms][%s]" % (adset["id"],publisher_platforms))
      redprint("[%s][update_adset_targeting_data][facebook_positions][%s]" % (adset["id"],facebook_positions))
      redprint("[%s][update_adset_targeting_data][targeting_optimization][%s]" % (adset["id"],targeting_optimization))
      redprint("[%s][update_adset_targeting_data][user_device][%s]" % (adset["id"],user_device))
      redprint("[%s][update_adset_targeting_data][user_os][%s]" % (adset["id"],user_os))
      redprint("[%s][update_adset_targeting_data][age_min][%s]" % (adset["id"],age_min))
      redprint("[%s][update_adset_targeting_data][age_max][%s]" % (adset["id"],age_max))
      redprint("[%s][update_adset_targeting_data][genders][%s]" % (adset["id"],genders))
      redprint("[%s][update_adset_targeting_data][geo_locations][%s]" % (adset["id"],geo_locations))
      redprint("[%s][update_adset_targeting_data][name][%s]" % (adset["id"],name))
      #redprint("[%s][update_adset_targeting_data][body][%s]" % (adset["id"],body))
      #redprint("[%s][update_adset_targeting_data][effective_object_story_id][%s]" % (adset["id"],effective_object_story_id))
      redprint("[%s][update_adset_targeting_data][daily_budget][%s]" % (adset["id"],daily_budget))
      #@[2018.12.17 12:25 AM]for ascii redprint("[%s][update_adset_targeting_data][flexible_spec1][%s]" % (adset["id"],flexible_spec1))
      #@[2018.12.17 12:25 AM]for ascii redprint("[%s][update_adset_targeting_data][flexible_spec2][%s]" % (adset["id"],flexible_spec2))
      #@[2018.12.17 12:25 AM]for ascii redprint("[%s][update_adset_targeting_data][flexible_spec3][%s]" % (adset["id"],flexible_spec3))
      #@[2018.12.17 12:25 AM]for ascii redprint("[%s][update_adset_targeting_data][flexible_spec4][%s]" % (adset["id"],flexible_spec4))
      #@[2018.12.17 12:25 AM]for ascii redprint("[%s][update_adset_targeting_data][flexible_spec5][%s]" % (adset["id"],flexible_spec5))


      adset = Adset.objects.get(adset_id=adset_id)
      adset.created_time = created_time
      adset.click_attribution = click_attribution
      adset.view_attribution = view_attribution
      adset.custom_event_type = custom_event_type
      adset.billing_event = billing_event
      adset.optimization_goal = optimization_goal
      adset.recommendations = recommendations
      adset.bid_info = dict(bid_info)
      adset.device_platforms = device_platforms
      adset.publisher_platforms = publisher_platforms
      adset.facebook_positions = facebook_positions
      adset.targeting_optimization = targeting_optimization
      adset.user_device = user_device
      adset.user_os = user_os
      adset.age_min = age_min
      adset.age_max = age_max
      adset.genders = genders
      adset.geo_locations = geo_locations
      adset.status = status
      adset.name = name
      adset.daily_budget = daily_budget
      #adset.body = body
      #adset.effective_object_story_id = effective_object_story_id
      adset.source_adset_id = source_adset_id
      adset.custom_audiences = custom_audiences
      adset.flexible_spec1 = flexible_spec1
      adset.flexible_spec2 = flexible_spec2
      adset.flexible_spec3 = flexible_spec3
      adset.flexible_spec4 = flexible_spec4
      adset.flexible_spec5 = flexible_spec5


      adset.save()
    def database_fields_to_data(self, adset_id):

      adset = Adset.objects.get(adset_id=adset_id)
      x = {}
      x = AttrDict(x)
      if adset.click_attribution:
        x.attribution_spec = [] if "attribution_spec" not in x else x.attribution_spec
        x.attribution_spec.append({'event_type': 'CLICK_THROUGH', 'window_days': adset.click_attribution})
      if adset.view_attribution:
        x.attribution_spec = [] if "attribution_spec" not in x else x.attribution_spec
        x.attribution_spec.append({'event_type': 'VIEW_THROUGH', 'window_days': adset.view_attribution})
      if adset.custom_event_type:
        x.promoted_object = {} if "promoted_object" not in x else x.promoted_object
        x.promoted_object.custom_event_type = adset.custom_event_type
        x.promoted_object.pixel_id = Shop.objects.get(shop_abbreviation = adset.shop_abbreviation).Facebook_Pixel_ID
        x.promoted_object.pixel_rule = '{"event":{"eq":"%s"}}' % adset.custom_event_type.title()
      if adset.billing_event:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.billing_event = adset.billing_event
      if adset.optimization_goal:
        x.optimization_goal = adset.optimization_goal
      if adset.recommendations:
        None
      if adset.bid_info:
        None
        redprint("[No information set on what to do in event of a bid_info field as of 7/20/18]")
      if adset.device_platforms:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.device_platforms = adset.device_platforms
      if adset.facebook_positions:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.facebook_positions = adset.facebook_positions
      if adset.publisher_platforms:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.publisher_platforms = adset.publisher_platforms
      if adset.targeting_optimization:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.targeting_optimization = adset.targeting_optimization
      if adset.user_device:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.user_device = adset.user_device
      if adset.user_os:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.user_os = adset.user_os
      if adset.age_min:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.age_min = adset.age_min
      if adset.age_max:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.age_max = adset.age_max
      if adset.genders:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.genders = [adset.genders]
      if adset.geo_locations:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.geo_locations = {'countries': adset.geo_locations, 'location_types': ['home', 'recent']} 
      if adset.status:
        x.status = adset.status
      if adset.flexible_spec1:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.flexible_spec = []
        x.targeting.flexible_spec.append({})
        x.targeting.flexible_spec[-1]["interests"] = []
        for i,j in adset.flexible_spec1:
          x.targeting.flexible_spec[-1]["interests"].append({"name":i, "id":j})
      if adset.flexible_spec2:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.flexible_spec = []
        x.targeting.flexible_spec.append({})
        x.targeting.flexible_spec[-1]["interests"] = []
        for i,j in adset.flexible_spec2:
          x.targeting.flexible_spec[-1]["interests"].append({"name":i, "id":j})
      if adset.flexible_spec3:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.flexible_spec = []
        x.targeting.flexible_spec.append({})
        x.targeting.flexible_spec[-1]["interests"] = []
        for i,j in adset.flexible_spec3:
          x.targeting.flexible_spec[-1]["interests"].append({"name":i, "id":j})
      if adset.flexible_spec4:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.flexible_spec = []
        x.targeting.flexible_spec.append({})
        x.targeting.flexible_spec[-1]["interests"] = []
        for i,j in adset.flexible_sspec4:
          x.targeting.flexible_spec[-1]["interests"].append({"name":i, "id":j})
      if adset.flexible_spec5:
        x.targeting = {} if "targeting" not in x else x.targeting
        x.targeting.flexible_spec = []
        x.targeting.flexible_spec.append({})
        x.targeting.flexible_spec[-1]["interests"] = []
        for i,j in adset.flexible_spec5:
          x.targeting.flexible_spec[-1]["interests"].append({"name":i, "id":j})
      x.targeting = dict(x.targeting)
      try:x.promoted_object = dict(x.promoted_object)
      except Exception as e:print(e)
      x = dict(x)
      return x
    def algorithm4(self,id):
      a_shop()
      adset = Get(Adset,adset_id=id)
      if adset.status=="ACTIVE":
        data = keysort("date", Adsethourlyinsight.objects.filter(adset_id=adset.adset_id), tcer=False)
        impressions = 0; sales = 0
        for x in data:

          impressions+=x.impression
          sales+=x.website_purchase


          print(impressions, sales)
          if impressions > 500:
            if sales < 1:
              print("stop")
              print("[adset_id][%s]"%adset.adset_id)
              input("please check it, impressions: %s, sales: %s" % (impressions, sales))
              AdSet(adset.adset_id).remote_update(params={"status":"PAUSED"})
              break
    def update_advertisement_all(self, id):
      # OSA.log("1")
      July_Adset_Utilities().update_adset(id=id)
      # OSA.log("2")
      July_Adset_Utilities().update_adset_targeting_data(id=id)
      # OSA.log("3")
      July_Adset_Utilities().update_adsetinsight_data(id=id)
      # OSA.log("4")
      July_Adset_Utilities().update_adsethourlyinsight_data(id=id)
      # OSA.log("5")
      July_Adset_Utilities().stop_adset_based_on_today_data(id=id)
      # OSA.log("6")
      July_Adset_Utilities().stop_adset_based_on_past_data(id=id)
      # OSA.log("7")
      July_Adset_Utilities().restart_adset_based_on_today_data(id=id)
      # OSA.log("8")
      July_Adset_Utilities().algorithm4(id=id)
      # OSA.log("I")
      July_Adset_Utilities().update_ad_keyword_data(id=id)
      # OSA.log("J")
      x = datetime.now()
      Update(Get(Adset,adset_id=id),last_check=datetime.now())
      # OSA.log("L")
      return x.strftime("%Y,%m,%d,%H,%M,%S")
    def update_advertisements(self,shop):
      for i in Filter(Adset,shop_abbreviation=shop):
        July_Adset_Utilities().update_advertisement_all(i.adset_id)
    def tests(self):
      #July_Adset_Utilities().update_adsets()
      #July_Adset_Utilities().update_adsetinsight_data(date_start = 30, date_end = 0)
      #data = CSV().pick_data(Adsetinsight.objects.all(), ["spend","adset_id","date","frequency","impression","impression_cost","impression_rate","post_click","post_click_cost","post_click_rate","click","click_cost","click_rate","add_to_cart","add_to_cart_cost","add_to_cart_rate","website_purchase","website_purchase_cost","website_purchase_rate","spend","website_purchase_value","return_on_investment","reach","reach_cost","reach_rate","landing_page_view","landing_page_view_cost","landing_page_view_rate","fb_pixel_view_content","fb_pixel_view_content_cost","fb_pixel_view_content_rate","fb_pixel_initiate_checkout","fb_pixel_initiate_checkout_cost","fb_pixel_initiate_checkout_rate","page_engagement","page_engagement_cost","page_engagement_rate","post_engagement","post_engagement_cost","post_engagement_rate","post_reaction","post_reaction_cost","post_reaction_rate"])
      #CSV().DictWriteWithHeaders("out.csv", data, headers=["spend","adset_id","date","frequency","impression","impression_cost","impression_rate","post_click","post_click_cost","post_click_rate","click","click_cost","click_rate","add_to_cart","add_to_cart_cost","add_to_cart_rate","website_purchase","website_purchase_cost","website_purchase_rate","spend","website_purchase_value","return_on_investment","reach","reach_cost","reach_rate","landing_page_view","landing_page_view_cost","landing_page_view_rate","fb_pixel_view_content","fb_pixel_view_content_cost","fb_pixel_view_content_rate","fb_pixel_initiate_checkout","fb_pixel_initiate_checkout_cost","fb_pixel_initiate_checkout_rate","page_engagement","page_engagement_cost","page_engagement_rate","post_engagement","post_engagement_cost","post_engagement_rate","post_reaction","post_reaction_cost","post_reaction_rate"])
      CSV().dictlist_to_xlsx(Adsetinsight.objects.all(), ["spend","adset_id","date","frequency","impression","impression_cost","impression_rate","post_click","post_click_cost","post_click_rate","click","click_cost","click_rate","add_to_cart","add_to_cart_cost","add_to_cart_rate","website_purchase","website_purchase_cost","website_purchase_rate","spend","website_purchase_value","return_on_investment","reach","reach_cost","reach_rate","landing_page_view","landing_page_view_cost","landing_page_view_rate","fb_pixel_view_content","fb_pixel_view_content_cost","fb_pixel_view_content_rate","fb_pixel_initiate_checkout","fb_pixel_initiate_checkout_cost","fb_pixel_initiate_checkout_rate","page_engagement","page_engagement_cost","page_engagement_rate","post_engagement","post_engagement_cost","post_engagement_rate","post_reaction","post_reaction_cost","post_reaction_rate"],
          workbook  =  ".xlsx", sheet="sheet" )

      July_Adset_Utilities().stop_adsets_based_on_today_data()
      July_Adset_Utilities().stop_adsets_based_on_past_data()
      July_Adset_Utilities().restart_adsets_based_on_today_data()
def how_to_create_new_virtualenv():
  """
  (u past this inside termal)
  virtualenv --python="/Users/your user name/.pyenv/pyenv-win/versions/3.5.0/python.exe" fucktown
  # not that one.
  winpty "/Users/Your user name/.pyenv/pyenv-win/versions/3.5.0/python.exe" -m venv "/Users/Your user name/venv"
  # sometimes it feels different

  winpty ".pyenv/pyenv-win/versions/3.9.0/python.exe" -m venv "venv"

  """
  return -1
def OUTPUT():
  return "tee"
def savedict():
  ifdo(lambda:globals().get('savedict')==None,setitem(globals()['savedict'],{}) )
  return globals()['savedict']
def typed(a={}):
  return type("",(a.get("type",object),),a)
  """
  typed({})()
  """
typed()
class Interface:
  def exist(you,rawr):
    print(42)
class WindowsDefenderFirewallWithAdvancedSecurity:
  def run(self):
    return
def p0():
  "pip install pyobjc ==5.0"
def p1():
  """
  #i am pretty sure this is for 3.9.0 `virtual1`
  # Hey! She  did do the --upgrade .  
  #pip install pip --upgrade
  #pip install setuptools --upgrade
  #pip install ipython
  #pip install ShopifyAPI #820
  #pip install pandas
  #pip install pyinstaller
  #pip install termcolor #1.1.0
  #"youtube-dl"
  #"requests"
  #pip install twine==1.11.0
  #pip install facebook-business==3.3.0
  #pip install facebookads==2.11.4
  """
def p2():
  """
  pip install bs4==0.0.1
  pip install multiprocess
  pip install Pillow

  pip install keyring

  pip install selenium==3.14.1
  pip install pyperclip==1.6.0
  pip install colorama==0.3.9
  pip install colored==1.3.93
  pip install colormath==3.0.0
  pip install numpy #1.20.1

  pip install imgkit==1.0.1
  pip install imgurpython==1.1.7
  pip install instapy==0.6.2
  pip install moviepy==1.0.0 # not fully required
  pip install playsound==1.2.2
  pip install mtranslate
  pip install gTTS==2.0.1 # not fully required
  pip install sounddevice==0.3.10
  pip install speedtest-cli==2.0.2

  pip install configparser==3.5.0
  pip install dicttoxml==1.7.4
  pip install dill --upgrade
  pip install emoji==0.5.1
  pip install fonttools==3.29.0
  pip install gspread==0.6.2
  pip install pydub==0.22.0
  pip install PyPDF2==1.26.0
  pip install python-dateutil==2.7.3
  pip install python-docx==0.8.6
  pip install python-pptx==0.6.5
  pip install python-resize-image==1.1.11


  pip install google-api-core==1.3.0
  pip install google-api-python-client==1.6.4
  pip install google-auth==1.5.1
  pip install google-auth-httplib2
  pip install google-auth-oauthlib==0.2.0
  pip install google-images-download==2.3.0
  pip install googleapis-common-protos==1.5.3
  """
def part1():
  """
  pip install oauth2==1.9.0.post1
  pip install oauth2client==4.1.2
  pip install oauthlib --upgrade # 3.1.0
  pip install pyocr==0.5.2
  pip install pytesseract==0.2.4
  pip install text-to-image==0.0.5
  pip install textract

  pip install mutagen==1.40.0
  pip install pathos==0.2.2.1
  pip install imageio --upgrade #2.9.0
  pip install virtualenv==16.0.0
  pip install matplotlib --upgrade #3.3.4
  pip install bitly-api==0.3


  pip install pdf2image==1.1.0
  pip install psutil --upgrade #5.8.0
  pip install ptyprocess==0.6.0
  pip install pyparsing --upgrade #2.4.7
  pip install pypng==0.0.18
  pip install PySocks==1.6.8
  pip install pytz==2017.3
  pip install PyVirtualDisplay==0.2.1

  pip install html5lib==1.0.1
  pip install httplib2==0.10.3
  pip install lxml --upgrade #4.6.2
  pip install opencv-python --upgrade #4.5.1.48
  pip install openpyxl==2.5.4
  pip install scikit-image --upgrade #0.18.1
  pip install urllib3 --upgrade #1.26.3
  pip install wcwidth==0.1.7
  pip install webcolors==1.7
  pip install xlrd --upgrade # 2.0.1
  pip install XlsxWriter==1.0.5
  pip install xmltodict==0.11.0

  pip install feedparser==5.2.1
  pip install gast==0.2.0
  pip install pathlib2==2.3.2
  pip install Wand==0.4.5
  """
class Wfr(object):
  
  def __getattribute__(self, attr):
    try:
      attribute = object.__getattribute__(self,attr)
    except:
      return Wfr()
    if callable(attribute):
      return attribute
    else:
      return Wfr()
  def __call__(you):
    return Wfr()
  def set_occupation(self,job):
    self._job = job
  
  """ {'from': 'https://towardsdatascience.com/create-new-functionality-with-getattribute-a6757ee27428'} """
  """ """
class Fwe(Wfr):
  1
class Worker(Wfr):
  1
class Leftist(Wfr):
  1
class IcelandFairies(str):
  def __init__(you):
    dict(Vala_Fanney=set())
    dict(RvkFashionJournal=set())
    dict(Salome_Osk=set())
    dict(Fjola_Hei66dal=set())
    dict(Idunn_Jonasar=set())
class WhileDude:
  def run(self,main,quarters=[False,False][-1]):
    time.sleep(0.7)
    if quarters is True:
      print('quarts')
      return
    if main() is True:
      return
      print("Done while Loop")
    else:
      print("Must, run aagain")
      return self.run(main=main,quarters=quarters)
  """
  class main:
    def __init__(self):
      self.posispqau=-3
    def main(self):
      self.posispqau = self.posispqau + 1
      if self.posispqau == 1:
        return True
      else:
        return False
  Main = main()
  WhileDude().run(main=0,quarters=True)
  WhileDude().run(main=Main.main)
  """
class WhileDudeIfMainIsTrueReturnElseCallAgain(WhileDude):
  1
class WhileDudeIfMainIsFalseCallAgain(WhileDude):
  1
class AbandonedShip(set):
  def r():
    class FlaccidTubeSatchel:
      def __call__(you,IPs=None):
        IPs=ifelsedo(lambda:IPs==None,lambda:TubeSatchel().run(),lambda:IPs)
        IPs=lmap(lambda i:{"http":"http://%s"%(i),"https":"http://%s"%(i)},IPs)
        return IPs
    you=CloudHeadForkedBus()
    def run(i):
      try:
        w=requests.get('https://oberlo.com',proxies=i,timeout=10,verify=False)
        print(w)
        print('success',w)
        return w
      except Exception as error:
        print(error)
        return(error)
      #  
    w=pool(run,you.IPs[:3000],nodes=200)
class PlaneAbandoned:
  def run(self):
    daata={'loginId': 'jchufoo@gmail.com',
            'password2': '8673388a37fafeb0fc0e5037403390d6fe69bad37190815e809e01eef0f93f9f40b5f62e315cb947624859467591ed80213ddd873a00d186709db31ec7b27f8c82681583d31af84228a0dc3cf9cc385e3d8f3889b7a13f7886aed7028388f8642580e052ebb9d6ab398f016430dce6aea09625d584601e8caf9e245e5d303a54'}
    daata={'loginId': 'jchufoo@gmail.com',
            'password': 'Dg7UXrMbfmACXTEUYM'}
    headers={"authority": "passport.aliexpress.com", "method": "POST", "path": "/newlogin/login.do?appName=aebuyer&fromSite=13", "scheme": "https", "accept": "application/json, text/plain, */*", "accept-encoding": "gzip, deflate, br", "accept-language": "en-US,en;q=0.9", "content-length": "2197", "content-type": "application/x-www-form-urlencoded", "dnt": "1", "origin": "https://login.aliexpress.com", "referer": "https://login.aliexpress.com/", "sec-ch-ua": "\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"", "sec-ch-ua-mobile": "?0", "sec-fetch-dest": "empty", "sec-fetch-mode": "cors", "sec-fetch-site": "same-site", "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4435.0 Safari/537.36"}
    # has ,br
    r=requests.session()
    r=r.post('https://passport.aliexpress.com/newlogin/login.do?appName=aebuyer&fromSite=13',
            headers=headers,data=daata)
    print(r.url)
    print(r.text)
    

    class MakeLargeHead(object):
      def lisp(self,out):
        return
    class Shake(object):
      def get(s,r):
        return r
    class Shakers(object):
      def __init__(s):
        1
    Shakers()
    r = Shake().get(r)
    headers=r.headers
    cookies=AbsorbCookies()(r)
    cookies=AssimilateCookies()(r)
    headers={"authority": "trade.aliexpress.com", "method": "GET", "path": "/order_list.htm?spm=a2g0s.8937460.0.0.73452e0eHR5XAX", "scheme": "https", "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9", "accept-encoding": "gzip, deflate", "accept-language": "en-US,en;q=0.9", "cache-control": "max-age=0", "dnt": "1", "referer": "https://my.aliexpress.com/", "sec-ch-ua": "\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"", "sec-ch-ua-mobile": "?0", "sec-fetch-dest": "document", "sec-fetch-mode": "navigate", "sec-fetch-site": "same-site", "sec-fetch-user": "?1", "upgrade-insecure-requests": "1", "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4435.0 Safari/537.36"}
    headers['Cookie']=cookies
    headers


    w=requests.get('https://trade.aliexpress.com/order_list.htm?spm=a2g0s.8937460.0.0.73452e0eHR5XAX',headers=headers,)

    {"content":{"data":{"loginResult":"success","loginSucResultAction":"loginResult","st":"3xabba7lSM1VN2GvC_wfoow","loginType":"pwdLogin","loginScene":"normal","resultCode":100,"appEntrance":"aebuyer","smartlock":true,"stSite":13},"status":0,"success":true},"hasError":false}
class SysStdOutWrite(object):
  def __init__(you,*args,**kwargs):
    sys.stdout.write(*args,**kwargs)
class SysStdOutClear(object):
  def __init__(you,*args,**kwargs):
    sys.stdout.flush(*args,**kwargs)
class SysStdOutParabola(object):
  def __init__(self,*args):
    self.plenty=args
    for i in range(100):
      sp(1)
      SysStdOutWrite(random.sample(self.plenty,1)[0])
      SysStdOutClear()
    return
    SysStdOutParabola("rah","roh","reh")
class Sys:
  def __init__(you):
    import sys
    zzvr=6
    globalosis(locals())
  def write(*bottles,**entries):
    sys.stdout.write(*bottles,**entries)    
  def clear(*bottles,**entries):
    sys.stdout.clear()
class PRINT(object):
  def __init__(you,*args,**entries):
    print(*args,**entries)
    try:1
    except:2
    return
    PRINT("hello","hello",end="")
    PRINT("hello","hello",end="")
class AlphabetNumericalizeOr:
  def a(YOU,IO):
    b='abcdefghijklmnopqrstuvwxyz000'[:26]
    r="|".join(b).split("b")
    strand=''
    for i in IO:
      try:
        num = str(b.index(i.lower()))
      except Exception as ERROR:
        strand+=i
      strand+=num
    return(strand)
    AlphabetNumericalizeOr().a("Barta Holocene")
class MoneyPie(str):
  def __init__(you,zc,er,ra):
    w=Slime().verbalpolygon(zc,[er,ra])
    super().__init__(w)
class MoneyPie(object):
  def __call__(you,zc,er,ra):
    w=Slime().verbalpolygon(zc,[er,ra])
    return(w)
class PieMoney(set):
  def __call__(you,zc,er):
    box=[]
    for i in ["en","fr","de","no","ru","lv","se","ch"]:
      w=Slime().verbalpolygon(zc,[er,i])
      print(zc,i,w)
      box.append([zc,i,w])
      print([zc,i,w])
    return(box)
class SetRecursionLimit:
  def __call__(you):
    import sys
    sys.setrecursionlimit(random.randrange(100000,999999))
class CLEARLINE(object):
  def __init__(you,x=1):
    [print("\033[A\033[A") for i in range(x)]
class CLEARLINEBLOB(int):
  def __init__(*args,**kwargs):
    lmap(lambda i:[print("\033[A\033[A"),super().__init__(args[0])],lrange(args[0]))
class KlassTwoVersionsNotTestOneThenMakeSecond(object):
  def __init__(you):
    return
class Twoo(object):
  1
class OnlinerGoMoreOnlinerGetAwakeOnlinerWakeUpOnliner:
  def __call__(you):
    sys.setrecursionlimit(random.randrange(100000,999999))
    print(str(random.random())[:4])
    sp(random.random()*3)
    CLEARLINE(1)
    Onliner()()
class OnlinerGoMoreOnlinerGetAwakeOnlinerWakeUpOnlinerWithStatusWrapper:
  def __call__(you):
    print(str(random.random())[:4])
class NewEdit:

  def input():
    return x
  def concert():
    while True:

      fg = "%s, %s%%, %s%%"%(random.randrange(101),random.randrange(101),random.randrange(101))
      xr=lambda *args,**kwargs:print#(*args,**kwargs)
      xr("fg")
      bg = "%s, %s%%, %s%%"%(random.randrange(101),random.randrange(101),random.randrange(101))
      xr("got bg bech")
      x='    "variables":    {\n        "black": "hsl(100, 100%, 100%)",\n        "black2": "hsl(100, 100%, 100%)",\n        "black3": "hsl(bagrund)",\n        "blue": "hsl(0, 0%, 0%)",\n        "grey": "hsl(26, 82%, 51%)",\n        "orange": "hsl(0, 0%, 0%)",\n        "orange2": "hsl(0, 0%, 0%)",\n        "orange3": "hsl(0, 0%, 0%)",\n        "purple": "hsl(0, 0%, 0%)",\n        "red": "hsl(0, 0%, 0%)",\n        "red2": "hsl(0, 0%, 0%)",\n        "white": "hsl(roseta)",\n        "white2": "hsl(roseta)",\n        "white3": "hsl(roseta)",\n        "yellow": "hsl(0, 0%, 0%)",\n        "yellow2": "hsl(0, 0%, 0%)",\n        "yellow3": "hsl(0, 0%, 0%)",\n        "yellow4": "hsl(0, 0%, 0%)",\n        "yellow5": "hsl(0, 0%, 0%)"\n    },\n'
      xr("assimilate x")
      tp(lambda:Nat().stunning())
      xr("nat stunning acuresdnt ewha")
      x=x.replace('roseta',fg).replace('bagrund',bg).replace("\n","")+"\n"
      xr("replacing x")
      xr("fg(%s) bg(%s)"%(fg,bg))
      pyperclip.copy(x)
    return
class NeverSpendTheInstantiatedPartOfYourDayDebuggingVisualStudioItUpFirst:
  1
class Smack(object):
  def __init__(self,x):
    r=PieMoney()(x,"en")
    print(r)
    for i in r:
      tp(lambda:
        open(os.path.expanduser("~/venv/sele.txt"),"a",encoding="").write((",\n ".join(i)+"\n") )
        )
    open(os.path.expanduser("~/venv/sele.txt"),"a").write("\n")
class WfrFriend(object):

  def __getattribute__(self, attr):
    try:
      attribute = object.__getattribute__(self,attr)
    except:
      return Wfr()
    if callable(attribute):
      return attribute
    else:
      return attribute
  def __call__(you):
    return Wfr()
  def set_occupation(self,job):
    self._job = job
class Parsher:
  def __call__(you,*args):
    import argparse
    parser = argparse.ArgumentParser(description="a")
    for i in args[0]:
      first = i
      second = i.replace("-","")
      help=""
      required=False
      flags="+"
      #parser.add_argument("-i",help="Id",dest="i",required=False)
      parser.add_argument(first,dest=second,required=False,
                          nargs="*")


    args=parser.parse_args()
    return args
    args
    """
    print(Parsher()(["-index","-binance","-ar"]))
    print("-")
    """
class Parser:
  def __call__(you,*args):
    import argparse
    parser = argparse.ArgumentParser(description="a")
    for i in args[0]:
      first = i
      second = i.replace("-","")
      help=""
      required=False
      flags="+"
      #parser.add_argument("-i",help="Id",dest="i",required=False)
      parser.add_argument(first,dest=second,required=False,
                          nargs="*")


    args=parser.parse_args()
    return args
    args
    """
    print(Parsher()(["-index","-binance","-ar"]))
    print("-")
    """
class BanMislabelledNames:
  def run(you):
    return
class Cults:
  def __call__(you):
    print(
      "house,stuy,manhattan,china,jews,".split(",")
      )
class MDilate:
  def mdilate(self, to_dilate, to_phagephage="en", from_language="auto"):
    from mtranslate import translate
    return translate(to_dilate, to_phagephage, from_language)
class Dilate:
  def mdilate(self, to_dilate, to_phagephage="en", from_language="auto"):
    from mtranslate import translate
    return translate(to_dilate, to_phagephage, from_language)
class MTranslate:
  def mtranslate(self, to_dilate, to_phagephage="en", from_language="auto"):
    from mtranslate import translate
    return translate(to_dilate, to_phagephage, from_language)
class Translate:
  def translate(self, to_dilate, to_phagephage="en", from_language="auto"):
    from mtranslate import translate
    return translate(to_dilate, to_phagephage, from_language)
class PackFreezer(dict):
  def __init__(you):
    SleepPrint("---",0.05)
    SleepPrint("Opening Freezer",2)
    you.update(pickle.load(open("Freezer.pkl","rb")))
    SleepPrint(type(you),4)
    SleepPrint("~fin",1)
  def close(you,test=0):
    SleepPrint("---",3)
    SleepPrint("PackFreezer.close",1)
    SleepPrint("Original Loaded",3)
    original=pickle.load(open("Freezer.pkl","rb"))
    SleepPrint("`",1)
    print("This is a test, 1 is true: %s"%(test))
    SleepPrint("Packing Freezer",1)
    try:
      test and 0/0
      pickle.dump(dict(you),open("Freezer.pkl","wb"))
      SleepPrint("Packed",6)
    except Exception as error:
      SleepPrint("ERROR",5)
      SleepPrint(error,5)
      SleepPrint("`",2)
      SleepPrint("Packing Original",3)
      pickle.dump(original,open("Freezer.pkl","wb"))
      SleepPrint("Packed Original",1)
      SleepPrint(subprocess.getoutput("ls -lt | grep Freezer"),10)
    SleepPrint("~fin",2)
class Freezer(dict):
  def __init__(you):
    SleepPrint("---",0.05)
    SleepPrint("Opening Freezer",2)
    you.update(pickle.load(open("Freezer.pkl","rb")))
    SleepPrint(type(you),4)
    SleepPrint("~fin",1)
  def close(you,test=0):
    SleepPrint("---",3)
    SleepPrint("PackFreezer.close",1)
    SleepPrint("Original Loaded",3)
    original=pickle.load(open("Freezer.pkl","rb"))
    SleepPrint("`",1)
    print("This is a test, 1 is true: %s"%(test))
    SleepPrint("Packing Freezer",1)
    try:
      test and 0/0
      pickle.dump(dict(you),open("Freezer.pkl","wb"))
      SleepPrint("Packed",6)
    except Exception as error:
      SleepPrint("ERROR",5)
      SleepPrint(error,5)
      SleepPrint("`",2)
      SleepPrint("Packing Original",3)
      pickle.dump(original,open("Freezer.pkl","wb"))
      SleepPrint("Packed Original",1)
      SleepPrint(subprocess.getoutput("ls -lt | grep Freezer"),10)
    SleepPrint("~fin",2)
class OracleOracleScribeScribeKnifeMyKniteKnifeMyKite:
  helifactor=lambda x_text,*args,**kwargs: open("the_html_file_you_open_in_a_browser.html","w").write(x_text.encode("ascii",errors="ignore").decode("ascii",errors="ignore"))
  rgx1='importProducts: (.*),'
  rgx2='window.App.payload.pagination = (.*);'
  import argparse
  parser = argparse.ArgumentParser(description="a")
  parser.add_argument("-i",help="Id",dest="i",required=False)
  parser.add_argument("-t",help="Title",dest="t",required=False)
  parser.add_argument("-p",help="Type",dest="p",required=False)
  parser.add_argument("-d",help="Desc",dest="d",required=False)
  parser.add_argument("-v",help="Vnames",dest="v",required=False)
  parser.add_argument("-vnamefire",help="vnamefire",dest="vnamefire",required=False)
  parser.add_argument("-c",help="c",dest="c",default=False,action="store_true",required=False)
  parser.add_argument("-u",help="Updates",dest="u",required=False)
  parser.add_argument("-delete",help="delete",dest="delete",required=False)
  args=parser.parse_args()
  url2='https://app.oberlo.com/ajax/import/save-title'
  url3='https://app.oberlo.com/ajax/import/save-type'
  url4='https://app.oberlo.com/ajax/import/save-description'
  url5='https://app.oberlo.com/ajax/import/save-option-value'
  url6='https://app.oberlo.com/import?status[]=0&status[]=1&keywords=&source=1&page=%s'
  url7='https://app.oberlo.com/ajax/products/ali-url?id=%s'
  url8='https://app.oberlo.com/my-products'
  url9='https://app.oberlo.com/my-products?page={}'
  url10='https://app.oberlo.com/ajax/import/ready-to-push'
class SleepPrint:
  def __init__(self,*args,**kwargs):
    """ Usage: SleepPrint('hi',5) """
    sleeptime=args[-1]
    sleeptime=(sleeptime/(25*4))
    args=args[:-1]
    print(*args,**kwargs)
    time.sleep(sleeptime)
class SampleCookies:
  def map_pickle(you,test=0):
    """ Usage: SampleCookies().map_pickle(test=0) """
    SleepPrint("===",0.05)
    SleepPrint("Running SampleCookies()",1)
    SleepPrint("This only Dents your Pickle Database to folder.",2)
    SleepPrint("===",0.25)
    SleepPrint("`",0.05)
    if os.path.exists("Freezer.pkl")==0:
      pickle.dump({},open("Freezer.pkl","wb"))
      print("Dumped new Pickle to Freezer",type(pickle.load(open("Freezer.pkl","rb"))) )
    if test==1:
      print("It is a test. Remove Freezer.pkl")
      os.remove("Freezer.pkl")
      print(subprocess.getoutput("ls -lt | grep Freezer"))
    SleepPrint("Its Dented.",2)
    SleepPrint(subprocess.getoutput("ls -lt | grep Freezer"),2)
    SleepPrint("`",0)
    SleepPrint("~fin",1)
class PackFreezer(dict):
  def __init__(you):
    SleepPrint("---",0.05)
    SleepPrint("Opening Freezer",2)
    you.update(pickle.load(open("Freezer.pkl","rb")))
    SleepPrint(type(you),4)
    SleepPrint("~fin",1)
  def close(you,test=0):
    SleepPrint("---",3)
    SleepPrint("PackFreezer.close",1)
    SleepPrint("Original Loaded",3)
    original=pickle.load(open("Freezer.pkl","rb"))
    SleepPrint("`",1)
    print("This is a test, 1 is true: %s"%(test))
    SleepPrint("Packing Freezer",1)
    try:
      test and 0/0
      pickle.dump(dict(you),open("Freezer.pkl","wb"))
      SleepPrint("Packed",6)
    except Exception as error:
      SleepPrint("ERROR",5)
      SleepPrint(error,5)
      SleepPrint("`",2)
      SleepPrint("Packing Original",3)
      pickle.dump(original,open("Freezer.pkl","wb"))
      SleepPrint("Packed Original",1)
      SleepPrint(subprocess.getoutput("ls -lt | grep Freezer"),10)
    SleepPrint("~fin",2)
class SLEEPPRINT(SleepPrint):
  pass
class SLEEPYPRINT(SleepPrint):
  pass
class ObservantRequestsForOberlo(object):
  def __init__(you,
        info={
          "email":"cavernclip@gmx.com",
          "password":"RandomPassword10"
          },
        jacuzzi="https://app.oberlo.com/import",):

    SLEEPPRINT("Observant Requests Involve",2)
    SLEEPPRINT("Gulp Info",2)
    SLEEPPRINT(info,2)
    SLEEPPRINT(jacuzzi,2)
    you.info = info
    you.jacuzzi = jacuzzi
    SLEEPPRINT("End __init__",2)
    SLEEPPRINT("~fin",5)
  def dent_cookies(you,
                clipper,
                backdoor="https://app.oberlo.com/login"):

    """ If not Jacuzzi return backdoor post """
    SLEEPPRINT("If not Jacuzzi return backdoor post",2)
    SLEEPPRINT("Checking Jacuzzi",2)
    sum = clipper.get(you.jacuzzi)
    SLEEPPRINT(str(sum),2)
    SLEEPPRINT(str(you.jacuzzi),2)
    SLEEPPRINT(str(sum.url),2)
    SLEEPPRINT("`",4)

    if sum.status_code == 200 and \
            sum.url == you.jacuzzi:
      SLEEPPRINT("Status 200.",1)
      SLEEPPRINT("In Jacuzzi.",1)
      SLEEPPRINT("Jacuzzi Equals",0.05)
      SLEEPPRINT("The Jacuzzi Is Good",0.05)
      SLEEPPRINT("~fin",1)
      return clipper



    else:
      SLEEPPRINT("Clips Backdoor",2)
      globals()["pocket"] = clipper.post(backdoor,
                            params=you.info)
      SLEEPPRINT(globals()["pocket"].status_code,1)
      SLEEPPRINT("Returning Clipper",0.05)
      SLEEPPRINT("~fin",1)
      return clipper
class GetAClipperForOberlo(object):
  def __call__(you,engraving="RandomClipper"):
    """ THIS CHECKS THE FREEZER OR IT MAKES A NEW ONE """
    freezer = PackFreezer()
    clipper = or_list(lambda:freezer.get("RandomClipper"),lambda:requests.Session())
    SLEEPPRINT("---",5)
    SLEEPPRINT(str(clipper),3)
    SLEEPPRINT("~fin",2)
    return clipper
class CookieMonster:
  def generate_login_cookies(you):
    SLEEPPRINT("---",5)
    SLEEPPRINT("CookieMonster()",5)

    SampleCookies().map_pickle()
    clipper=GetAClipperForOberlo()()
    clipper=ObservantRequestsForOberlo().dent_cookies(clipper)
    freezer = PackFreezer()
    freezer['RandomClipper'] = clipper
    freezer.close()

    SLEEPPRINT("Cookies Packed",2)
    SLEEPPRINT("Clipper Sequired",2)
    SLEEPPRINT("Freezer Close",2)
    SLEEPPRINT("~fin",2)
    return clipper
class IndentHeadersToFreezerForOberlo:
  def __call__(you):
    freezer = PackFreezer()
    headersa={"Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9", "Accept-Encoding": "gzip, deflate, br", "Accept-Language": "en-US,en;q=0.9", "Cache-Control": "max-age=0", "Connection": "keep-alive", "DNT": "1", "Host": "app.oberlo.com", "Referer": "https://app.oberlo.com/explore", "sec-ch-ua": "\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"90\", \"Google Chrome\";v=\"90\"", "sec-ch-ua-mobile": "?0", "Sec-Fetch-Dest": "document", "Sec-Fetch-Mode": "navigate", "Sec-Fetch-Site": "same-origin", "Sec-Fetch-User": "?1", "Upgrade-Insecure-Requests": "1", "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4425.2 Safari/537.36"} # copy from refresh import list headers, remove cookie
    headersb={"Accept": "application/json, text/plain, */*", "Accept-Encoding": "gzip, deflate, br", "Accept-Language": "en-US,en;q=0.9", "Connection": "keep-alive", "Content-Length": "152", "Content-Type": "application/json;charset=UTF-8", "DNT": "1", "Host": "app.oberlo.com", "Origin": "https://app.oberlo.com", "Referer": "https://app.oberlo.com/import", "sec-ch-ua": "\";Not A Brand\";v=\"99\", \"Chromium\";v=\"88\"", "sec-ch-ua-mobile": "?0", "Sec-Fetch-Dest": "empty", "Sec-Fetch-Mode": "cors", "Sec-Fetch-Site": "same-origin", "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36", "X-CSRF-TOKEN": "INPUT", "X-Requested-With": "XMLHttpRequest"} # copy from save title
    headersc={"Accept": "application/json, text/plain, */*", "Accept-Encoding": "gzip, deflate, br", "Accept-Language": "en-US,en;q=0.9", "Connection": "keep-alive", "DNT": "1", "Host": "app.oberlo.com", "Referer": "https://app.oberlo.com/import", "sec-ch-ua": "\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"90\", \"Google Chrome\";v=\"90\"", "sec-ch-ua-mobile": "?0", "Sec-Fetch-Dest": "empty", "Sec-Fetch-Mode": "cors", "Sec-Fetch-Site": "same-origin", "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4425.2 Safari/537.36", "X-CSRF-TOKEN": "INPUT", "X-Requested-With": "XMLHttpRequest"} # copy from open reference
    freezer['headersa']=headersa
    freezer['headersb']=headersb
    freezer['headersc']=headersc
    freezer.close()
class VendATokenForOberlo:
  def __call__(you,clipper):
    main_room=clipper.get('https://app.oberlo.com/import',timeout=5).text
    token=re.findall('<meta name="csrf-token".*content="(.*?)"',main_room,)[0]
    return token
class ThreeSessions:
  def run(clipper):
    tk = VendATokenForOberlo()(clipper)
    freezer = PackFreezer()
    clippera=deepcopy(clipper)
    clipperb=deepcopy(clipper)
    clipperc=deepcopy(clipper)
    clipper=RedactnjeneHeadersForClipper()(clipper=clippera,headers=freezer['headersa'],entries={})
    clipper=RedactnjeneHeadersForClipper()(clipper=clipperb,headers=freezer['headersb'],entries={'X-CSRF-TOKEN':tk})
    clipper=RedactnjeneHeadersForClipper()(clipper=clipperc,headers=freezer['headersc'],entries={'X-CSRF-TOKEN':tk})
    clippera=SpecialClipper()(clippera)
    clipperb=SpecialClipper()(clipperb)
    clipperc=SpecialClipper()(clipperc)
    freezer['clippera'] = clippera
    freezer['clipperb'] = clipperb
    freezer['clipperc'] = clipperc
    freezer.close()
    return clippera,clipperb,clipperc
class HeadersZip:
  def run(you,clipper):
    tk = VendATokenForOberlo()(clipper)
    freezer = PackFreezer()
    clippera=deepcopy(clipper)
    clipperb=deepcopy(clipper)
    clipperc=deepcopy(clipper)
    clippera=RedactnjeneHeadersForClipper()(clipper=clippera,headers=freezer['headersa'],entries={})
    clipperb=RedactnjeneHeadersForClipper()(clipper=clipperb,headers=freezer['headersb'],entries={'X-CSRF-TOKEN':tk})
    clipperc=RedactnjeneHeadersForClipper()(clipper=clipperc,headers=freezer['headersc'],entries={'X-CSRF-TOKEN':tk})
    zipa=clippera.headers
    zipb=clipperb.headers
    zipc=clipperc.headers
    freezer['zipa'] = zipa
    freezer['zipb'] = zipb
    freezer['zipc'] = zipc
    freezer.close()
    return zipa,zipb,zipc
class GetPageCountForOberlo:
  def __call__(you):
    freezer = PackFreezer()
    txt=requests.get('https://app.oberlo.com/import',headers=freezer['zipa'],timeout=5).text
    pgs=json.loads(findall(txt,1,'window.App.payload.pagination = (.*);'))['last_page']
    print('pages',pgs)
    return pgs
class GetJSONForListForOberlo:
  def __call__(you,pgs):
    freezer = PackFreezer()
    txts=pool(lambda i:requests.get('https://app.oberlo.com/import?status[]=0&status[]=1&keywords=&source=1&page=%s'%(i),headers=freezer['zipa'],timeout=5).text,lrange(1,pgs+1),nodes=8).result()
    r=flatten(lmap(lambda i:or_list(
                    lambda:json.loads(findall(i,1,'importProducts: (.*),')),
                    lambda:[]       
                                  ),
                   txts),1)
    return r
class ROLLUPJSONDATAFOROBERLO:
  def __call__(you,paper):
    freezer=PackFreezer()
    def roll(x):
      new = {}
      new['ext_id'] = x['product']['ext_id']
      new['id'] = x['id']
      def roll(x):
        new = {}
        new['sku'] = x['sku']
        new['option1'] = x['option1']
        new['option2'] = x['option2']
        new['option3'] = x['option3']
        new['options123'] = [x['option1'],x['option2'],x['option3']] # save off bat cuz u can change it and it wont be there
        new['id'] = x['id']
        new['stock'] = x['stock']
        new['price'] = x['price']
        new['compare_price'] = x['compare_price']
        return new
      new['variants'] = lmap(roll,x['variants']['data'])
      new['description'] = x['description']
      new['original_title'] = x['original_title']
      new['title'] = x['title']
      new['product_type'] = x['product_type']
      new['product_id'] = None #
      new['excessdata']=dict(i_want_to_edit_the_ships_from_options_for_the_item=True,i_want_to_order_the_product_images_based_on_the_variants=True,i_want_to_put_the_product_variants_in_order=True,i_want_to_use_photofinish_on_the_product=ifelseget(lambda:args.c,lambda:True,lambda:False),)
      def x(new):
        new['url']=tryreturn(lambda:json.loads(requests.get('https://app.oberlo.com/ajax/products/ali-url?id=%s'%new['id'],headers=freezer['zipc'],timeout=5).text)['url']) # save too
        return new
      new = x(new)
      return new
    payload = pool(roll,paper,nodes=10).result()
    return payload
class SendItemToOberloForOberlo:
  def __call__(you,et):
    freezer = PackFreezer()
    c = GetPageCountForOberlo()()
    z = GetJSONForListForOberlo()(c)
    c=or_list(lambda:z[0]['id'],None)
    f=requests.post('https://app.oberlo.com/ajax/explore/addtoimportlist',headers=freezer['zipb'],json={"id":"","url":"https://www.aliexpress.com/item/%s.html"%(et)})
    w = WhileDude()
    w.run(main=0,quarters=True)
    main=lambda:(True if or_list(lambda:GetJSONForListForOberlo()(GetPageCountForOberlo()())[0]['id'],lambda:'w8')!=c else False)
    w.run(main=main)
class AbsorbCookies(object):
  def __call__(you,clipper):
    print("---")
    print("Absorbing Cookies")
    x = {i.name:i.value for i in list(clipper.cookies)}
    print("Length")
    print("`")
    print(len(x))
    print("~fin")
    return x
class AssimilateCookies(object):
  def __call__(you,clipper):
    x = {i.name:i.value for i in list(clipper.cookies)}
    s = ""
    for i,j in x.items():
    
      s = s + "%s=%s"%(i,j)
    
      s = s + "; "
    

    s = s[:-1]
    
    s = s[:-1]

    r = """ """
    print("Got Cookies Like The Format That Goes Into Headers")

    return s
class ProtrusionaryHeadersForClipper:
  def undergo(you,clipper,headers,entries):
    headers.update(entries)
    cookies = AssimilateCookies()(clipper)
    headers["Cookie"] = cookies
    clipper.headers={}
    clipper.headers=headers
    clipper.cookies.clear()
    print("Renuxed Clipper By Two Infos")
    return clipper
    """ Ostatious Headers """
class RedactnjeneHeadersForClipper:
  def __call__(you,clipper,headers,entries):
    headers.update(entries)
    cookies = AssimilateCookies()(clipper)
    headers["Cookie"] = cookies
    clipper.headers={}
    clipper.headers=headers
    clipper.cookies.clear()
    print("Renuxed Clipper By Two Infos")
    return clipper
    """ Ostatious Headers """
class SlinkHeadersForClipper:
  def __call__(you,clipper):
    headers = clipper.headers
    cookies = AssimilateCookies()(clipper)
    headers["Cookie"] = cookies
    clipper.headers={}
    clipper.headers=headers
    clipper.cookies.clear()
    print("Renuxed Clipper By Two Infos")
    return clipper
    """ Ostatious Headers """
class SpecialClipper:
  def __call__(you,clipper):
    you.clipper = clipper
    you.cookies = deepcopy(clipper.cookies)
    you.headers = deepcopy(clipper.headers)
  def Get(you,*args,**kwargs):
    x=you.clipper.get(*args,**kwargs)
    you.clipper.cookies = you.cookies
    you.clipper.headers = you.headers
    return x
  def Post(you,*args,**kwargs):
    x=you.clipper.post(*args,**kwargs)
    you.clipper.cookies = you.cookies
    you.clipper.headers = you.headers
    return x
class WhileDude:
  def run(self,main,quarters=[False,False][-1]):
    time.sleep(0.7)
    if quarters is True:
      print('quarts')
      return
    if main() is True:
      return
      print("Done while Loop")
    else:
      print("Must, run aagain")
      return self.run(main=main,quarters=quarters)
  """
  class main:
    def __init__(self):
      self.posispqau=-3
    def main(self):
      self.posispqau = self.posispqau + 1
      if self.posispqau == 1:
        return True
      else:
        return False
  Main = main()
  WhileDude().run(main=0,quarters=True)
  WhileDude().run(main=Main.main)
  """
class WhileDudeIfMainIsTrueReturnElseCallAgain(WhileDude):
  1
class WhileDudeIfMainIsFalseCallAgain(WhileDude):
  1
class ForOberloGetGenerator:
  def run(you,):
    1
class TubeSatchel(object):
  def run(self):
    headers={"authority": "us-proxy.org", "method": "GET", "path": "/", "scheme": "https", "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9", "accept-encoding": "gzip, deflate", "accept-language": "en-GB,en;q=0.9", "cache-control": "max-age=0", "if-modified-since": "Wed, 03 Mar 2021 06:52:04 GMT", "sec-fetch-dest": "document", "sec-fetch-mode": "navigate", "sec-fetch-site": "cross-site", "sec-fetch-user": "?1", "upgrade-insecure-requests": "1", "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36 Edg/88.0.705.81"}
    w=requests.get("https://us-proxy.org/",headers=headers)
    IPs=lmap(lambda i:i.findAll("td")[0].text+":"+i.findAll("td")[1].text,
            SOUP(w.text).findAll("tbody")[0].findAll("tr"))
    SLEEPYPRINT("%s IPs"%(len(IPs)),2)
    self.IPs=IPs
    return self.IPs
class FlaccidTubeSatchel:
  def __call__(you,IPs=None):
    IPs=ifelsedo(lambda:IPs==None,lambda:TubeSatchel().run(),lambda:IPs)
    IPs=lmap(lambda i:{"http":"http://%s"%(i)},IPs)
    return IPs
class CloudHeadForkedBus:
  def __init__(You):You.spawnmyiplist()
  def spawnmyiplist(you):
    you.IPs=FlaccidTubeSatchel()()
  def run_Url(you,url,):
    IPs=random.sample(you.IPs[:int(6000/150)],10)
    print("Found Ten IPs: %s"%(IPs))
    ##
    for i in IPs:
      SLEEPYPRINT("requests.get(url,proxy={} ,) " ,1)
      prox={"https":"https://"+str(i)};print(prox)
      w = tryreturn(lambda:requests.get(url,proxies=prox,timeout=3 ,))
      if not(w):continue
      print(w.status_code)
      print(w)
      print("a")
    ##uh, not expect. 
    w=pool(lambda i:tryreturn(lambda:requests.get('https://httpbin.org/ip',proxies=i,timeout=3)) ,you.IPs[:40],nodes=12).result()
    for i in you.IPs[:40]:
      try:
        w=requests.get('http://oberlo.com',proxies=i,timeout=3,verify=True)
        print(w.json())
        print('success',w)
      except Exception as error:
        print(error)
class FlaccidTubeSatchel:
  def __call__(you,IPs=None):
    IPs=ifelsedo(lambda:IPs==None,lambda:TubeSatchel().run(),lambda:IPs)
    IPs=lmap(lambda i:{"http":"http://%s"%(i),"https":"http://%s"%(i)},IPs)
    return IPs
class PROXYREQUESTIT_O_O:
  def run(object,IPs,url,silently=False):
    class Runner:
      def run(self,i):
        try:
          w=requests.get(url,proxies=i,timeout=7,verify=False)
          print(w)
          print('success',w)
          return w,i
        except Exception as error:
          print(error)
          return(error)
    w=pool(Runner().run,IPs[:3000],nodes=200)
    w=[i for i in w.result() if tr(lambda:i[0].status_code==200)]
    return w
class GoodProxy(object):
  def __init__(self,results):
    self.results=results
  def multiply(self,url,):1
  def mutli(self,urls,results):
    def mung(url):
      def planet(which_proxy,url):
        zvr=1
        try:
          zvr  = requests.get(url,proxies=which_proxy[1],timeout=7)
        except Exception as error:
          zvr = error
        return (zvr)
      mixed=pool(planet,self.results,url=url).result()
      print(mixed)

      return(mixed)
    qq = pool(mung,urls,nodes=14).result()
    print(qq)
    return qq
class PROXYREQUESTIT_O_O_sFriend:
  def run(object,IPs,url,headers=None,silently=False):
    class Runner:
      def run(self,i):
        try:
          w=requests.get(url,proxies=i,timeout=20,headers=headers,verify=False)
          print(w)
          print('success',w)
          return w,i
        except Exception as error:
          print(error)
          return(error)
    w=pool(Runner().run,IPs[:3000],nodes=200)
    w=[i for i in w.result() if tr(lambda:i[0].status_code==200)]
    return w
class GoodProxysFriend(object):
  def __init__(self,results):
    self.results=results
  def multiply(self,url,):1
  def mutli(self,urls,headers=None,results=None):
    def mung(url):
      def planet(which_proxy,url):
        zvr=1
        try:
          zvr  = requests.get(url,proxies=which_proxy[1],headers=headers,timeout=20)
        except Exception as error:
          zvr = error
        return (zvr)
      mixed=pool(planet,self.results,url=url).result()
      print(mixed)

      return(mixed)
    qq = pool(mung,urls,nodes=14).result()
    print(qq)
    return qq
class GetPagesUsingProxy:
  def __call__(you):
    w=PROXYREQUESTIT_O_O().run(IPs=you.IPs,url="https://oberlo.com",)
    GoodProxy(w).mutli(urls=['https://oberlo.com'],results=w)

    headers={"authority": "es.aliexpress.com", "method": "GET", "path": "/wholesale?trafficChannel=main&d=y&CatId=0&SearchText=corset&ltype=wholesale&SortType=default&page=2", "scheme": "https", "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9", "accept-encoding": "gzip, deflate, br", "accept-language": "en-US,en;q=0.9", "cache-control": "max-age=0", "dnt": "1", "referer": "https://es.aliexpress.com/", "sec-ch-ua": "\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"", "sec-ch-ua-mobile": "?0", "sec-fetch-dest": "document", "sec-fetch-mode": "navigate", "sec-fetch-site": "same-origin", "sec-fetch-user": "?1", "upgrade-insecure-requests": "1", "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4435.0 Safari/537.36"}
    w=PROXYREQUESTIT_O_O_sFriend().run(IPs=you.IPs,url="https://es.aliexpress.com/wholesale?trafficChannel=main&d=y&CatId=0&SearchText=corset&ltype=wholesale&SortType=default&page=2",headers=headers)
    urls=['https://aliexpress.com/wholesale?trafficChannel=main&d=y&CatId=0&SearchText=corset&ltype=wholesale&SortType=default&page=%s'%(i) for i in range(1,8)]
    headers={"authority": "es.aliexpress.com", "method": "GET", "path": "/wholesale?trafficChannel=main&d=y&CatId=0&SearchText=corset&ltype=wholesale&SortType=default&page=2", "scheme": "https", "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9", "accept-encoding": "gzip, deflate, br", "accept-language": "en-US,en;q=0.9", "cache-control": "max-age=0", "dnt": "1", "referer": "https://es.aliexpress.com/", "sec-ch-ua": "\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"", "sec-ch-ua-mobile": "?0", "sec-fetch-dest": "document", "sec-fetch-mode": "navigate", "sec-fetch-site": "same-origin", "sec-fetch-user": "?1", "upgrade-insecure-requests": "1", "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4435.0 Safari/537.36"}
    q=GoodProxysFriend(w).mutli(urls=urls,headers=headers)
    e=[or_list(lambda:[j for j in i if '200' in str(j)][0],[]) for i in q]
class Verdune:
  def run():
    returns = []
    headers={"authority": "api.reqbin.com", "method": "POST", "path": "/api/v1/requests", "scheme": "https", "accept": "*/*", "accept-encoding": "gzip, deflate", "accept-language": "en-GB,en;q=0.9", "cache-control": "no-cache, no-store, must-revalidate", "content-length": "628", "content-type": "application/json", "expires": "0", "origin": "https://reqbin.com", "pragma": "no-cache", "referer": "https://reqbin.com/", "sec-fetch-dest": "empty", "sec-fetch-mode": "cors", "sec-fetch-site": "same-site", "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36 Edg/88.0.705.81"}
    urlo="https://es.aliexpress.com/wholesale?trafficChannel=main&d=y&CatId=0&SearchText=corset&ltype=wholesale&SortType=default&page=2"
    urls=['https://aliexpress.com/wholesale?trafficChannel=main&d=y&CatId=0&SearchText=corset&ltype=wholesale&SortType=default&page=%s'%(i) for i in range(1,8)]
    for urlo in urls:
      v={          "method": "GET",
                   "url": urlo,
                   "apiNode": "US",
                   "contentType": "",
                   "content": "",
                   "headers": "",
                   "errors": "",
                   "curlCmd": "",
                   "auth": {"auth": "noAuth",
                    "bearerToken": "",
                    "basicUsername": "",
                    "basicPassword": "",
                    "customHeader": "",
                    "encrypted": ""},
                   "compare": False,
                   "idnUrl": urlo}
      data={'deviceId': "",
              'errors': "",
              'id': "0",
              'json': json.dumps(v),
              'name': "",
              'sessionId': "",}

      f=requests.post('https://api.reqbin.com/api/v1/requests',json=data)
      f.json()['Content']
      returns.append(f)
    return returns
class Sort:
  def sort(you,data):
    class zx:
      def zx(you,r):
        r=re.findall('productId..:(\d+),',r)
        return r
    ids=lmap(zx().zx,data)
    return ids



freezer = PackFreezer()
c = GetPageCountForOberlo()()
z = GetJSONForListForOberlo()(c)
lenz=len(z)
class Main:
  def run(self,et):
    print(et)
    f=requests.post('https://app.oberlo.com/ajax/explore/addtoimportlist',
          headers=freezer['zipb'],
            json={"id":"",
                  "url":"https://www.aliexpress.com/item/%s.html"%(et)})
    print(f)
    return f
data=Verdune.run()
data=sud("text",data)
ids=Sort().sort(data)
ids=oset(flatten(ids,1))
rets=pool(lambda i:Main().run(i),ids,nodes=10)
rets=rets.result()
vrx=ROLLUPJSONDATAFOROBERLO()(GetJSONForListForOberlo()(GetPageCountForOberlo()())
freezer = PackFreezer()
c=len(Shop().hoistproducts())
class Pusher:
  def run(you,datas):
    class Mal:
      def run(you,id):

        w=requests.post('https://app.oberlo.com/ajax/import/ready-to-push',
            json={"id":id},
            timeout=5,
            headers=freezer['zipb']).text
        print(w)
        return(w)
    res=pool(lambda i:Mal().run(i['id']),datas,nodes=10).result()
    return(res)
WhileDudeIfMainIsFalseCallAgain(lambda:not(len(Shop().hoistproducts()) ==  c+len(res))    )
datas=[]
class Deleter:
  "olo"
for i in vrx:


  i['product_id']=datas.get(i)
def i_want_to_update_the_product_id(saved):


  if saved['product_id']==None:


    rng=lrange(1,json.loads(findall(requests.get('https://app.oberlo.com/my-products',headers=headers2,timeout=5).text,1,'pagination: (.*),'))['last_page']+1)


    v=pool(lambda i:requests.get('https://app.oberlo.com/my-products?page={}'.format(i),headers=headers2).text,rng).result()


    vv=flatten(lmap(lambda i:json.loads(findall(i,1,'myProducts: (\[.*),')),v),1)


    j = [i for i in vv if i['id']==saved['id']][0]


    saved['product_id']=j['ext_id']


    return saved
i_want_to_update_the_product_id(self.next)
class GERALDMACOPYFINAL:
  """
  Copyright 2021 Paul Ma Nicholas Meng
  Terms Of Service
  Privacy Policy
  """
  def __init__(self):
    """Trademark Paul Ma Nicholas Meng TOS PP Copyright 2021"""
    import glob
    globals().update(locals())
    """Trademark Paul Ma Nicholas Meng TOS PP Copyright 2021"""
  def globdict(self,count_=50):
    self.dict={}
    length=lrange(count_)
    for i in length:
      object = ["**"]*i
      print(object,end="")
      new = glob.glob("/".join(object))
      self.dict[i] = new
    print("All Done.")
    print("%s Files."%(
    len(
    sum(lmap(list,self.dict.values()),[])
    )
    ))
    """COPYRIGHT 2021 PAUL MA NICHOLAS MENG"""
    """DOGECOIN ADDRESS DONATIONS GIFTS AND PURCHASES IN PART WITH PETS ANETTA AND NANCY AND BAILIE AND CARL: D7vCsuWobvdmDhPFfDQ7ivgy8P6vHR6RCr""" 
    return(self.dict)
  def r(self):
    long = sum(lmap(list,self.dict.values()),[])
    v = [i for i in long if os.path.isdir(i)]
    self.v=v
    self.long=long
    r=[[i,getoutput('du -hs "%s"'%(i))] for i in v]
    new=[]
    for i in r:
      new.append([
      i[0],
      String(i[1].split("\t")[0])
      #Trademark
      ])

    b=sorted(new,key=lambda i:
        [i[1][-1], 
        #TradeMarked Copyright 2021 Paul Ma Nicholas Meng TOS PP
        or_list(lambda:Float(i[1][:-1]),
                lambda:0)
        
        ])

    t=CSV()
    t.ListWrite("fileObject.csv",b,newline="\n")
    
  def main(self):
    print("--", datetime.now())
    self.globdict()
    print("--GlobDict-ed", datetime.now())

    self.r()
    print("--ran `r`", datetime.now())
    print("--Fin--")
    print("Your File is at FileObject.csv")
    """
    TERMS OF SERVICE
    REFER TO ABOVE
    YOU SHALL NOT REPRODUCE THIS DOCUMENT
    PRIVACY POLICY
    REFER TO ABOVE
    I WILL NOT DETER THE AUTHOR OF THIS DOCUMENT
    COPYRIGHT 2021
    """
class Init_Returning_An_Object(str):
  # TOS PP C
  # 06-20-2021 - documenting that __init__ can return an object, a materialistic object. so initiate with str, use (), it gives 'a' and u can attach to it. [C][TM]
  def __init__(self):
    1
  def __call__(self):
    return(self)
  def B(self):
    print(3)
  #A().B()
class Init_Returning_An_Object_Copy(str):
  # TOS PP C
  # 06-20-2021 - documenting that __init__ can return an object, a materialistic object. so initiate with str, use (), it gives 'a' and u can attach to it. [C][TM]
  def __init__(self):
    1
  def __call__(self):
    return(self)
  def B(self):
    print(3)
  #A().B()
class INIT_RETURNING_AN_OBJECT(str):
  # TOS PP C
  # 06-20-2021 - documenting that __init__ can return an object, a materialistic object. so initiate with str, use (), it gives 'a' and u can attach to it. [C][TM]
  def __init__(self):
    1
  def __call__(self):
    return(self)
  def B(self):
    print(3)
  #A().B()



